<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - coverage.info - mnt/c/libtorch/include/ATen/core/TensorBody.h</title>
  <link rel="stylesheet" type="text/css" href="../../../../../../gcov.css">
</head>

<body>

          <table width="100%" border=0 cellspacing=0 cellpadding=0>
            <tr><td class="title">LCOV - code coverage report</td></tr>
            <tr><td class="ruler"><img src="../../../../../../glass.png" width=3 height=3 alt=""></td></tr>

            <tr>
              <td width="100%">
                <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="10%" class="headerValue"><a href="../../../../../../index.html">top level</a> - <a href="index.html">/mnt/c/libtorch/include/ATen/core</a> - TensorBody.h<span style="font-size: 80%;"> (source / <a href="TensorBody.h.func-c.html">functions</a>)</span></td>
            <td width="5%"></td>
            <td width="5%"></td>
            <td width="5%" class="headerCovTableHead">Coverage</td>
            <td width="5%" class="headerCovTableHead" title="Covered + Uncovered code">Total</td>
            <td width="5%" class="headerCovTableHead" title="Exercised code only">Hit</td>
          </tr>
          <tr>
            <td class="headerItem">Test:</td>
            <td class="headerValue">coverage.info</td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntryLo">50.0&nbsp;%</td>
            <td class="headerCovTableEntry">2</td>
            <td class="headerCovTableEntry">1</td>
          </tr>
          <tr>
            <td class="headerItem">Test Date:</td>
            <td class="headerValue">2025-02-05 05:35:48</td>
            <td></td>
            <td class="headerItem">Functions:</td>
            <td class="headerCovTableEntryLo">50.0&nbsp;%</td>
            <td class="headerCovTableEntry">2</td>
            <td class="headerCovTableEntry">1</td>
          </tr>
                  <tr><td><img src="../../../../../../glass.png" width=3 height=3 alt=""></td></tr>
                </table>
              </td>
            </tr>

            <tr><td class="ruler"><img src="../../../../../../glass.png" width=3 height=3 alt=""></td></tr>
          </table>

          <table cellpadding=0 cellspacing=0 border=0>
            <tr>
              <td><br></td>
            </tr>
            <tr>
              <td>
<pre class="sourceHeading">            Line data    Source code</pre>
<pre class="source">
<span id="L1"><span class="lineNum">       1</span>              : #pragma once</span>
<span id="L2"><span class="lineNum">       2</span>              : </span>
<span id="L3"><span class="lineNum">       3</span>              : #ifdef TORCH_ASSERT_NO_OPERATORS</span>
<span id="L4"><span class="lineNum">       4</span>              : #error This change adds a dependency on native_functions.yaml,            \</span>
<span id="L5"><span class="lineNum">       5</span>              :   meaning the file will need to be re-compiled every time an operator     \</span>
<span id="L6"><span class="lineNum">       6</span>              :   is changed or added. Consider if your change would be better placed in  \</span>
<span id="L7"><span class="lineNum">       7</span>              :   another file, or if a more specific header might achieve the same goal. \</span>
<span id="L8"><span class="lineNum">       8</span>              :   See NOTE: [Tensor vs. TensorBase]</span>
<span id="L9"><span class="lineNum">       9</span>              : #endif</span>
<span id="L10"><span class="lineNum">      10</span>              : </span>
<span id="L11"><span class="lineNum">      11</span>              : #include &lt;c10/core/Device.h&gt;</span>
<span id="L12"><span class="lineNum">      12</span>              : #include &lt;c10/core/Layout.h&gt;</span>
<span id="L13"><span class="lineNum">      13</span>              : #include &lt;c10/core/MemoryFormat.h&gt;</span>
<span id="L14"><span class="lineNum">      14</span>              : #include &lt;c10/core/QScheme.h&gt;</span>
<span id="L15"><span class="lineNum">      15</span>              : #include &lt;c10/core/Stream.h&gt;</span>
<span id="L16"><span class="lineNum">      16</span>              : #include &lt;c10/core/Scalar.h&gt;</span>
<span id="L17"><span class="lineNum">      17</span>              : #include &lt;c10/core/ScalarType.h&gt;</span>
<span id="L18"><span class="lineNum">      18</span>              : #include &lt;c10/core/ScalarTypeToTypeMeta.h&gt;</span>
<span id="L19"><span class="lineNum">      19</span>              : #include &lt;c10/core/Storage.h&gt;</span>
<span id="L20"><span class="lineNum">      20</span>              : #include &lt;c10/core/TensorImpl.h&gt;</span>
<span id="L21"><span class="lineNum">      21</span>              : #include &lt;c10/core/UndefinedTensorImpl.h&gt;</span>
<span id="L22"><span class="lineNum">      22</span>              : #include &lt;c10/core/WrapDimMinimal.h&gt;</span>
<span id="L23"><span class="lineNum">      23</span>              : #include &lt;c10/util/Exception.h&gt;</span>
<span id="L24"><span class="lineNum">      24</span>              : #include &lt;c10/util/ExclusivelyOwned.h&gt;</span>
<span id="L25"><span class="lineNum">      25</span>              : #include &lt;c10/util/Deprecated.h&gt;</span>
<span id="L26"><span class="lineNum">      26</span>              : #include &lt;c10/util/MaybeOwned.h&gt;</span>
<span id="L27"><span class="lineNum">      27</span>              : #include &lt;optional&gt;</span>
<span id="L28"><span class="lineNum">      28</span>              : #include &lt;c10/util/OptionalArrayRef.h&gt;</span>
<span id="L29"><span class="lineNum">      29</span>              : #include &lt;c10/util/intrusive_ptr.h&gt;</span>
<span id="L30"><span class="lineNum">      30</span>              : #include &lt;c10/macros/Export.h&gt;</span>
<span id="L31"><span class="lineNum">      31</span>              : #include &lt;ATen/core/CheckMemoryFormat.h&gt;</span>
<span id="L32"><span class="lineNum">      32</span>              : #include &lt;ATen/core/DeprecatedTypePropertiesRegistry.h&gt;</span>
<span id="L33"><span class="lineNum">      33</span>              : #include &lt;ATen/core/DeprecatedTypeProperties.h&gt;</span>
<span id="L34"><span class="lineNum">      34</span>              : #include &lt;ATen/core/NamedTensor.h&gt;</span>
<span id="L35"><span class="lineNum">      35</span>              : #include &lt;ATen/core/QuantizerBase.h&gt;</span>
<span id="L36"><span class="lineNum">      36</span>              : #include &lt;c10/core/SymInt.h&gt;</span>
<span id="L37"><span class="lineNum">      37</span>              : #include &lt;ATen/core/TensorAccessor.h&gt;</span>
<span id="L38"><span class="lineNum">      38</span>              : #include &lt;ATen/core/TensorBase.h&gt;</span>
<span id="L39"><span class="lineNum">      39</span>              : </span>
<span id="L40"><span class="lineNum">      40</span>              : </span>
<span id="L41"><span class="lineNum">      41</span>              : #include &lt;ATen/MethodOperators.h&gt;</span>
<span id="L42"><span class="lineNum">      42</span>              : </span>
<span id="L43"><span class="lineNum">      43</span>              : namespace c10{</span>
<span id="L44"><span class="lineNum">      44</span>              : template&lt;class T&gt; class List;</span>
<span id="L45"><span class="lineNum">      45</span>              : template&lt;class T&gt; class IListRef;</span>
<span id="L46"><span class="lineNum">      46</span>              : }</span>
<span id="L47"><span class="lineNum">      47</span>              : namespace at {</span>
<span id="L48"><span class="lineNum">      48</span>              : struct Generator;</span>
<span id="L49"><span class="lineNum">      49</span>              : struct Type;</span>
<span id="L50"><span class="lineNum">      50</span>              : class DeprecatedTypeProperties;</span>
<span id="L51"><span class="lineNum">      51</span>              : class Tensor;</span>
<span id="L52"><span class="lineNum">      52</span>              : } // namespace at</span>
<span id="L53"><span class="lineNum">      53</span>              : namespace at {</span>
<span id="L54"><span class="lineNum">      54</span>              : namespace indexing {</span>
<span id="L55"><span class="lineNum">      55</span>              : struct TensorIndex;</span>
<span id="L56"><span class="lineNum">      56</span>              : } // namespace indexing</span>
<span id="L57"><span class="lineNum">      57</span>              : } // namespace at</span>
<span id="L58"><span class="lineNum">      58</span>              : </span>
<span id="L59"><span class="lineNum">      59</span>              : namespace torch { namespace autograd {</span>
<span id="L60"><span class="lineNum">      60</span>              : </span>
<span id="L61"><span class="lineNum">      61</span>              : struct Node;</span>
<span id="L62"><span class="lineNum">      62</span>              : </span>
<span id="L63"><span class="lineNum">      63</span>              : }} // namespace torch::autograd</span>
<span id="L64"><span class="lineNum">      64</span>              : </span>
<span id="L65"><span class="lineNum">      65</span>              : namespace at {</span>
<span id="L66"><span class="lineNum">      66</span>              : </span>
<span id="L67"><span class="lineNum">      67</span>              : class OptionalTensorRef;</span>
<span id="L68"><span class="lineNum">      68</span>              : class TensorRef;</span>
<span id="L69"><span class="lineNum">      69</span>              : class Tensor;</span>
<span id="L70"><span class="lineNum">      70</span>              : using TensorList = ArrayRef&lt;Tensor&gt;;</span>
<span id="L71"><span class="lineNum">      71</span>              : using ITensorList = c10::IListRef&lt;Tensor&gt;;</span>
<span id="L72"><span class="lineNum">      72</span>              : </span>
<span id="L73"><span class="lineNum">      73</span>              : using Stream = c10::Stream;</span>
<span id="L74"><span class="lineNum">      74</span>              : </span>
<span id="L75"><span class="lineNum">      75</span>              : // Tensor is a &quot;generic&quot; object holding a pointer to the underlying TensorImpl object, which</span>
<span id="L76"><span class="lineNum">      76</span>              : // has an embedded reference count. In this way, Tensor is similar to boost::intrusive_ptr.</span>
<span id="L77"><span class="lineNum">      77</span>              : //</span>
<span id="L78"><span class="lineNum">      78</span>              : // For example:</span>
<span id="L79"><span class="lineNum">      79</span>              : //</span>
<span id="L80"><span class="lineNum">      80</span>              : // void func(Tensor a) {</span>
<span id="L81"><span class="lineNum">      81</span>              : //   Tensor b = a;</span>
<span id="L82"><span class="lineNum">      82</span>              : //   ...</span>
<span id="L83"><span class="lineNum">      83</span>              : // }</span>
<span id="L84"><span class="lineNum">      84</span>              : //</span>
<span id="L85"><span class="lineNum">      85</span>              : // In this example, when we say Tensor b = a, we are creating a new object that points to the</span>
<span id="L86"><span class="lineNum">      86</span>              : // same underlying TensorImpl, and bumps its reference count. When b goes out of scope, the</span>
<span id="L87"><span class="lineNum">      87</span>              : // destructor decrements the reference count by calling release() on the TensorImpl it points to.</span>
<span id="L88"><span class="lineNum">      88</span>              : // The existing constructors, operator overloads, etc. take care to implement the correct semantics.</span>
<span id="L89"><span class="lineNum">      89</span>              : //</span>
<span id="L90"><span class="lineNum">      90</span>              : // Note that Tensor can also be NULL, i.e. it is not associated with any underlying TensorImpl, and</span>
<span id="L91"><span class="lineNum">      91</span>              : // special care must be taken to handle this.</span>
<span id="L92"><span class="lineNum">      92</span>              : class TORCH_API Tensor: public TensorBase {</span>
<span id="L93"><span class="lineNum">      93</span>              :  protected:</span>
<span id="L94"><span class="lineNum">      94</span>              :   // Create a Tensor with a +0 reference count. Special care must be</span>
<span id="L95"><span class="lineNum">      95</span>              :   // taken to avoid decrementing this reference count at destruction</span>
<span id="L96"><span class="lineNum">      96</span>              :   // time. Intended to support MaybeOwnedTraits&lt;Tensor&gt;.</span>
<span id="L97"><span class="lineNum">      97</span>              :   explicit Tensor(unsafe_borrow_t, const TensorBase&amp; rhs): TensorBase(unsafe_borrow_t{}, rhs) {}</span>
<span id="L98"><span class="lineNum">      98</span>              :   friend MaybeOwnedTraits&lt;Tensor&gt;;</span>
<span id="L99"><span class="lineNum">      99</span>              :   friend OptionalTensorRef;</span>
<span id="L100"><span class="lineNum">     100</span>              :   friend TensorRef;</span>
<span id="L101"><span class="lineNum">     101</span>              : </span>
<span id="L102"><span class="lineNum">     102</span>              :  public:</span>
<span id="L103"><span class="lineNum">     103</span>              :   Tensor() = default;</span>
<span id="L104"><span class="lineNum">     104</span>              :   // This constructor should not be used by end users and is an implementation</span>
<span id="L105"><span class="lineNum">     105</span>              :   // detail invoked by autogenerated code.</span>
<span id="L106"><span class="lineNum">     106</span>              :   explicit Tensor(</span>
<span id="L107"><span class="lineNum">     107</span>              :       c10::intrusive_ptr&lt;TensorImpl, UndefinedTensorImpl&gt; tensor_impl)</span>
<span id="L108"><span class="lineNum">     108</span>              :       : TensorBase(std::move(tensor_impl)) {}</span>
<span id="L109"><span class="lineNum">     109</span> <span class="tlaGNC tlaBgGNC">           6 :   Tensor(const Tensor &amp;tensor) = default;</span></span>
<span id="L110"><span class="lineNum">     110</span> <span class="tlaUNC tlaBgUNC">           0 :   Tensor(Tensor &amp;&amp;tensor) = default;</span></span>
<span id="L111"><span class="lineNum">     111</span>              : </span>
<span id="L112"><span class="lineNum">     112</span>              :   // Implicitly move-constructible from TensorBase, but must be explicit to increase refcount</span>
<span id="L113"><span class="lineNum">     113</span>              :   explicit Tensor(const TensorBase &amp;base): TensorBase(base) {}</span>
<span id="L114"><span class="lineNum">     114</span>              :   /*implicit*/ Tensor(TensorBase &amp;&amp;base): TensorBase(std::move(base)) {}</span>
<span id="L115"><span class="lineNum">     115</span>              : </span>
<span id="L116"><span class="lineNum">     116</span>              :   // Creates a new wrapper from TensorImpl. Intentionally a free method because</span>
<span id="L117"><span class="lineNum">     117</span>              :   // it should be used with care. Checks necessary invariants</span>
<span id="L118"><span class="lineNum">     118</span>              :   static Tensor wrap_tensor_impl(</span>
<span id="L119"><span class="lineNum">     119</span>              :       c10::intrusive_ptr&lt;TensorImpl, UndefinedTensorImpl&gt; tensor_impl) {</span>
<span id="L120"><span class="lineNum">     120</span>              :     return TensorBase::wrap_tensor_impl(std::move(tensor_impl));</span>
<span id="L121"><span class="lineNum">     121</span>              :   }</span>
<span id="L122"><span class="lineNum">     122</span>              : </span>
<span id="L123"><span class="lineNum">     123</span>              :   Tensor contiguous(MemoryFormat memory_format=MemoryFormat::Contiguous) const {</span>
<span id="L124"><span class="lineNum">     124</span>              :     return TensorBase::contiguous(memory_format);</span>
<span id="L125"><span class="lineNum">     125</span>              :   }</span>
<span id="L126"><span class="lineNum">     126</span>              : </span>
<span id="L127"><span class="lineNum">     127</span>              :   Tensor conj() const {</span>
<span id="L128"><span class="lineNum">     128</span>              :     if (!this-&gt;is_complex()) {</span>
<span id="L129"><span class="lineNum">     129</span>              :       return *this;</span>
<span id="L130"><span class="lineNum">     130</span>              :     }</span>
<span id="L131"><span class="lineNum">     131</span>              : </span>
<span id="L132"><span class="lineNum">     132</span>              :     switch (this-&gt;layout()) {</span>
<span id="L133"><span class="lineNum">     133</span>              :       case at::kSparse:</span>
<span id="L134"><span class="lineNum">     134</span>              :       case at::kSparseCsr:</span>
<span id="L135"><span class="lineNum">     135</span>              :       case at::kSparseCsc:</span>
<span id="L136"><span class="lineNum">     136</span>              :       case at::kSparseBsr:</span>
<span id="L137"><span class="lineNum">     137</span>              :       case at::kSparseBsc:</span>
<span id="L138"><span class="lineNum">     138</span>              :         return this-&gt;conj_physical();</span>
<span id="L139"><span class="lineNum">     139</span>              :       default:</span>
<span id="L140"><span class="lineNum">     140</span>              :         return this-&gt;_conj();</span>
<span id="L141"><span class="lineNum">     141</span>              :     }</span>
<span id="L142"><span class="lineNum">     142</span>              :   }</span>
<span id="L143"><span class="lineNum">     143</span>              : </span>
<span id="L144"><span class="lineNum">     144</span>              :   // Aliased by Dimname overloads, so need explicit using</span>
<span id="L145"><span class="lineNum">     145</span>              :   using TensorBase::size;</span>
<span id="L146"><span class="lineNum">     146</span>              :   using TensorBase::sym_size;</span>
<span id="L147"><span class="lineNum">     147</span>              :   using TensorBase::stride;</span>
<span id="L148"><span class="lineNum">     148</span>              : </span>
<span id="L149"><span class="lineNum">     149</span>              :   /// Should be used if *this can reasonably be expected to be contiguous and</span>
<span id="L150"><span class="lineNum">     150</span>              :   /// performance is important.</span>
<span id="L151"><span class="lineNum">     151</span>              :   /// Compared to contiguous, it saves a reference count</span>
<span id="L152"><span class="lineNum">     152</span>              :   /// increment/decrement if *this is already contiguous, at the cost</span>
<span id="L153"><span class="lineNum">     153</span>              :   /// in all cases of an extra pointer of stack usage, an extra branch</span>
<span id="L154"><span class="lineNum">     154</span>              :   /// to access, and an extra branch at destruction time.</span>
<span id="L155"><span class="lineNum">     155</span>              :   c10::MaybeOwned&lt;Tensor&gt; expect_contiguous(MemoryFormat memory_format=MemoryFormat::Contiguous) const &amp;;</span>
<span id="L156"><span class="lineNum">     156</span>              : </span>
<span id="L157"><span class="lineNum">     157</span>              :   // Use .contiguous() instead. Trying to borrow from a prvalue Tensor</span>
<span id="L158"><span class="lineNum">     158</span>              :   // will only lead to trouble and dangling references.</span>
<span id="L159"><span class="lineNum">     159</span>              :   c10::MaybeOwned&lt;Tensor&gt; expect_contiguous(MemoryFormat memory_format=MemoryFormat::Contiguous) &amp;&amp; = delete;</span>
<span id="L160"><span class="lineNum">     160</span>              : </span>
<span id="L161"><span class="lineNum">     161</span>              :   // The following overloads are very intruiging.  Consider the following</span>
<span id="L162"><span class="lineNum">     162</span>              :   // program:</span>
<span id="L163"><span class="lineNum">     163</span>              :   //</span>
<span id="L164"><span class="lineNum">     164</span>              :   //    x[1] = 3;</span>
<span id="L165"><span class="lineNum">     165</span>              :   //</span>
<span id="L166"><span class="lineNum">     166</span>              :   // We would expect that the first entry of x is written to 3.  But how can we</span>
<span id="L167"><span class="lineNum">     167</span>              :   // actually achieve this?  x[1] evaluates to a tensor...</span>
<span id="L168"><span class="lineNum">     168</span>              :   //</span>
<span id="L169"><span class="lineNum">     169</span>              :   // The answer is, using a ref-qualifier.  x[1] is an rvalue, which cannot be</span>
<span id="L170"><span class="lineNum">     170</span>              :   // (profitably) assigned to in the traditional sense, so we overload</span>
<span id="L171"><span class="lineNum">     171</span>              :   // assignment to mean, &quot;Actually, copy 3 into the tensor data.&quot;  This is done</span>
<span id="L172"><span class="lineNum">     172</span>              :   // with an rvalue-reference ref-qualified overload (the methods with &amp;&amp; at the</span>
<span id="L173"><span class="lineNum">     173</span>              :   // end of their type.)</span>
<span id="L174"><span class="lineNum">     174</span>              :   //</span>
<span id="L175"><span class="lineNum">     175</span>              :   // There's one more fly in the ointment: We also want</span>
<span id="L176"><span class="lineNum">     176</span>              :   //</span>
<span id="L177"><span class="lineNum">     177</span>              :   //    Tensor x = y;</span>
<span id="L178"><span class="lineNum">     178</span>              :   //</span>
<span id="L179"><span class="lineNum">     179</span>              :   // to work, and we want it NOT to copy.  So we need a traditional operator=</span>
<span id="L180"><span class="lineNum">     180</span>              :   // overload.  But we MUST specify a mutable lvalue ref-qualifier, to</span>
<span id="L181"><span class="lineNum">     181</span>              :   // disambiguate the traditional overload from the rvalue-reference</span>
<span id="L182"><span class="lineNum">     182</span>              :   // ref-qualified overload.  Otherwise, it will be ambiguous, because</span>
<span id="L183"><span class="lineNum">     183</span>              :   // a non ref-qualified method is eligible for all situations.</span>
<span id="L184"><span class="lineNum">     184</span>              : </span>
<span id="L185"><span class="lineNum">     185</span>              :   // Unfortunately, we have to write these constructors out manually</span>
<span id="L186"><span class="lineNum">     186</span>              :   // to work around an MSVC bug:</span>
<span id="L187"><span class="lineNum">     187</span>              :   //    error C2580: 'at::Tensor &amp;at::Tensor::operator =(const at::Tensor &amp;) &amp;':</span>
<span id="L188"><span class="lineNum">     188</span>              :   //    multiple versions of a defaulted special member functions are not allowed</span>
<span id="L189"><span class="lineNum">     189</span>              :   // Tensor&amp; operator=(const Tensor&amp;) &amp; = default;</span>
<span id="L190"><span class="lineNum">     190</span>              :   // Tensor&amp; operator=(Tensor&amp;&amp;) &amp; = default;</span>
<span id="L191"><span class="lineNum">     191</span>              : </span>
<span id="L192"><span class="lineNum">     192</span>              :   // Also MSVC will wrongly issue the following warning with the aforementioned fix</span>
<span id="L193"><span class="lineNum">     193</span>              :   //    warning C4522: 'at::Tensor': multiple assignment operators specified</span>
<span id="L194"><span class="lineNum">     194</span>              :   // Let's just skip the warning.</span>
<span id="L195"><span class="lineNum">     195</span>              :   //</span>
<span id="L196"><span class="lineNum">     196</span>              :   // TODO: temporarily disabled</span>
<span id="L197"><span class="lineNum">     197</span>              : </span>
<span id="L198"><span class="lineNum">     198</span>              :   Tensor&amp; operator=(const TensorBase&amp; x) &amp; noexcept {</span>
<span id="L199"><span class="lineNum">     199</span>              :     impl_ = x.getIntrusivePtr();</span>
<span id="L200"><span class="lineNum">     200</span>              :     return *this;</span>
<span id="L201"><span class="lineNum">     201</span>              :   }</span>
<span id="L202"><span class="lineNum">     202</span>              :   Tensor&amp; operator=(TensorBase&amp;&amp; x) &amp; noexcept {</span>
<span id="L203"><span class="lineNum">     203</span>              :     impl_ = x.unsafeReleaseIntrusivePtr();</span>
<span id="L204"><span class="lineNum">     204</span>              :     return *this;</span>
<span id="L205"><span class="lineNum">     205</span>              :   }</span>
<span id="L206"><span class="lineNum">     206</span>              : </span>
<span id="L207"><span class="lineNum">     207</span>              :   Tensor&amp; operator=(const Tensor &amp;x) &amp; noexcept {</span>
<span id="L208"><span class="lineNum">     208</span>              :     return operator=(static_cast&lt;const TensorBase&amp;&gt;(x));</span>
<span id="L209"><span class="lineNum">     209</span>              :   }</span>
<span id="L210"><span class="lineNum">     210</span>              :   Tensor&amp; operator=(Tensor &amp;&amp;x) &amp; noexcept {</span>
<span id="L211"><span class="lineNum">     211</span>              :     return operator=(static_cast&lt;TensorBase&amp;&amp;&gt;(x));</span>
<span id="L212"><span class="lineNum">     212</span>              :   }</span>
<span id="L213"><span class="lineNum">     213</span>              : </span>
<span id="L214"><span class="lineNum">     214</span>              :   Tensor&amp; operator=(const Scalar &amp;v) &amp;&amp; {</span>
<span id="L215"><span class="lineNum">     215</span>              :     return fill_(v);</span>
<span id="L216"><span class="lineNum">     216</span>              :   }</span>
<span id="L217"><span class="lineNum">     217</span>              :   Tensor&amp; operator=(const Tensor &amp;rhs) &amp;&amp; {</span>
<span id="L218"><span class="lineNum">     218</span>              :     return copy_(rhs);</span>
<span id="L219"><span class="lineNum">     219</span>              :   }</span>
<span id="L220"><span class="lineNum">     220</span>              :   Tensor&amp; operator=(Tensor&amp;&amp; rhs) &amp;&amp; {</span>
<span id="L221"><span class="lineNum">     221</span>              :     return copy_(rhs);</span>
<span id="L222"><span class="lineNum">     222</span>              :   }</span>
<span id="L223"><span class="lineNum">     223</span>              : </span>
<span id="L224"><span class="lineNum">     224</span>              :   C10_DEPRECATED_MESSAGE(&quot;Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device().&quot;)</span>
<span id="L225"><span class="lineNum">     225</span>              :   DeprecatedTypeProperties &amp; type() const {</span>
<span id="L226"><span class="lineNum">     226</span>              :     return globalDeprecatedTypePropertiesRegistry().getDeprecatedTypeProperties(</span>
<span id="L227"><span class="lineNum">     227</span>              :         dispatchKeyToBackend(legacyExtractDispatchKey(key_set())),</span>
<span id="L228"><span class="lineNum">     228</span>              :         scalar_type());</span>
<span id="L229"><span class="lineNum">     229</span>              :   }</span>
<span id="L230"><span class="lineNum">     230</span>              : </span>
<span id="L231"><span class="lineNum">     231</span>              :   Tensor toType(ScalarType t) const {</span>
<span id="L232"><span class="lineNum">     232</span>              :     return to(options().dtype(t), /*non_blocking*/ false, /*copy*/ false);</span>
<span id="L233"><span class="lineNum">     233</span>              :   }</span>
<span id="L234"><span class="lineNum">     234</span>              : </span>
<span id="L235"><span class="lineNum">     235</span>              :   // TODO: Deprecate me</span>
<span id="L236"><span class="lineNum">     236</span>              :   Tensor toBackend(Backend b) const {</span>
<span id="L237"><span class="lineNum">     237</span>              :     return to(options().device(backendToDeviceType(b)).layout(layout_from_backend(b)), /*non_blocking*/ false, /*copy*/ false);</span>
<span id="L238"><span class="lineNum">     238</span>              :   }</span>
<span id="L239"><span class="lineNum">     239</span>              : </span>
<span id="L240"><span class="lineNum">     240</span>              :   C10_DEPRECATED_MESSAGE(&quot;Tensor.is_variable() is deprecated; everything is a variable now. (If you want to assert that variable has been appropriately handled already, use at::impl::variable_excluded_from_dispatch())&quot;)</span>
<span id="L241"><span class="lineNum">     241</span>              :   bool is_variable() const noexcept {</span>
<span id="L242"><span class="lineNum">     242</span>              :     return !at::impl::variable_excluded_from_dispatch();</span>
<span id="L243"><span class="lineNum">     243</span>              :   }</span>
<span id="L244"><span class="lineNum">     244</span>              : </span>
<span id="L245"><span class="lineNum">     245</span>              :   template&lt;typename T&gt;</span>
<span id="L246"><span class="lineNum">     246</span>              :   C10_DEPRECATED_MESSAGE(&quot;Tensor.data&lt;T&gt;() is deprecated. Please use Tensor.data_ptr&lt;T&gt;() instead.&quot;)</span>
<span id="L247"><span class="lineNum">     247</span>              :   T * data() const {</span>
<span id="L248"><span class="lineNum">     248</span>              :     return data_ptr&lt;T&gt;();</span>
<span id="L249"><span class="lineNum">     249</span>              :   }</span>
<span id="L250"><span class="lineNum">     250</span>              : </span>
<span id="L251"><span class="lineNum">     251</span>              :   template &lt;typename T&gt;</span>
<span id="L252"><span class="lineNum">     252</span>              :   T item() const;</span>
<span id="L253"><span class="lineNum">     253</span>              : </span>
<span id="L254"><span class="lineNum">     254</span>              :   template&lt;typename T, size_t N, template &lt;typename U&gt; class PtrTraits = DefaultPtrTraits, typename index_t = int64_t&gt;</span>
<span id="L255"><span class="lineNum">     255</span>              :   C10_DEPRECATED_MESSAGE(&quot;packed_accessor is deprecated, use packed_accessor32 or packed_accessor64 instead&quot;)</span>
<span id="L256"><span class="lineNum">     256</span>              :   GenericPackedTensorAccessor&lt;T,N,PtrTraits,index_t&gt; packed_accessor() const &amp; {</span>
<span id="L257"><span class="lineNum">     257</span>              :     return generic_packed_accessor&lt;T,N,PtrTraits,index_t&gt;();</span>
<span id="L258"><span class="lineNum">     258</span>              :   }</span>
<span id="L259"><span class="lineNum">     259</span>              :   template&lt;typename T, size_t N, template &lt;typename U&gt; class PtrTraits = DefaultPtrTraits, typename index_t = int64_t&gt;</span>
<span id="L260"><span class="lineNum">     260</span>              :   C10_DEPRECATED_MESSAGE(&quot;packed_accessor is deprecated, use packed_accessor32 or packed_accessor64 instead&quot;)</span>
<span id="L261"><span class="lineNum">     261</span>              :   GenericPackedTensorAccessor&lt;T,N,PtrTraits,index_t&gt; packed_accessor() &amp;&amp; = delete;</span>
<span id="L262"><span class="lineNum">     262</span>              : </span>
<span id="L263"><span class="lineNum">     263</span>              :   Tensor operator~() const {</span>
<span id="L264"><span class="lineNum">     264</span>              :     return bitwise_not();</span>
<span id="L265"><span class="lineNum">     265</span>              :   }</span>
<span id="L266"><span class="lineNum">     266</span>              :   Tensor operator-() const {</span>
<span id="L267"><span class="lineNum">     267</span>              :     return neg();</span>
<span id="L268"><span class="lineNum">     268</span>              :   }</span>
<span id="L269"><span class="lineNum">     269</span>              :   Tensor&amp; operator+=(const Tensor &amp; other) {</span>
<span id="L270"><span class="lineNum">     270</span>              :     return add_(other);</span>
<span id="L271"><span class="lineNum">     271</span>              :   }</span>
<span id="L272"><span class="lineNum">     272</span>              :   Tensor&amp; operator+=(const Scalar &amp; other) {</span>
<span id="L273"><span class="lineNum">     273</span>              :     return add_(other);</span>
<span id="L274"><span class="lineNum">     274</span>              :   }</span>
<span id="L275"><span class="lineNum">     275</span>              :   Tensor&amp; operator-=(const Tensor &amp; other) {</span>
<span id="L276"><span class="lineNum">     276</span>              :     return sub_(other);</span>
<span id="L277"><span class="lineNum">     277</span>              :   }</span>
<span id="L278"><span class="lineNum">     278</span>              :   Tensor&amp; operator-=(const Scalar &amp; other) {</span>
<span id="L279"><span class="lineNum">     279</span>              :     return sub_(other);</span>
<span id="L280"><span class="lineNum">     280</span>              :   }</span>
<span id="L281"><span class="lineNum">     281</span>              :   Tensor&amp; operator*=(const Tensor &amp; other) {</span>
<span id="L282"><span class="lineNum">     282</span>              :     return mul_(other);</span>
<span id="L283"><span class="lineNum">     283</span>              :   }</span>
<span id="L284"><span class="lineNum">     284</span>              :   Tensor&amp; operator*=(const Scalar &amp; other) {</span>
<span id="L285"><span class="lineNum">     285</span>              :     return mul_(other);</span>
<span id="L286"><span class="lineNum">     286</span>              :   }</span>
<span id="L287"><span class="lineNum">     287</span>              :   Tensor&amp; operator/=(const Tensor &amp; other) {</span>
<span id="L288"><span class="lineNum">     288</span>              :     return div_(other);</span>
<span id="L289"><span class="lineNum">     289</span>              :   }</span>
<span id="L290"><span class="lineNum">     290</span>              :   Tensor&amp; operator/=(const Scalar &amp; other) {</span>
<span id="L291"><span class="lineNum">     291</span>              :     return div_(other);</span>
<span id="L292"><span class="lineNum">     292</span>              :   }</span>
<span id="L293"><span class="lineNum">     293</span>              :   Tensor&amp; operator&amp;=(const Tensor &amp; other) {</span>
<span id="L294"><span class="lineNum">     294</span>              :     return bitwise_and_(other);</span>
<span id="L295"><span class="lineNum">     295</span>              :   }</span>
<span id="L296"><span class="lineNum">     296</span>              :   Tensor&amp; operator|=(const Tensor &amp; other) {</span>
<span id="L297"><span class="lineNum">     297</span>              :     return bitwise_or_(other);</span>
<span id="L298"><span class="lineNum">     298</span>              :   }</span>
<span id="L299"><span class="lineNum">     299</span>              :   Tensor&amp; operator^=(const Tensor &amp; other) {</span>
<span id="L300"><span class="lineNum">     300</span>              :     return bitwise_xor_(other);</span>
<span id="L301"><span class="lineNum">     301</span>              :   }</span>
<span id="L302"><span class="lineNum">     302</span>              :   Tensor operator[](const Scalar &amp; index) const {</span>
<span id="L303"><span class="lineNum">     303</span>              :     if (!index.isIntegral(false)) {</span>
<span id="L304"><span class="lineNum">     304</span>              :       TORCH_CHECK_INDEX(false, &quot;Can only index tensors with integral scalars&quot;);</span>
<span id="L305"><span class="lineNum">     305</span>              :     }</span>
<span id="L306"><span class="lineNum">     306</span>              :     return this-&gt;operator[](index.toLong());</span>
<span id="L307"><span class="lineNum">     307</span>              :   }</span>
<span id="L308"><span class="lineNum">     308</span>              :   Tensor operator[](const Tensor &amp; index) const {</span>
<span id="L309"><span class="lineNum">     309</span>              :     // These properties are checked in the Scalar constructor, but we already</span>
<span id="L310"><span class="lineNum">     310</span>              :     // check them here to provide more useful diagnostics for the user.</span>
<span id="L311"><span class="lineNum">     311</span>              :     if (!index.defined()) {</span>
<span id="L312"><span class="lineNum">     312</span>              :       TORCH_CHECK_INDEX(false, &quot;Can only index with tensors that are defined&quot;);</span>
<span id="L313"><span class="lineNum">     313</span>              :     }</span>
<span id="L314"><span class="lineNum">     314</span>              :     if (index.dim() != 0) {</span>
<span id="L315"><span class="lineNum">     315</span>              :       TORCH_CHECK_INDEX(false,</span>
<span id="L316"><span class="lineNum">     316</span>              :                         &quot;Can only index with tensors that are scalars (zero-dim)&quot;);</span>
<span id="L317"><span class="lineNum">     317</span>              :     }</span>
<span id="L318"><span class="lineNum">     318</span>              :     // The Scalar(Tensor) constructor is explicit, so we need to call it.</span>
<span id="L319"><span class="lineNum">     319</span>              :     return this-&gt;operator[](index.item());</span>
<span id="L320"><span class="lineNum">     320</span>              :   }</span>
<span id="L321"><span class="lineNum">     321</span>              :   Tensor operator[](int64_t index) const {</span>
<span id="L322"><span class="lineNum">     322</span>              :     return select(0, index);</span>
<span id="L323"><span class="lineNum">     323</span>              :   }</span>
<span id="L324"><span class="lineNum">     324</span>              : </span>
<span id="L325"><span class="lineNum">     325</span>              :   Tensor index(ArrayRef&lt;at::indexing::TensorIndex&gt; indices) const;</span>
<span id="L326"><span class="lineNum">     326</span>              :   Tensor index(std::initializer_list&lt;at::indexing::TensorIndex&gt; indices) const;</span>
<span id="L327"><span class="lineNum">     327</span>              : </span>
<span id="L328"><span class="lineNum">     328</span>              :   Tensor &amp; index_put_(ArrayRef&lt;at::indexing::TensorIndex&gt; indices, Tensor const &amp; rhs);</span>
<span id="L329"><span class="lineNum">     329</span>              :   Tensor &amp; index_put_(ArrayRef&lt;at::indexing::TensorIndex&gt; indices, const Scalar&amp; v);</span>
<span id="L330"><span class="lineNum">     330</span>              :   Tensor &amp; index_put_(std::initializer_list&lt;at::indexing::TensorIndex&gt; indices, Tensor const &amp; rhs);</span>
<span id="L331"><span class="lineNum">     331</span>              :   Tensor &amp; index_put_(std::initializer_list&lt;at::indexing::TensorIndex&gt; indices, const Scalar&amp; v);</span>
<span id="L332"><span class="lineNum">     332</span>              : </span>
<span id="L333"><span class="lineNum">     333</span>              :   Tensor cpu() const {</span>
<span id="L334"><span class="lineNum">     334</span>              :     return to(options().device(c10::DeviceType::CPU), /*non_blocking*/ false, /*copy*/ false);</span>
<span id="L335"><span class="lineNum">     335</span>              :   }</span>
<span id="L336"><span class="lineNum">     336</span>              : </span>
<span id="L337"><span class="lineNum">     337</span>              :   // TODO: The Python version also accepts arguments</span>
<span id="L338"><span class="lineNum">     338</span>              :   Tensor cuda() const {</span>
<span id="L339"><span class="lineNum">     339</span>              :     return to(options().device(c10::DeviceType::CUDA), /*non_blocking*/ false, /*copy*/ false);</span>
<span id="L340"><span class="lineNum">     340</span>              :   }</span>
<span id="L341"><span class="lineNum">     341</span>              : </span>
<span id="L342"><span class="lineNum">     342</span>              :   Tensor hip() const {</span>
<span id="L343"><span class="lineNum">     343</span>              :     return to(options().device(c10::DeviceType::HIP), /*non_blocking*/ false, /*copy*/ false);</span>
<span id="L344"><span class="lineNum">     344</span>              :   }</span>
<span id="L345"><span class="lineNum">     345</span>              : </span>
<span id="L346"><span class="lineNum">     346</span>              :   Tensor ve() const {</span>
<span id="L347"><span class="lineNum">     347</span>              :     return to(options().device(c10::DeviceType::VE), /*non_blocking*/ false, /*copy*/ false);</span>
<span id="L348"><span class="lineNum">     348</span>              :   }</span>
<span id="L349"><span class="lineNum">     349</span>              : </span>
<span id="L350"><span class="lineNum">     350</span>              :   Tensor vulkan() const {</span>
<span id="L351"><span class="lineNum">     351</span>              :     return to(options().device(c10::DeviceType::Vulkan), /*non_blocking*/ false, /*copy*/ false);</span>
<span id="L352"><span class="lineNum">     352</span>              :   }</span>
<span id="L353"><span class="lineNum">     353</span>              : </span>
<span id="L354"><span class="lineNum">     354</span>              :   Tensor metal() const {</span>
<span id="L355"><span class="lineNum">     355</span>              :     return to(options().device(c10::DeviceType::Metal), /*non_blocking*/ false, /*copy*/ false);</span>
<span id="L356"><span class="lineNum">     356</span>              :   }</span>
<span id="L357"><span class="lineNum">     357</span>              : </span>
<span id="L358"><span class="lineNum">     358</span>              :   Tensor meta() const {</span>
<span id="L359"><span class="lineNum">     359</span>              :     return to(options().device(c10::DeviceType::Meta), /*non_blocking*/ false, /*copy*/ false);</span>
<span id="L360"><span class="lineNum">     360</span>              :   }</span>
<span id="L361"><span class="lineNum">     361</span>              : </span>
<span id="L362"><span class="lineNum">     362</span>              :   // ~~~~~ Autograd API ~~~~~</span>
<span id="L363"><span class="lineNum">     363</span>              : </span>
<span id="L364"><span class="lineNum">     364</span>              :   /// \fn bool is_leaf() const;</span>
<span id="L365"><span class="lineNum">     365</span>              :   ///</span>
<span id="L366"><span class="lineNum">     366</span>              :   /// All Tensors that have `requires_grad()` which is ``false`` will be leaf Tensors by convention.</span>
<span id="L367"><span class="lineNum">     367</span>              :   ///</span>
<span id="L368"><span class="lineNum">     368</span>              :   /// For Tensors that have `requires_grad()` which is ``true``, they will be leaf Tensors if they were</span>
<span id="L369"><span class="lineNum">     369</span>              :   /// created by the user. This means that they are not the result of an operation and so</span>
<span id="L370"><span class="lineNum">     370</span>              :   /// `grad_fn()` is `nullptr`.</span>
<span id="L371"><span class="lineNum">     371</span>              :   ///</span>
<span id="L372"><span class="lineNum">     372</span>              :   /// Only leaf Tensors will have their `grad()` populated during a call to `backward()`.</span>
<span id="L373"><span class="lineNum">     373</span>              :   /// To get `grad()` populated for non-leaf Tensors, you can use `retain_grad()`.</span>
<span id="L374"><span class="lineNum">     374</span>              :   ///</span>
<span id="L375"><span class="lineNum">     375</span>              :   /// Example:</span>
<span id="L376"><span class="lineNum">     376</span>              :   /// @code</span>
<span id="L377"><span class="lineNum">     377</span>              :   /// auto a = torch::rand(10, torch::requires_grad());</span>
<span id="L378"><span class="lineNum">     378</span>              :   /// std::cout &lt;&lt; a.is_leaf() &lt;&lt; std::endl; // prints `true`</span>
<span id="L379"><span class="lineNum">     379</span>              :   ///</span>
<span id="L380"><span class="lineNum">     380</span>              :   /// auto b = torch::rand(10, torch::requires_grad()).to(torch::kCUDA);</span>
<span id="L381"><span class="lineNum">     381</span>              :   /// std::cout &lt;&lt; b.is_leaf() &lt;&lt; std::endl; // prints `false`</span>
<span id="L382"><span class="lineNum">     382</span>              :   /// // b was created by the operation that cast a cpu Tensor into a cuda Tensor</span>
<span id="L383"><span class="lineNum">     383</span>              :   ///</span>
<span id="L384"><span class="lineNum">     384</span>              :   /// auto c = torch::rand(10, torch::requires_grad()) + 2;</span>
<span id="L385"><span class="lineNum">     385</span>              :   /// std::cout &lt;&lt; c.is_leaf() &lt;&lt; std::endl; // prints `false`</span>
<span id="L386"><span class="lineNum">     386</span>              :   /// // c was created by the addition operation</span>
<span id="L387"><span class="lineNum">     387</span>              :   ///</span>
<span id="L388"><span class="lineNum">     388</span>              :   /// auto d = torch::rand(10).cuda();</span>
<span id="L389"><span class="lineNum">     389</span>              :   /// std::cout &lt;&lt; d.is_leaf() &lt;&lt; std::endl; // prints `true`</span>
<span id="L390"><span class="lineNum">     390</span>              :   /// // d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)</span>
<span id="L391"><span class="lineNum">     391</span>              :   ///</span>
<span id="L392"><span class="lineNum">     392</span>              :   /// auto e = torch::rand(10).cuda().requires_grad_();</span>
<span id="L393"><span class="lineNum">     393</span>              :   /// std::cout &lt;&lt; e.is_leaf() &lt;&lt; std::endl; // prints `true`</span>
<span id="L394"><span class="lineNum">     394</span>              :   /// // e requires gradients and has no operations creating it</span>
<span id="L395"><span class="lineNum">     395</span>              :   ///</span>
<span id="L396"><span class="lineNum">     396</span>              :   /// auto f = torch::rand(10, torch::device(torch::kCUDA).requires_grad(true));</span>
<span id="L397"><span class="lineNum">     397</span>              :   /// std::cout &lt;&lt; f.is_leaf() &lt;&lt; std::endl; // prints `true`</span>
<span id="L398"><span class="lineNum">     398</span>              :   /// // f requires grad, has no operation creating it</span>
<span id="L399"><span class="lineNum">     399</span>              :   /// @endcode</span>
<span id="L400"><span class="lineNum">     400</span>              : </span>
<span id="L401"><span class="lineNum">     401</span>              :   /// \fn void backward(const Tensor &amp; gradient={}, std::optional&lt;bool&gt; retain_graph=std::nullopt, bool create_graph=false, std::optional&lt;TensorList&gt; inputs=std::nullopt) const;</span>
<span id="L402"><span class="lineNum">     402</span>              :   ///</span>
<span id="L403"><span class="lineNum">     403</span>              :   /// Computes the gradient of current tensor with respect to graph leaves.</span>
<span id="L404"><span class="lineNum">     404</span>              :   ///</span>
<span id="L405"><span class="lineNum">     405</span>              :   /// The graph is differentiated using the chain rule. If the tensor is</span>
<span id="L406"><span class="lineNum">     406</span>              :   /// non-scalar (i.e. its data has more than one element) and requires</span>
<span id="L407"><span class="lineNum">     407</span>              :   /// gradient, the function additionally requires specifying ``gradient``.</span>
<span id="L408"><span class="lineNum">     408</span>              :   /// It should be a tensor of matching type and location, that contains</span>
<span id="L409"><span class="lineNum">     409</span>              :   /// the gradient of the differentiated function w.r.t. this Tensor.</span>
<span id="L410"><span class="lineNum">     410</span>              :   ///</span>
<span id="L411"><span class="lineNum">     411</span>              :   /// This function accumulates gradients in the leaves - you might need to</span>
<span id="L412"><span class="lineNum">     412</span>              :   /// zero them before calling it.</span>
<span id="L413"><span class="lineNum">     413</span>              :   ///</span>
<span id="L414"><span class="lineNum">     414</span>              :   /// \param gradient Gradient w.r.t. the</span>
<span id="L415"><span class="lineNum">     415</span>              :   ///     tensor. If it is a tensor, it will be automatically converted</span>
<span id="L416"><span class="lineNum">     416</span>              :   ///     to a Tensor that does not require grad unless ``create_graph`` is True.</span>
<span id="L417"><span class="lineNum">     417</span>              :   ///     None values can be specified for scalar Tensors or ones that</span>
<span id="L418"><span class="lineNum">     418</span>              :   ///     don't require grad. If a None value would be acceptable then</span>
<span id="L419"><span class="lineNum">     419</span>              :   ///     this argument is optional.</span>
<span id="L420"><span class="lineNum">     420</span>              :   /// \param retain_graph If ``false``, the graph used to compute</span>
<span id="L421"><span class="lineNum">     421</span>              :   ///     the grads will be freed. Note that in nearly all cases setting</span>
<span id="L422"><span class="lineNum">     422</span>              :   ///     this option to True is not needed and often can be worked around</span>
<span id="L423"><span class="lineNum">     423</span>              :   ///     in a much more efficient way. Defaults to the value of</span>
<span id="L424"><span class="lineNum">     424</span>              :   ///     ``create_graph``.</span>
<span id="L425"><span class="lineNum">     425</span>              :   /// \param create_graph If ``true``, graph of the derivative will</span>
<span id="L426"><span class="lineNum">     426</span>              :   ///     be constructed, allowing to compute higher order derivative</span>
<span id="L427"><span class="lineNum">     427</span>              :   ///     products. Defaults to ``false``.</span>
<span id="L428"><span class="lineNum">     428</span>              :   /// \param inputs Inputs w.r.t. which the gradient will be accumulated into</span>
<span id="L429"><span class="lineNum">     429</span>              :   ///     ``at::Tensor::grad``. All other Tensors will be ignored. If not</span>
<span id="L430"><span class="lineNum">     430</span>              :   ///     provided, the gradient is accumulated into all the leaf Tensors</span>
<span id="L431"><span class="lineNum">     431</span>              :   ///     that were used to compute the current tensor.</span>
<span id="L432"><span class="lineNum">     432</span>              :   ///     When inputs are provided and a given input is not a leaf,</span>
<span id="L433"><span class="lineNum">     433</span>              :   ///     the current implementation will call its grad_fn (even though it is not strictly needed to get this gradients).</span>
<span id="L434"><span class="lineNum">     434</span>              :   ///     It is an implementation detail on which the user should not rely.</span>
<span id="L435"><span class="lineNum">     435</span>              :   ///     See https://github.com/pytorch/pytorch/pull/60521#issuecomment-867061780 for more details.</span>
<span id="L436"><span class="lineNum">     436</span>              :   void backward(const Tensor &amp; gradient={}, std::optional&lt;bool&gt; retain_graph=std::nullopt, bool create_graph=false, std::optional&lt;TensorList&gt; inputs=std::nullopt) const {</span>
<span id="L437"><span class="lineNum">     437</span>              :     // NB: Adding this wrapper to _backward here because we'd like our</span>
<span id="L438"><span class="lineNum">     438</span>              :     // 'backwards' api to accept the 'inputs' argument optionally. Since code gen</span>
<span id="L439"><span class="lineNum">     439</span>              :     // currently does not support optional of TensorList our approach is to replace</span>
<span id="L440"><span class="lineNum">     440</span>              :     // backward in native_functions.yaml with _backward and call it here instead.</span>
<span id="L441"><span class="lineNum">     441</span>              :     if (inputs.has_value()) {</span>
<span id="L442"><span class="lineNum">     442</span>              :       TORCH_CHECK(inputs.value().size() &gt; 0, &quot;'inputs' argument to backward cannot be empty&quot;)</span>
<span id="L443"><span class="lineNum">     443</span>              :       this-&gt;_backward(inputs.value(), gradient, retain_graph, create_graph);</span>
<span id="L444"><span class="lineNum">     444</span>              :     } else {</span>
<span id="L445"><span class="lineNum">     445</span>              :       this-&gt;_backward({}, gradient, retain_graph, create_graph);</span>
<span id="L446"><span class="lineNum">     446</span>              :     }</span>
<span id="L447"><span class="lineNum">     447</span>              :   }</span>
<span id="L448"><span class="lineNum">     448</span>              : </span>
<span id="L449"><span class="lineNum">     449</span>              :   /// \fn Tensor detach() const;</span>
<span id="L450"><span class="lineNum">     450</span>              :   ///</span>
<span id="L451"><span class="lineNum">     451</span>              :   /// Returns a new Tensor, detached from the current graph.</span>
<span id="L452"><span class="lineNum">     452</span>              :   /// The result will never require gradient.</span>
<span id="L453"><span class="lineNum">     453</span>              : </span>
<span id="L454"><span class="lineNum">     454</span>              :   /// \fn Tensor &amp; detach_() const;</span>
<span id="L455"><span class="lineNum">     455</span>              :   ///</span>
<span id="L456"><span class="lineNum">     456</span>              :   /// Detaches the Tensor from the graph that created it, making it a leaf.</span>
<span id="L457"><span class="lineNum">     457</span>              :   /// Views cannot be detached in-place.</span>
<span id="L458"><span class="lineNum">     458</span>              : </span>
<span id="L459"><span class="lineNum">     459</span>              :   /// \fn void retain_grad() const;</span>
<span id="L460"><span class="lineNum">     460</span>              :   ///</span>
<span id="L461"><span class="lineNum">     461</span>              :   /// Enables this Tensor to have their :attr:`grad` populated during</span>
<span id="L462"><span class="lineNum">     462</span>              :   /// :func:`backward`. This is a no-op for leaf tensors.</span>
<span id="L463"><span class="lineNum">     463</span>              : </span>
<span id="L464"><span class="lineNum">     464</span>              :   /// \fn bool retains_grad() const;</span>
<span id="L465"><span class="lineNum">     465</span>              :   ///</span>
<span id="L466"><span class="lineNum">     466</span>              :   /// Is ``true`` if this Tensor is non-leaf and its :attr:`grad` is enabled to be</span>
<span id="L467"><span class="lineNum">     467</span>              :   /// populated during :func:`backward`, ``false`` otherwise.</span>
<span id="L468"><span class="lineNum">     468</span>              : </span>
<span id="L469"><span class="lineNum">     469</span>              :   const Tensor&amp; set_requires_grad(bool requires_grad) const {</span>
<span id="L470"><span class="lineNum">     470</span>              :     TensorBase::set_requires_grad(requires_grad);</span>
<span id="L471"><span class="lineNum">     471</span>              :     return *this;</span>
<span id="L472"><span class="lineNum">     472</span>              :   }</span>
<span id="L473"><span class="lineNum">     473</span>              : </span>
<span id="L474"><span class="lineNum">     474</span>              :   /// Return a mutable reference to the gradient. This is conventionally</span>
<span id="L475"><span class="lineNum">     475</span>              :   /// used as `t.grad() = x` to set a gradient to a completely new tensor.</span>
<span id="L476"><span class="lineNum">     476</span>              :   /// Note that this function work with a non-const Tensor and is not</span>
<span id="L477"><span class="lineNum">     477</span>              :   /// thread safe.</span>
<span id="L478"><span class="lineNum">     478</span>              :   Tensor&amp; mutable_grad() const {</span>
<span id="L479"><span class="lineNum">     479</span>              :     return impl_-&gt;mutable_grad();</span>
<span id="L480"><span class="lineNum">     480</span>              :   }</span>
<span id="L481"><span class="lineNum">     481</span>              : </span>
<span id="L482"><span class="lineNum">     482</span>              :   /// This function returns an undefined tensor by default and returns a defined tensor</span>
<span id="L483"><span class="lineNum">     483</span>              :   /// the first time a call to `backward()` computes gradients for this Tensor.</span>
<span id="L484"><span class="lineNum">     484</span>              :   /// The attribute will then contain the gradients computed and future calls</span>
<span id="L485"><span class="lineNum">     485</span>              :   /// to `backward()` will accumulate (add) gradients into it.</span>
<span id="L486"><span class="lineNum">     486</span>              :   const Tensor&amp; grad() const {</span>
<span id="L487"><span class="lineNum">     487</span>              :     const Tensor&amp; maybe_grad = impl_-&gt;grad();</span>
<span id="L488"><span class="lineNum">     488</span>              :     if (!is_leaf() &amp;&amp; !retains_grad() &amp;&amp; !maybe_grad.defined()) {</span>
<span id="L489"><span class="lineNum">     489</span>              :       TORCH_WARN(</span>
<span id="L490"><span class="lineNum">     490</span>              :         &quot;The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad &quot;</span>
<span id="L491"><span class="lineNum">     491</span>              :         &quot;attribute won't be populated during autograd.backward(). If you indeed want the .grad &quot;</span>
<span id="L492"><span class="lineNum">     492</span>              :         &quot;field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. &quot;</span>
<span id="L493"><span class="lineNum">     493</span>              :         &quot;If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor &quot;</span>
<span id="L494"><span class="lineNum">     494</span>              :         &quot;instead. See github.com/pytorch/pytorch/pull/30531 for more informations.&quot;);</span>
<span id="L495"><span class="lineNum">     495</span>              :     }</span>
<span id="L496"><span class="lineNum">     496</span>              :     return maybe_grad;</span>
<span id="L497"><span class="lineNum">     497</span>              :   }</span>
<span id="L498"><span class="lineNum">     498</span>              : </span>
<span id="L499"><span class="lineNum">     499</span>              :   // The Forward AD API functions below are low level and are not to be used by end</span>
<span id="L500"><span class="lineNum">     500</span>              :   // users who should use the API provided in torch/csrc/autograd.h</span>
<span id="L501"><span class="lineNum">     501</span>              : </span>
<span id="L502"><span class="lineNum">     502</span>              :   /// This function returns the forward gradient for this Tensor at the given level.</span>
<span id="L503"><span class="lineNum">     503</span>              :   const Tensor&amp; _fw_grad(uint64_t level) const {</span>
<span id="L504"><span class="lineNum">     504</span>              :     return impl_-&gt;_fw_grad(level, *this);</span>
<span id="L505"><span class="lineNum">     505</span>              :   }</span>
<span id="L506"><span class="lineNum">     506</span>              : </span>
<span id="L507"><span class="lineNum">     507</span>              :   /// This function can be used to set the value of the forward grad.</span>
<span id="L508"><span class="lineNum">     508</span>              :   /// Note that the given new_grad might not be used directly if it has different</span>
<span id="L509"><span class="lineNum">     509</span>              :   /// metadata (size/stride/storage offset) compared to this Tensor. In that case,</span>
<span id="L510"><span class="lineNum">     510</span>              :   /// new_grad content will be copied into a new Tensor</span>
<span id="L511"><span class="lineNum">     511</span>              :   void _set_fw_grad(const TensorBase&amp; new_grad, uint64_t level, bool is_inplace_op) const {</span>
<span id="L512"><span class="lineNum">     512</span>              :     impl_-&gt;_set_fw_grad(new_grad, *this, level, is_inplace_op);</span>
<span id="L513"><span class="lineNum">     513</span>              :   }</span>
<span id="L514"><span class="lineNum">     514</span>              : </span>
<span id="L515"><span class="lineNum">     515</span>              : </span>
<span id="L516"><span class="lineNum">     516</span>              :   // STOP.  Thinking of adding a method here, which only makes use</span>
<span id="L517"><span class="lineNum">     517</span>              :   // of other ATen methods?  Define it in native_functions.yaml.</span>
<span id="L518"><span class="lineNum">     518</span>              : </span>
<span id="L519"><span class="lineNum">     519</span>              :   //example</span>
<span id="L520"><span class="lineNum">     520</span>              :   //Tensor * add(Tensor &amp; b);</span>
<span id="L521"><span class="lineNum">     521</span>              :   void __dispatch__backward(at::TensorList inputs, const ::std::optional&lt;at::Tensor&gt; &amp; gradient={}, ::std::optional&lt;bool&gt; retain_graph=::std::nullopt, bool create_graph=false) const;</span>
<span id="L522"><span class="lineNum">     522</span>              :   void __dispatch_set_data(const at::Tensor &amp; new_data) const;</span>
<span id="L523"><span class="lineNum">     523</span>              :   at::Tensor __dispatch_data() const;</span>
<span id="L524"><span class="lineNum">     524</span>              :   bool __dispatch_is_leaf() const;</span>
<span id="L525"><span class="lineNum">     525</span>              :   int64_t __dispatch_output_nr() const;</span>
<span id="L526"><span class="lineNum">     526</span>              :   int64_t __dispatch__version() const;</span>
<span id="L527"><span class="lineNum">     527</span>              :   at::Tensor &amp; __dispatch_requires_grad_(bool requires_grad=true) const;</span>
<span id="L528"><span class="lineNum">     528</span>              :   void __dispatch_retain_grad() const;</span>
<span id="L529"><span class="lineNum">     529</span>              :   bool __dispatch_retains_grad() const;</span>
<span id="L530"><span class="lineNum">     530</span>              :   at::Tensor _fw_primal(int64_t level) const;</span>
<span id="L531"><span class="lineNum">     531</span>              :   at::Tensor &amp; rename_(::std::optional&lt;at::DimnameList&gt; names) const;</span>
<span id="L532"><span class="lineNum">     532</span>              :   at::Tensor rename(::std::optional&lt;at::DimnameList&gt; names) const;</span>
<span id="L533"><span class="lineNum">     533</span>              :   at::Tensor align_to(at::DimnameList names) const;</span>
<span id="L534"><span class="lineNum">     534</span>              :   at::Tensor align_to(at::DimnameList order, int64_t ellipsis_idx) const;</span>
<span id="L535"><span class="lineNum">     535</span>              :   at::Tensor align_as(const at::Tensor &amp; other) const;</span>
<span id="L536"><span class="lineNum">     536</span>              :   at::Tensor refine_names(at::DimnameList names) const;</span>
<span id="L537"><span class="lineNum">     537</span>              :   at::Tensor abs() const;</span>
<span id="L538"><span class="lineNum">     538</span>              :   at::Tensor &amp; abs_() const;</span>
<span id="L539"><span class="lineNum">     539</span>              :   at::Tensor absolute() const;</span>
<span id="L540"><span class="lineNum">     540</span>              :   at::Tensor &amp; absolute_() const;</span>
<span id="L541"><span class="lineNum">     541</span>              :   at::Tensor angle() const;</span>
<span id="L542"><span class="lineNum">     542</span>              :   at::Tensor sgn() const;</span>
<span id="L543"><span class="lineNum">     543</span>              :   at::Tensor &amp; sgn_() const;</span>
<span id="L544"><span class="lineNum">     544</span>              :   at::Tensor chalf(::std::optional&lt;at::MemoryFormat&gt; memory_format=::std::nullopt) const;</span>
<span id="L545"><span class="lineNum">     545</span>              :   at::Tensor _conj() const;</span>
<span id="L546"><span class="lineNum">     546</span>              :   at::Tensor __dispatch_conj() const;</span>
<span id="L547"><span class="lineNum">     547</span>              :   at::Tensor _conj_physical() const;</span>
<span id="L548"><span class="lineNum">     548</span>              :   at::Tensor conj_physical() const;</span>
<span id="L549"><span class="lineNum">     549</span>              :   at::Tensor &amp; conj_physical_() const;</span>
<span id="L550"><span class="lineNum">     550</span>              :   at::Tensor resolve_conj() const;</span>
<span id="L551"><span class="lineNum">     551</span>              :   at::Tensor resolve_neg() const;</span>
<span id="L552"><span class="lineNum">     552</span>              :   at::Tensor _neg_view() const;</span>
<span id="L553"><span class="lineNum">     553</span>              :   at::Tensor acos() const;</span>
<span id="L554"><span class="lineNum">     554</span>              :   at::Tensor &amp; acos_() const;</span>
<span id="L555"><span class="lineNum">     555</span>              :   at::Tensor arccos() const;</span>
<span id="L556"><span class="lineNum">     556</span>              :   at::Tensor &amp; arccos_() const;</span>
<span id="L557"><span class="lineNum">     557</span>              :   at::Tensor add(const at::Tensor &amp; other, const at::Scalar &amp; alpha=1) const;</span>
<span id="L558"><span class="lineNum">     558</span>              :   at::Tensor &amp; add_(const at::Tensor &amp; other, const at::Scalar &amp; alpha=1) const;</span>
<span id="L559"><span class="lineNum">     559</span>              :   at::Tensor add(const at::Scalar &amp; other, const at::Scalar &amp; alpha=1) const;</span>
<span id="L560"><span class="lineNum">     560</span>              :   at::Tensor &amp; add_(const at::Scalar &amp; other, const at::Scalar &amp; alpha=1) const;</span>
<span id="L561"><span class="lineNum">     561</span>              :   at::Tensor addmv(const at::Tensor &amp; mat, const at::Tensor &amp; vec, const at::Scalar &amp; beta=1, const at::Scalar &amp; alpha=1) const;</span>
<span id="L562"><span class="lineNum">     562</span>              :   at::Tensor &amp; addmv_(const at::Tensor &amp; mat, const at::Tensor &amp; vec, const at::Scalar &amp; beta=1, const at::Scalar &amp; alpha=1) const;</span>
<span id="L563"><span class="lineNum">     563</span>              :   at::Tensor addr(const at::Tensor &amp; vec1, const at::Tensor &amp; vec2, const at::Scalar &amp; beta=1, const at::Scalar &amp; alpha=1) const;</span>
<span id="L564"><span class="lineNum">     564</span>              :   at::Tensor &amp; addr_(const at::Tensor &amp; vec1, const at::Tensor &amp; vec2, const at::Scalar &amp; beta=1, const at::Scalar &amp; alpha=1) const;</span>
<span id="L565"><span class="lineNum">     565</span>              :   at::Tensor _is_all_true() const;</span>
<span id="L566"><span class="lineNum">     566</span>              :   at::Tensor _is_any_true() const;</span>
<span id="L567"><span class="lineNum">     567</span>              :   at::Tensor all(int64_t dim, bool keepdim=false) const;</span>
<span id="L568"><span class="lineNum">     568</span>              :   at::Tensor all(at::OptionalIntArrayRef dim, bool keepdim=false) const;</span>
<span id="L569"><span class="lineNum">     569</span>              :   at::Tensor all(at::Dimname dim, bool keepdim=false) const;</span>
<span id="L570"><span class="lineNum">     570</span>              :   bool allclose(const at::Tensor &amp; other, double rtol=1e-05, double atol=1e-08, bool equal_nan=false) const;</span>
<span id="L571"><span class="lineNum">     571</span>              :   at::Tensor any(int64_t dim, bool keepdim=false) const;</span>
<span id="L572"><span class="lineNum">     572</span>              :   at::Tensor any(at::OptionalIntArrayRef dim, bool keepdim=false) const;</span>
<span id="L573"><span class="lineNum">     573</span>              :   at::Tensor any(at::Dimname dim, bool keepdim=false) const;</span>
<span id="L574"><span class="lineNum">     574</span>              :   at::Tensor argmax(::std::optional&lt;int64_t&gt; dim=::std::nullopt, bool keepdim=false) const;</span>
<span id="L575"><span class="lineNum">     575</span>              :   at::Tensor argmin(::std::optional&lt;int64_t&gt; dim=::std::nullopt, bool keepdim=false) const;</span>
<span id="L576"><span class="lineNum">     576</span>              :   at::Tensor acosh() const;</span>
<span id="L577"><span class="lineNum">     577</span>              :   at::Tensor &amp; acosh_() const;</span>
<span id="L578"><span class="lineNum">     578</span>              :   at::Tensor arccosh() const;</span>
<span id="L579"><span class="lineNum">     579</span>              :   at::Tensor &amp; arccosh_() const;</span>
<span id="L580"><span class="lineNum">     580</span>              :   at::Tensor asinh() const;</span>
<span id="L581"><span class="lineNum">     581</span>              :   at::Tensor &amp; asinh_() const;</span>
<span id="L582"><span class="lineNum">     582</span>              :   at::Tensor arcsinh() const;</span>
<span id="L583"><span class="lineNum">     583</span>              :   at::Tensor &amp; arcsinh_() const;</span>
<span id="L584"><span class="lineNum">     584</span>              :   at::Tensor atanh() const;</span>
<span id="L585"><span class="lineNum">     585</span>              :   at::Tensor &amp; atanh_() const;</span>
<span id="L586"><span class="lineNum">     586</span>              :   at::Tensor arctanh() const;</span>
<span id="L587"><span class="lineNum">     587</span>              :   at::Tensor &amp; arctanh_() const;</span>
<span id="L588"><span class="lineNum">     588</span>              :   at::Tensor as_strided(at::IntArrayRef size, at::IntArrayRef stride, ::std::optional&lt;int64_t&gt; storage_offset=::std::nullopt) const;</span>
<span id="L589"><span class="lineNum">     589</span>              :   at::Tensor as_strided_symint(c10::SymIntArrayRef size, c10::SymIntArrayRef stride, ::std::optional&lt;c10::SymInt&gt; storage_offset=::std::nullopt) const;</span>
<span id="L590"><span class="lineNum">     590</span>              :   const at::Tensor &amp; as_strided_(at::IntArrayRef size, at::IntArrayRef stride, ::std::optional&lt;int64_t&gt; storage_offset=::std::nullopt) const;</span>
<span id="L591"><span class="lineNum">     591</span>              :   const at::Tensor &amp; as_strided__symint(c10::SymIntArrayRef size, c10::SymIntArrayRef stride, ::std::optional&lt;c10::SymInt&gt; storage_offset=::std::nullopt) const;</span>
<span id="L592"><span class="lineNum">     592</span>              :   at::Tensor asin() const;</span>
<span id="L593"><span class="lineNum">     593</span>              :   at::Tensor &amp; asin_() const;</span>
<span id="L594"><span class="lineNum">     594</span>              :   at::Tensor arcsin() const;</span>
<span id="L595"><span class="lineNum">     595</span>              :   at::Tensor &amp; arcsin_() const;</span>
<span id="L596"><span class="lineNum">     596</span>              :   at::Tensor atan() const;</span>
<span id="L597"><span class="lineNum">     597</span>              :   at::Tensor &amp; atan_() const;</span>
<span id="L598"><span class="lineNum">     598</span>              :   at::Tensor arctan() const;</span>
<span id="L599"><span class="lineNum">     599</span>              :   at::Tensor &amp; arctan_() const;</span>
<span id="L600"><span class="lineNum">     600</span>              :   at::Tensor baddbmm(const at::Tensor &amp; batch1, const at::Tensor &amp; batch2, const at::Scalar &amp; beta=1, const at::Scalar &amp; alpha=1) const;</span>
<span id="L601"><span class="lineNum">     601</span>              :   at::Tensor &amp; baddbmm_(const at::Tensor &amp; batch1, const at::Tensor &amp; batch2, const at::Scalar &amp; beta=1, const at::Scalar &amp; alpha=1) const;</span>
<span id="L602"><span class="lineNum">     602</span>              :   at::Tensor bernoulli(::std::optional&lt;at::Generator&gt; generator=::std::nullopt) const;</span>
<span id="L603"><span class="lineNum">     603</span>              :   at::Tensor &amp; bernoulli_(const at::Tensor &amp; p, ::std::optional&lt;at::Generator&gt; generator=::std::nullopt) const;</span>
<span id="L604"><span class="lineNum">     604</span>              :   at::Tensor &amp; bernoulli_(double p=0.5, ::std::optional&lt;at::Generator&gt; generator=::std::nullopt) const;</span>
<span id="L605"><span class="lineNum">     605</span>              :   at::Tensor bernoulli(double p, ::std::optional&lt;at::Generator&gt; generator=::std::nullopt) const;</span>
<span id="L606"><span class="lineNum">     606</span>              :   at::Tensor bincount(const ::std::optional&lt;at::Tensor&gt; &amp; weights={}, int64_t minlength=0) const;</span>
<span id="L607"><span class="lineNum">     607</span>              :   at::Tensor bitwise_not() const;</span>
<span id="L608"><span class="lineNum">     608</span>              :   at::Tensor &amp; bitwise_not_() const;</span>
<span id="L609"><span class="lineNum">     609</span>              :   at::Tensor copysign(const at::Tensor &amp; other) const;</span>
<span id="L610"><span class="lineNum">     610</span>              :   at::Tensor &amp; copysign_(const at::Tensor &amp; other) const;</span>
<span id="L611"><span class="lineNum">     611</span>              :   at::Tensor copysign(const at::Scalar &amp; other) const;</span>
<span id="L612"><span class="lineNum">     612</span>              :   at::Tensor &amp; copysign_(const at::Scalar &amp; other) const;</span>
<span id="L613"><span class="lineNum">     613</span>              :   at::Tensor _lazy_clone() const;</span>
<span id="L614"><span class="lineNum">     614</span>              :   at::Tensor logical_not() const;</span>
<span id="L615"><span class="lineNum">     615</span>              :   at::Tensor &amp; logical_not_() const;</span>
<span id="L616"><span class="lineNum">     616</span>              :   at::Tensor logical_xor(const at::Tensor &amp; other) const;</span>
<span id="L617"><span class="lineNum">     617</span>              :   at::Tensor &amp; logical_xor_(const at::Tensor &amp; other) const;</span>
<span id="L618"><span class="lineNum">     618</span>              :   at::Tensor logical_and(const at::Tensor &amp; other) const;</span>
<span id="L619"><span class="lineNum">     619</span>              :   at::Tensor &amp; logical_and_(const at::Tensor &amp; other) const;</span>
<span id="L620"><span class="lineNum">     620</span>              :   at::Tensor logical_or(const at::Tensor &amp; other) const;</span>
<span id="L621"><span class="lineNum">     621</span>              :   at::Tensor &amp; logical_or_(const at::Tensor &amp; other) const;</span>
<span id="L622"><span class="lineNum">     622</span>              :   at::Tensor bmm(const at::Tensor &amp; mat2) const;</span>
<span id="L623"><span class="lineNum">     623</span>              :   at::Tensor broadcast_to(at::IntArrayRef size) const;</span>
<span id="L624"><span class="lineNum">     624</span>              :   at::Tensor broadcast_to_symint(c10::SymIntArrayRef size) const;</span>
<span id="L625"><span class="lineNum">     625</span>              :   at::Tensor ceil() const;</span>
<span id="L626"><span class="lineNum">     626</span>              :   at::Tensor &amp; ceil_() const;</span>
<span id="L627"><span class="lineNum">     627</span>              :   ::std::vector&lt;at::Tensor&gt; unsafe_chunk(int64_t chunks, int64_t dim=0) const;</span>
<span id="L628"><span class="lineNum">     628</span>              :   ::std::vector&lt;at::Tensor&gt; chunk(int64_t chunks, int64_t dim=0) const;</span>
<span id="L629"><span class="lineNum">     629</span>              :   ::std::vector&lt;at::Tensor&gt; tensor_split(int64_t sections, int64_t dim=0) const;</span>
<span id="L630"><span class="lineNum">     630</span>              :   ::std::vector&lt;at::Tensor&gt; tensor_split_symint(c10::SymInt sections, int64_t dim=0) const;</span>
<span id="L631"><span class="lineNum">     631</span>              :   ::std::vector&lt;at::Tensor&gt; tensor_split(at::IntArrayRef indices, int64_t dim=0) const;</span>
<span id="L632"><span class="lineNum">     632</span>              :   ::std::vector&lt;at::Tensor&gt; tensor_split_symint(c10::SymIntArrayRef indices, int64_t dim=0) const;</span>
<span id="L633"><span class="lineNum">     633</span>              :   ::std::vector&lt;at::Tensor&gt; tensor_split(const at::Tensor &amp; tensor_indices_or_sections, int64_t dim=0) const;</span>
<span id="L634"><span class="lineNum">     634</span>              :   at::Tensor clamp(const ::std::optional&lt;at::Scalar&gt; &amp; min, const ::std::optional&lt;at::Scalar&gt; &amp; max=::std::nullopt) const;</span>
<span id="L635"><span class="lineNum">     635</span>              :   at::Tensor clamp(const ::std::optional&lt;at::Tensor&gt; &amp; min={}, const ::std::optional&lt;at::Tensor&gt; &amp; max={}) const;</span>
<span id="L636"><span class="lineNum">     636</span>              :   at::Tensor &amp; clamp_(const ::std::optional&lt;at::Scalar&gt; &amp; min, const ::std::optional&lt;at::Scalar&gt; &amp; max=::std::nullopt) const;</span>
<span id="L637"><span class="lineNum">     637</span>              :   at::Tensor &amp; clamp_(const ::std::optional&lt;at::Tensor&gt; &amp; min={}, const ::std::optional&lt;at::Tensor&gt; &amp; max={}) const;</span>
<span id="L638"><span class="lineNum">     638</span>              :   at::Tensor clamp_max(const at::Scalar &amp; max) const;</span>
<span id="L639"><span class="lineNum">     639</span>              :   at::Tensor clamp_max(const at::Tensor &amp; max) const;</span>
<span id="L640"><span class="lineNum">     640</span>              :   at::Tensor &amp; clamp_max_(const at::Scalar &amp; max) const;</span>
<span id="L641"><span class="lineNum">     641</span>              :   at::Tensor &amp; clamp_max_(const at::Tensor &amp; max) const;</span>
<span id="L642"><span class="lineNum">     642</span>              :   at::Tensor clamp_min(const at::Scalar &amp; min) const;</span>
<span id="L643"><span class="lineNum">     643</span>              :   at::Tensor clamp_min(const at::Tensor &amp; min) const;</span>
<span id="L644"><span class="lineNum">     644</span>              :   at::Tensor &amp; clamp_min_(const at::Scalar &amp; min) const;</span>
<span id="L645"><span class="lineNum">     645</span>              :   at::Tensor &amp; clamp_min_(const at::Tensor &amp; min) const;</span>
<span id="L646"><span class="lineNum">     646</span>              :   at::Tensor clip(const ::std::optional&lt;at::Scalar&gt; &amp; min, const ::std::optional&lt;at::Scalar&gt; &amp; max=::std::nullopt) const;</span>
<span id="L647"><span class="lineNum">     647</span>              :   at::Tensor clip(const ::std::optional&lt;at::Tensor&gt; &amp; min={}, const ::std::optional&lt;at::Tensor&gt; &amp; max={}) const;</span>
<span id="L648"><span class="lineNum">     648</span>              :   at::Tensor &amp; clip_(const ::std::optional&lt;at::Scalar&gt; &amp; min, const ::std::optional&lt;at::Scalar&gt; &amp; max=::std::nullopt) const;</span>
<span id="L649"><span class="lineNum">     649</span>              :   at::Tensor &amp; clip_(const ::std::optional&lt;at::Tensor&gt; &amp; min={}, const ::std::optional&lt;at::Tensor&gt; &amp; max={}) const;</span>
<span id="L650"><span class="lineNum">     650</span>              :   at::Tensor __dispatch_contiguous(at::MemoryFormat memory_format=c10::MemoryFormat::Contiguous) const;</span>
<span id="L651"><span class="lineNum">     651</span>              :   at::Tensor &amp; copy_(const at::Tensor &amp; src, bool non_blocking=false) const;</span>
<span id="L652"><span class="lineNum">     652</span>              :   at::Tensor cos() const;</span>
<span id="L653"><span class="lineNum">     653</span>              :   at::Tensor &amp; cos_() const;</span>
<span id="L654"><span class="lineNum">     654</span>              :   at::Tensor cosh() const;</span>
<span id="L655"><span class="lineNum">     655</span>              :   at::Tensor &amp; cosh_() const;</span>
<span id="L656"><span class="lineNum">     656</span>              :   at::Tensor count_nonzero(at::IntArrayRef dim) const;</span>
<span id="L657"><span class="lineNum">     657</span>              :   at::Tensor count_nonzero(::std::optional&lt;int64_t&gt; dim=::std::nullopt) const;</span>
<span id="L658"><span class="lineNum">     658</span>              :   at::Tensor cov(int64_t correction=1, const ::std::optional&lt;at::Tensor&gt; &amp; fweights={}, const ::std::optional&lt;at::Tensor&gt; &amp; aweights={}) const;</span>
<span id="L659"><span class="lineNum">     659</span>              :   at::Tensor corrcoef() const;</span>
<span id="L660"><span class="lineNum">     660</span>              :   ::std::tuple&lt;at::Tensor,at::Tensor&gt; cummax(int64_t dim) const;</span>
<span id="L661"><span class="lineNum">     661</span>              :   ::std::tuple&lt;at::Tensor,at::Tensor&gt; cummax(at::Dimname dim) const;</span>
<span id="L662"><span class="lineNum">     662</span>              :   ::std::tuple&lt;at::Tensor,at::Tensor&gt; cummin(int64_t dim) const;</span>
<span id="L663"><span class="lineNum">     663</span>              :   ::std::tuple&lt;at::Tensor,at::Tensor&gt; cummin(at::Dimname dim) const;</span>
<span id="L664"><span class="lineNum">     664</span>              :   at::Tensor cumprod(int64_t dim, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) const;</span>
<span id="L665"><span class="lineNum">     665</span>              :   at::Tensor &amp; cumprod_(int64_t dim, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) const;</span>
<span id="L666"><span class="lineNum">     666</span>              :   at::Tensor cumprod(at::Dimname dim, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) const;</span>
<span id="L667"><span class="lineNum">     667</span>              :   at::Tensor &amp; cumprod_(at::Dimname dim, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) const;</span>
<span id="L668"><span class="lineNum">     668</span>              :   at::Tensor cumsum(int64_t dim, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) const;</span>
<span id="L669"><span class="lineNum">     669</span>              :   at::Tensor &amp; cumsum_(int64_t dim, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) const;</span>
<span id="L670"><span class="lineNum">     670</span>              :   at::Tensor cumsum(at::Dimname dim, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) const;</span>
<span id="L671"><span class="lineNum">     671</span>              :   at::Tensor &amp; cumsum_(at::Dimname dim, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) const;</span>
<span id="L672"><span class="lineNum">     672</span>              :   at::Tensor diag_embed(int64_t offset=0, int64_t dim1=-2, int64_t dim2=-1) const;</span>
<span id="L673"><span class="lineNum">     673</span>              :   at::Tensor diagflat(int64_t offset=0) const;</span>
<span id="L674"><span class="lineNum">     674</span>              :   at::Tensor diagonal(int64_t offset=0, int64_t dim1=0, int64_t dim2=1) const;</span>
<span id="L675"><span class="lineNum">     675</span>              :   at::Tensor diagonal(at::Dimname outdim, at::Dimname dim1, at::Dimname dim2, int64_t offset=0) const;</span>
<span id="L676"><span class="lineNum">     676</span>              :   at::Tensor &amp; fill_diagonal_(const at::Scalar &amp; fill_value, bool wrap=false) const;</span>
<span id="L677"><span class="lineNum">     677</span>              :   at::Tensor diff(int64_t n=1, int64_t dim=-1, const ::std::optional&lt;at::Tensor&gt; &amp; prepend={}, const ::std::optional&lt;at::Tensor&gt; &amp; append={}) const;</span>
<span id="L678"><span class="lineNum">     678</span>              :   at::Tensor div(const at::Tensor &amp; other) const;</span>
<span id="L679"><span class="lineNum">     679</span>              :   at::Tensor &amp; div_(const at::Tensor &amp; other) const;</span>
<span id="L680"><span class="lineNum">     680</span>              :   at::Tensor div(const at::Tensor &amp; other, ::std::optional&lt;c10::string_view&gt; rounding_mode) const;</span>
<span id="L681"><span class="lineNum">     681</span>              :   at::Tensor &amp; div_(const at::Tensor &amp; other, ::std::optional&lt;c10::string_view&gt; rounding_mode) const;</span>
<span id="L682"><span class="lineNum">     682</span>              :   at::Tensor div(const at::Scalar &amp; other) const;</span>
<span id="L683"><span class="lineNum">     683</span>              :   at::Tensor &amp; div_(const at::Scalar &amp; other) const;</span>
<span id="L684"><span class="lineNum">     684</span>              :   at::Tensor div(const at::Scalar &amp; other, ::std::optional&lt;c10::string_view&gt; rounding_mode) const;</span>
<span id="L685"><span class="lineNum">     685</span>              :   at::Tensor &amp; div_(const at::Scalar &amp; other, ::std::optional&lt;c10::string_view&gt; rounding_mode) const;</span>
<span id="L686"><span class="lineNum">     686</span>              :   at::Tensor divide(const at::Tensor &amp; other) const;</span>
<span id="L687"><span class="lineNum">     687</span>              :   at::Tensor &amp; divide_(const at::Tensor &amp; other) const;</span>
<span id="L688"><span class="lineNum">     688</span>              :   at::Tensor divide(const at::Scalar &amp; other) const;</span>
<span id="L689"><span class="lineNum">     689</span>              :   at::Tensor &amp; divide_(const at::Scalar &amp; other) const;</span>
<span id="L690"><span class="lineNum">     690</span>              :   at::Tensor divide(const at::Tensor &amp; other, ::std::optional&lt;c10::string_view&gt; rounding_mode) const;</span>
<span id="L691"><span class="lineNum">     691</span>              :   at::Tensor &amp; divide_(const at::Tensor &amp; other, ::std::optional&lt;c10::string_view&gt; rounding_mode) const;</span>
<span id="L692"><span class="lineNum">     692</span>              :   at::Tensor divide(const at::Scalar &amp; other, ::std::optional&lt;c10::string_view&gt; rounding_mode) const;</span>
<span id="L693"><span class="lineNum">     693</span>              :   at::Tensor &amp; divide_(const at::Scalar &amp; other, ::std::optional&lt;c10::string_view&gt; rounding_mode) const;</span>
<span id="L694"><span class="lineNum">     694</span>              :   at::Tensor true_divide(const at::Tensor &amp; other) const;</span>
<span id="L695"><span class="lineNum">     695</span>              :   at::Tensor &amp; true_divide_(const at::Tensor &amp; other) const;</span>
<span id="L696"><span class="lineNum">     696</span>              :   at::Tensor true_divide(const at::Scalar &amp; other) const;</span>
<span id="L697"><span class="lineNum">     697</span>              :   at::Tensor &amp; true_divide_(const at::Scalar &amp; other) const;</span>
<span id="L698"><span class="lineNum">     698</span>              :   at::Tensor dot(const at::Tensor &amp; tensor) const;</span>
<span id="L699"><span class="lineNum">     699</span>              :   at::Tensor vdot(const at::Tensor &amp; other) const;</span>
<span id="L700"><span class="lineNum">     700</span>              :   at::Tensor new_empty(at::IntArrayRef size, at::TensorOptions options={}) const;</span>
<span id="L701"><span class="lineNum">     701</span>              :   at::Tensor new_empty(at::IntArrayRef size, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;bool&gt; pin_memory) const;</span>
<span id="L702"><span class="lineNum">     702</span>              :   at::Tensor new_empty_symint(c10::SymIntArrayRef size, at::TensorOptions options={}) const;</span>
<span id="L703"><span class="lineNum">     703</span>              :   at::Tensor new_empty_symint(c10::SymIntArrayRef size, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;bool&gt; pin_memory) const;</span>
<span id="L704"><span class="lineNum">     704</span>              :   at::Tensor new_empty_strided(at::IntArrayRef size, at::IntArrayRef stride, at::TensorOptions options={}) const;</span>
<span id="L705"><span class="lineNum">     705</span>              :   at::Tensor new_empty_strided(at::IntArrayRef size, at::IntArrayRef stride, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;bool&gt; pin_memory) const;</span>
<span id="L706"><span class="lineNum">     706</span>              :   at::Tensor new_empty_strided_symint(c10::SymIntArrayRef size, c10::SymIntArrayRef stride, at::TensorOptions options={}) const;</span>
<span id="L707"><span class="lineNum">     707</span>              :   at::Tensor new_empty_strided_symint(c10::SymIntArrayRef size, c10::SymIntArrayRef stride, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;bool&gt; pin_memory) const;</span>
<span id="L708"><span class="lineNum">     708</span>              :   at::Tensor new_full(at::IntArrayRef size, const at::Scalar &amp; fill_value, at::TensorOptions options={}) const;</span>
<span id="L709"><span class="lineNum">     709</span>              :   at::Tensor new_full(at::IntArrayRef size, const at::Scalar &amp; fill_value, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;bool&gt; pin_memory) const;</span>
<span id="L710"><span class="lineNum">     710</span>              :   at::Tensor new_full_symint(c10::SymIntArrayRef size, const at::Scalar &amp; fill_value, at::TensorOptions options={}) const;</span>
<span id="L711"><span class="lineNum">     711</span>              :   at::Tensor new_full_symint(c10::SymIntArrayRef size, const at::Scalar &amp; fill_value, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;bool&gt; pin_memory) const;</span>
<span id="L712"><span class="lineNum">     712</span>              :   at::Tensor new_zeros(at::IntArrayRef size, at::TensorOptions options={}) const;</span>
<span id="L713"><span class="lineNum">     713</span>              :   at::Tensor new_zeros(at::IntArrayRef size, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;bool&gt; pin_memory) const;</span>
<span id="L714"><span class="lineNum">     714</span>              :   at::Tensor new_zeros_symint(c10::SymIntArrayRef size, at::TensorOptions options={}) const;</span>
<span id="L715"><span class="lineNum">     715</span>              :   at::Tensor new_zeros_symint(c10::SymIntArrayRef size, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;bool&gt; pin_memory) const;</span>
<span id="L716"><span class="lineNum">     716</span>              :   at::Tensor new_ones(at::IntArrayRef size, at::TensorOptions options={}) const;</span>
<span id="L717"><span class="lineNum">     717</span>              :   at::Tensor new_ones(at::IntArrayRef size, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;bool&gt; pin_memory) const;</span>
<span id="L718"><span class="lineNum">     718</span>              :   at::Tensor new_ones_symint(c10::SymIntArrayRef size, at::TensorOptions options={}) const;</span>
<span id="L719"><span class="lineNum">     719</span>              :   at::Tensor new_ones_symint(c10::SymIntArrayRef size, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;bool&gt; pin_memory) const;</span>
<span id="L720"><span class="lineNum">     720</span>              :   const at::Tensor &amp; resize_(at::IntArrayRef size, ::std::optional&lt;at::MemoryFormat&gt; memory_format=::std::nullopt) const;</span>
<span id="L721"><span class="lineNum">     721</span>              :   const at::Tensor &amp; resize__symint(c10::SymIntArrayRef size, ::std::optional&lt;at::MemoryFormat&gt; memory_format=::std::nullopt) const;</span>
<span id="L722"><span class="lineNum">     722</span>              :   at::Tensor erf() const;</span>
<span id="L723"><span class="lineNum">     723</span>              :   at::Tensor &amp; erf_() const;</span>
<span id="L724"><span class="lineNum">     724</span>              :   at::Tensor erfc() const;</span>
<span id="L725"><span class="lineNum">     725</span>              :   at::Tensor &amp; erfc_() const;</span>
<span id="L726"><span class="lineNum">     726</span>              :   at::Tensor exp() const;</span>
<span id="L727"><span class="lineNum">     727</span>              :   at::Tensor &amp; exp_() const;</span>
<span id="L728"><span class="lineNum">     728</span>              :   at::Tensor exp2() const;</span>
<span id="L729"><span class="lineNum">     729</span>              :   at::Tensor &amp; exp2_() const;</span>
<span id="L730"><span class="lineNum">     730</span>              :   at::Tensor expm1() const;</span>
<span id="L731"><span class="lineNum">     731</span>              :   at::Tensor &amp; expm1_() const;</span>
<span id="L732"><span class="lineNum">     732</span>              :   at::Tensor expand(at::IntArrayRef size, bool implicit=false) const;</span>
<span id="L733"><span class="lineNum">     733</span>              :   at::Tensor expand_symint(c10::SymIntArrayRef size, bool implicit=false) const;</span>
<span id="L734"><span class="lineNum">     734</span>              :   at::Tensor expand_as(const at::Tensor &amp; other) const;</span>
<span id="L735"><span class="lineNum">     735</span>              :   at::Tensor flatten(int64_t start_dim=0, int64_t end_dim=-1) const;</span>
<span id="L736"><span class="lineNum">     736</span>              :   at::Tensor flatten(int64_t start_dim, int64_t end_dim, at::Dimname out_dim) const;</span>
<span id="L737"><span class="lineNum">     737</span>              :   at::Tensor flatten(at::Dimname start_dim, at::Dimname end_dim, at::Dimname out_dim) const;</span>
<span id="L738"><span class="lineNum">     738</span>              :   at::Tensor flatten(at::DimnameList dims, at::Dimname out_dim) const;</span>
<span id="L739"><span class="lineNum">     739</span>              :   at::Tensor unflatten(int64_t dim, at::IntArrayRef sizes) const;</span>
<span id="L740"><span class="lineNum">     740</span>              :   at::Tensor unflatten_symint(int64_t dim, c10::SymIntArrayRef sizes) const;</span>
<span id="L741"><span class="lineNum">     741</span>              :   at::Tensor unflatten(at::Dimname dim, at::IntArrayRef sizes, at::DimnameList names) const;</span>
<span id="L742"><span class="lineNum">     742</span>              :   at::Tensor unflatten_symint(at::Dimname dim, c10::SymIntArrayRef sizes, at::DimnameList names) const;</span>
<span id="L743"><span class="lineNum">     743</span>              :   at::Tensor &amp; fill_(const at::Scalar &amp; value) const;</span>
<span id="L744"><span class="lineNum">     744</span>              :   at::Tensor &amp; fill_(const at::Tensor &amp; value) const;</span>
<span id="L745"><span class="lineNum">     745</span>              :   at::Tensor floor() const;</span>
<span id="L746"><span class="lineNum">     746</span>              :   at::Tensor &amp; floor_() const;</span>
<span id="L747"><span class="lineNum">     747</span>              :   at::Tensor floor_divide(const at::Tensor &amp; other) const;</span>
<span id="L748"><span class="lineNum">     748</span>              :   at::Tensor &amp; floor_divide_(const at::Tensor &amp; other) const;</span>
<span id="L749"><span class="lineNum">     749</span>              :   at::Tensor floor_divide(const at::Scalar &amp; other) const;</span>
<span id="L750"><span class="lineNum">     750</span>              :   at::Tensor &amp; floor_divide_(const at::Scalar &amp; other) const;</span>
<span id="L751"><span class="lineNum">     751</span>              :   at::Tensor frac() const;</span>
<span id="L752"><span class="lineNum">     752</span>              :   at::Tensor &amp; frac_() const;</span>
<span id="L753"><span class="lineNum">     753</span>              :   at::Tensor gcd(const at::Tensor &amp; other) const;</span>
<span id="L754"><span class="lineNum">     754</span>              :   at::Tensor &amp; gcd_(const at::Tensor &amp; other) const;</span>
<span id="L755"><span class="lineNum">     755</span>              :   at::Tensor lcm(const at::Tensor &amp; other) const;</span>
<span id="L756"><span class="lineNum">     756</span>              :   at::Tensor &amp; lcm_(const at::Tensor &amp; other) const;</span>
<span id="L757"><span class="lineNum">     757</span>              :   at::Tensor index(const c10::List&lt;::std::optional&lt;at::Tensor&gt;&gt; &amp; indices) const;</span>
<span id="L758"><span class="lineNum">     758</span>              :   at::Tensor &amp; index_copy_(int64_t dim, const at::Tensor &amp; index, const at::Tensor &amp; source) const;</span>
<span id="L759"><span class="lineNum">     759</span>              :   at::Tensor index_copy(int64_t dim, const at::Tensor &amp; index, const at::Tensor &amp; source) const;</span>
<span id="L760"><span class="lineNum">     760</span>              :   at::Tensor &amp; index_copy_(at::Dimname dim, const at::Tensor &amp; index, const at::Tensor &amp; source) const;</span>
<span id="L761"><span class="lineNum">     761</span>              :   at::Tensor index_copy(at::Dimname dim, const at::Tensor &amp; index, const at::Tensor &amp; source) const;</span>
<span id="L762"><span class="lineNum">     762</span>              :   at::Tensor &amp; index_put_(const c10::List&lt;::std::optional&lt;at::Tensor&gt;&gt; &amp; indices, const at::Tensor &amp; values, bool accumulate=false) const;</span>
<span id="L763"><span class="lineNum">     763</span>              :   at::Tensor index_put(const c10::List&lt;::std::optional&lt;at::Tensor&gt;&gt; &amp; indices, const at::Tensor &amp; values, bool accumulate=false) const;</span>
<span id="L764"><span class="lineNum">     764</span>              :   at::Tensor isclose(const at::Tensor &amp; other, double rtol=1e-05, double atol=1e-08, bool equal_nan=false) const;</span>
<span id="L765"><span class="lineNum">     765</span>              :   at::Tensor isnan() const;</span>
<span id="L766"><span class="lineNum">     766</span>              :   bool is_distributed() const;</span>
<span id="L767"><span class="lineNum">     767</span>              :   bool __dispatch_is_floating_point() const;</span>
<span id="L768"><span class="lineNum">     768</span>              :   bool __dispatch_is_complex() const;</span>
<span id="L769"><span class="lineNum">     769</span>              :   bool __dispatch_is_conj() const;</span>
<span id="L770"><span class="lineNum">     770</span>              :   bool __dispatch__is_zerotensor() const;</span>
<span id="L771"><span class="lineNum">     771</span>              :   bool __dispatch_is_neg() const;</span>
<span id="L772"><span class="lineNum">     772</span>              :   at::Tensor isreal() const;</span>
<span id="L773"><span class="lineNum">     773</span>              :   bool is_nonzero() const;</span>
<span id="L774"><span class="lineNum">     774</span>              :   bool is_same_size(const at::Tensor &amp; other) const;</span>
<span id="L775"><span class="lineNum">     775</span>              :   bool __dispatch_is_signed() const;</span>
<span id="L776"><span class="lineNum">     776</span>              :   bool __dispatch_is_inference() const;</span>
<span id="L777"><span class="lineNum">     777</span>              :   at::Tensor kron(const at::Tensor &amp; other) const;</span>
<span id="L778"><span class="lineNum">     778</span>              :   ::std::tuple&lt;at::Tensor,at::Tensor&gt; kthvalue(int64_t k, int64_t dim=-1, bool keepdim=false) const;</span>
<span id="L779"><span class="lineNum">     779</span>              :   ::std::tuple&lt;at::Tensor,at::Tensor&gt; kthvalue(int64_t k, at::Dimname dim, bool keepdim=false) const;</span>
<span id="L780"><span class="lineNum">     780</span>              :   at::Tensor nan_to_num(::std::optional&lt;double&gt; nan=::std::nullopt, ::std::optional&lt;double&gt; posinf=::std::nullopt, ::std::optional&lt;double&gt; neginf=::std::nullopt) const;</span>
<span id="L781"><span class="lineNum">     781</span>              :   at::Tensor &amp; nan_to_num_(::std::optional&lt;double&gt; nan=::std::nullopt, ::std::optional&lt;double&gt; posinf=::std::nullopt, ::std::optional&lt;double&gt; neginf=::std::nullopt) const;</span>
<span id="L782"><span class="lineNum">     782</span>              :   at::Tensor ldexp(const at::Tensor &amp; other) const;</span>
<span id="L783"><span class="lineNum">     783</span>              :   at::Tensor &amp; ldexp_(const at::Tensor &amp; other) const;</span>
<span id="L784"><span class="lineNum">     784</span>              :   at::Tensor log() const;</span>
<span id="L785"><span class="lineNum">     785</span>              :   at::Tensor &amp; log_() const;</span>
<span id="L786"><span class="lineNum">     786</span>              :   at::Tensor log10() const;</span>
<span id="L787"><span class="lineNum">     787</span>              :   at::Tensor &amp; log10_() const;</span>
<span id="L788"><span class="lineNum">     788</span>              :   at::Tensor log1p() const;</span>
<span id="L789"><span class="lineNum">     789</span>              :   at::Tensor &amp; log1p_() const;</span>
<span id="L790"><span class="lineNum">     790</span>              :   at::Tensor log2() const;</span>
<span id="L791"><span class="lineNum">     791</span>              :   at::Tensor &amp; log2_() const;</span>
<span id="L792"><span class="lineNum">     792</span>              :   at::Tensor logaddexp(const at::Tensor &amp; other) const;</span>
<span id="L793"><span class="lineNum">     793</span>              :   at::Tensor logaddexp2(const at::Tensor &amp; other) const;</span>
<span id="L794"><span class="lineNum">     794</span>              :   at::Tensor xlogy(const at::Tensor &amp; other) const;</span>
<span id="L795"><span class="lineNum">     795</span>              :   at::Tensor xlogy(const at::Scalar &amp; other) const;</span>
<span id="L796"><span class="lineNum">     796</span>              :   at::Tensor &amp; xlogy_(const at::Tensor &amp; other) const;</span>
<span id="L797"><span class="lineNum">     797</span>              :   at::Tensor &amp; xlogy_(const at::Scalar &amp; other) const;</span>
<span id="L798"><span class="lineNum">     798</span>              :   at::Tensor log_softmax(int64_t dim, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) const;</span>
<span id="L799"><span class="lineNum">     799</span>              :   at::Tensor log_softmax(at::Dimname dim, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) const;</span>
<span id="L800"><span class="lineNum">     800</span>              :   at::Tensor logcumsumexp(int64_t dim) const;</span>
<span id="L801"><span class="lineNum">     801</span>              :   at::Tensor logcumsumexp(at::Dimname dim) const;</span>
<span id="L802"><span class="lineNum">     802</span>              :   at::Tensor logsumexp(at::IntArrayRef dim, bool keepdim=false) const;</span>
<span id="L803"><span class="lineNum">     803</span>              :   at::Tensor logsumexp(at::DimnameList dim, bool keepdim=false) const;</span>
<span id="L804"><span class="lineNum">     804</span>              :   at::Tensor matmul(const at::Tensor &amp; other) const;</span>
<span id="L805"><span class="lineNum">     805</span>              :   at::Tensor matrix_power(int64_t n) const;</span>
<span id="L806"><span class="lineNum">     806</span>              :   at::Tensor matrix_exp() const;</span>
<span id="L807"><span class="lineNum">     807</span>              :   ::std::tuple&lt;at::Tensor,at::Tensor&gt; aminmax(::std::optional&lt;int64_t&gt; dim=::std::nullopt, bool keepdim=false) const;</span>
<span id="L808"><span class="lineNum">     808</span>              :   ::std::tuple&lt;at::Tensor,at::Tensor&gt; max(int64_t dim, bool keepdim=false) const;</span>
<span id="L809"><span class="lineNum">     809</span>              :   ::std::tuple&lt;at::Tensor,at::Tensor&gt; max(at::Dimname dim, bool keepdim=false) const;</span>
<span id="L810"><span class="lineNum">     810</span>              :   at::Tensor amax(at::IntArrayRef dim={}, bool keepdim=false) const;</span>
<span id="L811"><span class="lineNum">     811</span>              :   at::Tensor mean(::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) const;</span>
<span id="L812"><span class="lineNum">     812</span>              :   at::Tensor mean(at::OptionalIntArrayRef dim, bool keepdim=false, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) const;</span>
<span id="L813"><span class="lineNum">     813</span>              :   at::Tensor mean(at::DimnameList dim, bool keepdim=false, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) const;</span>
<span id="L814"><span class="lineNum">     814</span>              :   at::Tensor nanmean(at::OptionalIntArrayRef dim=::std::nullopt, bool keepdim=false, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) const;</span>
<span id="L815"><span class="lineNum">     815</span>              :   at::Tensor median() const;</span>
<span id="L816"><span class="lineNum">     816</span>              :   ::std::tuple&lt;at::Tensor,at::Tensor&gt; median(int64_t dim, bool keepdim=false) const;</span>
<span id="L817"><span class="lineNum">     817</span>              :   ::std::tuple&lt;at::Tensor,at::Tensor&gt; median(at::Dimname dim, bool keepdim=false) const;</span>
<span id="L818"><span class="lineNum">     818</span>              :   at::Tensor nanmedian() const;</span>
<span id="L819"><span class="lineNum">     819</span>              :   ::std::tuple&lt;at::Tensor,at::Tensor&gt; nanmedian(int64_t dim, bool keepdim=false) const;</span>
<span id="L820"><span class="lineNum">     820</span>              :   ::std::tuple&lt;at::Tensor,at::Tensor&gt; nanmedian(at::Dimname dim, bool keepdim=false) const;</span>
<span id="L821"><span class="lineNum">     821</span>              :   ::std::tuple&lt;at::Tensor,at::Tensor&gt; min(int64_t dim, bool keepdim=false) const;</span>
<span id="L822"><span class="lineNum">     822</span>              :   ::std::tuple&lt;at::Tensor,at::Tensor&gt; min(at::Dimname dim, bool keepdim=false) const;</span>
<span id="L823"><span class="lineNum">     823</span>              :   at::Tensor amin(at::IntArrayRef dim={}, bool keepdim=false) const;</span>
<span id="L824"><span class="lineNum">     824</span>              :   at::Tensor mm(const at::Tensor &amp; mat2) const;</span>
<span id="L825"><span class="lineNum">     825</span>              :   ::std::tuple&lt;at::Tensor,at::Tensor&gt; mode(int64_t dim=-1, bool keepdim=false) const;</span>
<span id="L826"><span class="lineNum">     826</span>              :   ::std::tuple&lt;at::Tensor,at::Tensor&gt; mode(at::Dimname dim, bool keepdim=false) const;</span>
<span id="L827"><span class="lineNum">     827</span>              :   at::Tensor mul(const at::Tensor &amp; other) const;</span>
<span id="L828"><span class="lineNum">     828</span>              :   at::Tensor &amp; mul_(const at::Tensor &amp; other) const;</span>
<span id="L829"><span class="lineNum">     829</span>              :   at::Tensor mul(const at::Scalar &amp; other) const;</span>
<span id="L830"><span class="lineNum">     830</span>              :   at::Tensor &amp; mul_(const at::Scalar &amp; other) const;</span>
<span id="L831"><span class="lineNum">     831</span>              :   at::Tensor multiply(const at::Tensor &amp; other) const;</span>
<span id="L832"><span class="lineNum">     832</span>              :   at::Tensor &amp; multiply_(const at::Tensor &amp; other) const;</span>
<span id="L833"><span class="lineNum">     833</span>              :   at::Tensor multiply(const at::Scalar &amp; other) const;</span>
<span id="L834"><span class="lineNum">     834</span>              :   at::Tensor &amp; multiply_(const at::Scalar &amp; other) const;</span>
<span id="L835"><span class="lineNum">     835</span>              :   at::Tensor mv(const at::Tensor &amp; vec) const;</span>
<span id="L836"><span class="lineNum">     836</span>              :   at::Tensor mvlgamma(int64_t p) const;</span>
<span id="L837"><span class="lineNum">     837</span>              :   at::Tensor &amp; mvlgamma_(int64_t p) const;</span>
<span id="L838"><span class="lineNum">     838</span>              :   at::Tensor narrow_copy(int64_t dim, int64_t start, int64_t length) const;</span>
<span id="L839"><span class="lineNum">     839</span>              :   at::Tensor narrow_copy_symint(int64_t dim, c10::SymInt start, c10::SymInt length) const;</span>
<span id="L840"><span class="lineNum">     840</span>              :   at::Tensor narrow(int64_t dim, int64_t start, int64_t length) const;</span>
<span id="L841"><span class="lineNum">     841</span>              :   at::Tensor narrow_symint(int64_t dim, c10::SymInt start, c10::SymInt length) const;</span>
<span id="L842"><span class="lineNum">     842</span>              :   at::Tensor narrow(int64_t dim, const at::Tensor &amp; start, int64_t length) const;</span>
<span id="L843"><span class="lineNum">     843</span>              :   at::Tensor narrow_symint(int64_t dim, const at::Tensor &amp; start, c10::SymInt length) const;</span>
<span id="L844"><span class="lineNum">     844</span>              :   at::Tensor permute(at::IntArrayRef dims) const;</span>
<span id="L845"><span class="lineNum">     845</span>              :   at::Tensor movedim(at::IntArrayRef source, at::IntArrayRef destination) const;</span>
<span id="L846"><span class="lineNum">     846</span>              :   at::Tensor movedim(int64_t source, int64_t destination) const;</span>
<span id="L847"><span class="lineNum">     847</span>              :   at::Tensor moveaxis(at::IntArrayRef source, at::IntArrayRef destination) const;</span>
<span id="L848"><span class="lineNum">     848</span>              :   at::Tensor moveaxis(int64_t source, int64_t destination) const;</span>
<span id="L849"><span class="lineNum">     849</span>              :   at::Tensor numpy_T() const;</span>
<span id="L850"><span class="lineNum">     850</span>              :   at::Tensor matrix_H() const;</span>
<span id="L851"><span class="lineNum">     851</span>              :   at::Tensor mT() const;</span>
<span id="L852"><span class="lineNum">     852</span>              :   at::Tensor mH() const;</span>
<span id="L853"><span class="lineNum">     853</span>              :   at::Tensor adjoint() const;</span>
<span id="L854"><span class="lineNum">     854</span>              :   bool is_pinned(::std::optional&lt;at::Device&gt; device=::std::nullopt) const;</span>
<span id="L855"><span class="lineNum">     855</span>              :   at::Tensor pin_memory(::std::optional&lt;at::Device&gt; device=::std::nullopt) const;</span>
<span id="L856"><span class="lineNum">     856</span>              :   at::Tensor pinverse(double rcond=1e-15) const;</span>
<span id="L857"><span class="lineNum">     857</span>              :   at::Tensor rad2deg() const;</span>
<span id="L858"><span class="lineNum">     858</span>              :   at::Tensor &amp; rad2deg_() const;</span>
<span id="L859"><span class="lineNum">     859</span>              :   at::Tensor deg2rad() const;</span>
<span id="L860"><span class="lineNum">     860</span>              :   at::Tensor &amp; deg2rad_() const;</span>
<span id="L861"><span class="lineNum">     861</span>              :   at::Tensor ravel() const;</span>
<span id="L862"><span class="lineNum">     862</span>              :   at::Tensor reciprocal() const;</span>
<span id="L863"><span class="lineNum">     863</span>              :   at::Tensor &amp; reciprocal_() const;</span>
<span id="L864"><span class="lineNum">     864</span>              :   at::Tensor neg() const;</span>
<span id="L865"><span class="lineNum">     865</span>              :   at::Tensor &amp; neg_() const;</span>
<span id="L866"><span class="lineNum">     866</span>              :   at::Tensor negative() const;</span>
<span id="L867"><span class="lineNum">     867</span>              :   at::Tensor &amp; negative_() const;</span>
<span id="L868"><span class="lineNum">     868</span>              :   at::Tensor repeat(at::IntArrayRef repeats) const;</span>
<span id="L869"><span class="lineNum">     869</span>              :   at::Tensor repeat_symint(c10::SymIntArrayRef repeats) const;</span>
<span id="L870"><span class="lineNum">     870</span>              :   at::Tensor repeat_interleave(const at::Tensor &amp; repeats, ::std::optional&lt;int64_t&gt; dim=::std::nullopt, ::std::optional&lt;int64_t&gt; output_size=::std::nullopt) const;</span>
<span id="L871"><span class="lineNum">     871</span>              :   at::Tensor repeat_interleave_symint(const at::Tensor &amp; repeats, ::std::optional&lt;int64_t&gt; dim=::std::nullopt, ::std::optional&lt;c10::SymInt&gt; output_size=::std::nullopt) const;</span>
<span id="L872"><span class="lineNum">     872</span>              :   at::Tensor repeat_interleave(int64_t repeats, ::std::optional&lt;int64_t&gt; dim=::std::nullopt, ::std::optional&lt;int64_t&gt; output_size=::std::nullopt) const;</span>
<span id="L873"><span class="lineNum">     873</span>              :   at::Tensor repeat_interleave_symint(c10::SymInt repeats, ::std::optional&lt;int64_t&gt; dim=::std::nullopt, ::std::optional&lt;c10::SymInt&gt; output_size=::std::nullopt) const;</span>
<span id="L874"><span class="lineNum">     874</span>              :   at::Tensor reshape(at::IntArrayRef shape) const;</span>
<span id="L875"><span class="lineNum">     875</span>              :   at::Tensor reshape_symint(c10::SymIntArrayRef shape) const;</span>
<span id="L876"><span class="lineNum">     876</span>              :   at::Tensor _reshape_alias(at::IntArrayRef size, at::IntArrayRef stride) const;</span>
<span id="L877"><span class="lineNum">     877</span>              :   at::Tensor _reshape_alias_symint(c10::SymIntArrayRef size, c10::SymIntArrayRef stride) const;</span>
<span id="L878"><span class="lineNum">     878</span>              :   at::Tensor reshape_as(const at::Tensor &amp; other) const;</span>
<span id="L879"><span class="lineNum">     879</span>              :   at::Tensor round() const;</span>
<span id="L880"><span class="lineNum">     880</span>              :   at::Tensor &amp; round_() const;</span>
<span id="L881"><span class="lineNum">     881</span>              :   at::Tensor round(int64_t decimals) const;</span>
<span id="L882"><span class="lineNum">     882</span>              :   at::Tensor &amp; round_(int64_t decimals) const;</span>
<span id="L883"><span class="lineNum">     883</span>              :   at::Tensor relu() const;</span>
<span id="L884"><span class="lineNum">     884</span>              :   at::Tensor &amp; relu_() const;</span>
<span id="L885"><span class="lineNum">     885</span>              :   at::Tensor prelu(const at::Tensor &amp; weight) const;</span>
<span id="L886"><span class="lineNum">     886</span>              :   at::Tensor hardshrink(const at::Scalar &amp; lambd=0.5) const;</span>
<span id="L887"><span class="lineNum">     887</span>              :   at::Tensor hardshrink_backward(const at::Tensor &amp; grad_out, const at::Scalar &amp; lambd) const;</span>
<span id="L888"><span class="lineNum">     888</span>              :   at::Tensor rsqrt() const;</span>
<span id="L889"><span class="lineNum">     889</span>              :   at::Tensor &amp; rsqrt_() const;</span>
<span id="L890"><span class="lineNum">     890</span>              :   at::Tensor select(at::Dimname dim, int64_t index) const;</span>
<span id="L891"><span class="lineNum">     891</span>              :   at::Tensor select(int64_t dim, int64_t index) const;</span>
<span id="L892"><span class="lineNum">     892</span>              :   at::Tensor select_symint(int64_t dim, c10::SymInt index) const;</span>
<span id="L893"><span class="lineNum">     893</span>              :   at::Tensor sigmoid() const;</span>
<span id="L894"><span class="lineNum">     894</span>              :   at::Tensor &amp; sigmoid_() const;</span>
<span id="L895"><span class="lineNum">     895</span>              :   at::Tensor logit(::std::optional&lt;double&gt; eps=::std::nullopt) const;</span>
<span id="L896"><span class="lineNum">     896</span>              :   at::Tensor &amp; logit_(::std::optional&lt;double&gt; eps=::std::nullopt) const;</span>
<span id="L897"><span class="lineNum">     897</span>              :   at::Tensor sin() const;</span>
<span id="L898"><span class="lineNum">     898</span>              :   at::Tensor &amp; sin_() const;</span>
<span id="L899"><span class="lineNum">     899</span>              :   at::Tensor sinc() const;</span>
<span id="L900"><span class="lineNum">     900</span>              :   at::Tensor &amp; sinc_() const;</span>
<span id="L901"><span class="lineNum">     901</span>              :   at::Tensor sinh() const;</span>
<span id="L902"><span class="lineNum">     902</span>              :   at::Tensor &amp; sinh_() const;</span>
<span id="L903"><span class="lineNum">     903</span>              :   at::Tensor detach() const;</span>
<span id="L904"><span class="lineNum">     904</span>              :   at::Tensor &amp; detach_() const;</span>
<span id="L905"><span class="lineNum">     905</span>              :   int64_t size(at::Dimname dim) const;</span>
<span id="L906"><span class="lineNum">     906</span>              :   at::Tensor slice(int64_t dim=0, ::std::optional&lt;int64_t&gt; start=::std::nullopt, ::std::optional&lt;int64_t&gt; end=::std::nullopt, int64_t step=1) const;</span>
<span id="L907"><span class="lineNum">     907</span>              :   at::Tensor slice_symint(int64_t dim=0, ::std::optional&lt;c10::SymInt&gt; start=::std::nullopt, ::std::optional&lt;c10::SymInt&gt; end=::std::nullopt, c10::SymInt step=1) const;</span>
<span id="L908"><span class="lineNum">     908</span>              :   at::Tensor slice_inverse(const at::Tensor &amp; src, int64_t dim=0, ::std::optional&lt;int64_t&gt; start=::std::nullopt, ::std::optional&lt;int64_t&gt; end=::std::nullopt, int64_t step=1) const;</span>
<span id="L909"><span class="lineNum">     909</span>              :   at::Tensor slice_inverse_symint(const at::Tensor &amp; src, int64_t dim=0, ::std::optional&lt;c10::SymInt&gt; start=::std::nullopt, ::std::optional&lt;c10::SymInt&gt; end=::std::nullopt, c10::SymInt step=1) const;</span>
<span id="L910"><span class="lineNum">     910</span>              :   at::Tensor slice_scatter(const at::Tensor &amp; src, int64_t dim=0, ::std::optional&lt;int64_t&gt; start=::std::nullopt, ::std::optional&lt;int64_t&gt; end=::std::nullopt, int64_t step=1) const;</span>
<span id="L911"><span class="lineNum">     911</span>              :   at::Tensor slice_scatter_symint(const at::Tensor &amp; src, int64_t dim=0, ::std::optional&lt;c10::SymInt&gt; start=::std::nullopt, ::std::optional&lt;c10::SymInt&gt; end=::std::nullopt, c10::SymInt step=1) const;</span>
<span id="L912"><span class="lineNum">     912</span>              :   at::Tensor select_scatter(const at::Tensor &amp; src, int64_t dim, int64_t index) const;</span>
<span id="L913"><span class="lineNum">     913</span>              :   at::Tensor select_scatter_symint(const at::Tensor &amp; src, int64_t dim, c10::SymInt index) const;</span>
<span id="L914"><span class="lineNum">     914</span>              :   at::Tensor diagonal_scatter(const at::Tensor &amp; src, int64_t offset=0, int64_t dim1=0, int64_t dim2=1) const;</span>
<span id="L915"><span class="lineNum">     915</span>              :   at::Tensor as_strided_scatter(const at::Tensor &amp; src, at::IntArrayRef size, at::IntArrayRef stride, ::std::optional&lt;int64_t&gt; storage_offset=::std::nullopt) const;</span>
<span id="L916"><span class="lineNum">     916</span>              :   at::Tensor as_strided_scatter_symint(const at::Tensor &amp; src, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, ::std::optional&lt;c10::SymInt&gt; storage_offset=::std::nullopt) const;</span>
<span id="L917"><span class="lineNum">     917</span>              :   at::Tensor smm(const at::Tensor &amp; mat2) const;</span>
<span id="L918"><span class="lineNum">     918</span>              :   at::Tensor softmax(int64_t dim, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) const;</span>
<span id="L919"><span class="lineNum">     919</span>              :   at::Tensor softmax(at::Dimname dim, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) const;</span>
<span id="L920"><span class="lineNum">     920</span>              :   ::std::vector&lt;at::Tensor&gt; unsafe_split(int64_t split_size, int64_t dim=0) const;</span>
<span id="L921"><span class="lineNum">     921</span>              :   ::std::vector&lt;at::Tensor&gt; unsafe_split_symint(c10::SymInt split_size, int64_t dim=0) const;</span>
<span id="L922"><span class="lineNum">     922</span>              :   ::std::vector&lt;at::Tensor&gt; split(int64_t split_size, int64_t dim=0) const;</span>
<span id="L923"><span class="lineNum">     923</span>              :   ::std::vector&lt;at::Tensor&gt; split_symint(c10::SymInt split_size, int64_t dim=0) const;</span>
<span id="L924"><span class="lineNum">     924</span>              :   ::std::vector&lt;at::Tensor&gt; split(at::IntArrayRef split_size, int64_t dim=0) const;</span>
<span id="L925"><span class="lineNum">     925</span>              :   ::std::vector&lt;at::Tensor&gt; split_symint(c10::SymIntArrayRef split_size, int64_t dim=0) const;</span>
<span id="L926"><span class="lineNum">     926</span>              :   ::std::vector&lt;at::Tensor&gt; unsafe_split_with_sizes(at::IntArrayRef split_sizes, int64_t dim=0) const;</span>
<span id="L927"><span class="lineNum">     927</span>              :   ::std::vector&lt;at::Tensor&gt; unsafe_split_with_sizes_symint(c10::SymIntArrayRef split_sizes, int64_t dim=0) const;</span>
<span id="L928"><span class="lineNum">     928</span>              :   ::std::vector&lt;at::Tensor&gt; split_with_sizes(at::IntArrayRef split_sizes, int64_t dim=0) const;</span>
<span id="L929"><span class="lineNum">     929</span>              :   ::std::vector&lt;at::Tensor&gt; split_with_sizes_symint(c10::SymIntArrayRef split_sizes, int64_t dim=0) const;</span>
<span id="L930"><span class="lineNum">     930</span>              :   ::std::vector&lt;at::Tensor&gt; hsplit(int64_t sections) const;</span>
<span id="L931"><span class="lineNum">     931</span>              :   ::std::vector&lt;at::Tensor&gt; hsplit(at::IntArrayRef indices) const;</span>
<span id="L932"><span class="lineNum">     932</span>              :   ::std::vector&lt;at::Tensor&gt; vsplit(int64_t sections) const;</span>
<span id="L933"><span class="lineNum">     933</span>              :   ::std::vector&lt;at::Tensor&gt; vsplit(at::IntArrayRef indices) const;</span>
<span id="L934"><span class="lineNum">     934</span>              :   ::std::vector&lt;at::Tensor&gt; dsplit(int64_t sections) const;</span>
<span id="L935"><span class="lineNum">     935</span>              :   ::std::vector&lt;at::Tensor&gt; dsplit(at::IntArrayRef indices) const;</span>
<span id="L936"><span class="lineNum">     936</span>              :   at::Tensor squeeze() const;</span>
<span id="L937"><span class="lineNum">     937</span>              :   at::Tensor squeeze(int64_t dim) const;</span>
<span id="L938"><span class="lineNum">     938</span>              :   at::Tensor squeeze(at::Dimname dim) const;</span>
<span id="L939"><span class="lineNum">     939</span>              :   at::Tensor squeeze(at::IntArrayRef dim) const;</span>
<span id="L940"><span class="lineNum">     940</span>              :   at::Tensor &amp; squeeze_() const;</span>
<span id="L941"><span class="lineNum">     941</span>              :   at::Tensor &amp; squeeze_(int64_t dim) const;</span>
<span id="L942"><span class="lineNum">     942</span>              :   at::Tensor &amp; squeeze_(at::IntArrayRef dim) const;</span>
<span id="L943"><span class="lineNum">     943</span>              :   at::Tensor &amp; squeeze_(at::Dimname dim) const;</span>
<span id="L944"><span class="lineNum">     944</span>              :   at::Tensor sspaddmm(const at::Tensor &amp; mat1, const at::Tensor &amp; mat2, const at::Scalar &amp; beta=1, const at::Scalar &amp; alpha=1) const;</span>
<span id="L945"><span class="lineNum">     945</span>              :   at::Tensor stft(int64_t n_fft, ::std::optional&lt;int64_t&gt; hop_length, ::std::optional&lt;int64_t&gt; win_length, const ::std::optional&lt;at::Tensor&gt; &amp; window, bool normalized, ::std::optional&lt;bool&gt; onesided=::std::nullopt, ::std::optional&lt;bool&gt; return_complex=::std::nullopt) const;</span>
<span id="L946"><span class="lineNum">     946</span>              :   at::Tensor stft(int64_t n_fft, ::std::optional&lt;int64_t&gt; hop_length=::std::nullopt, ::std::optional&lt;int64_t&gt; win_length=::std::nullopt, const ::std::optional&lt;at::Tensor&gt; &amp; window={}, bool center=true, c10::string_view pad_mode=&quot;reflect&quot;, bool normalized=false, ::std::optional&lt;bool&gt; onesided=::std::nullopt, ::std::optional&lt;bool&gt; return_complex=::std::nullopt) const;</span>
<span id="L947"><span class="lineNum">     947</span>              :   at::Tensor istft(int64_t n_fft, ::std::optional&lt;int64_t&gt; hop_length=::std::nullopt, ::std::optional&lt;int64_t&gt; win_length=::std::nullopt, const ::std::optional&lt;at::Tensor&gt; &amp; window={}, bool center=true, bool normalized=false, ::std::optional&lt;bool&gt; onesided=::std::nullopt, ::std::optional&lt;int64_t&gt; length=::std::nullopt, bool return_complex=false) const;</span>
<span id="L948"><span class="lineNum">     948</span>              :   int64_t stride(at::Dimname dim) const;</span>
<span id="L949"><span class="lineNum">     949</span>              :   at::Tensor sum(::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) const;</span>
<span id="L950"><span class="lineNum">     950</span>              :   at::Tensor sum(at::OptionalIntArrayRef dim, bool keepdim=false, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) const;</span>
<span id="L951"><span class="lineNum">     951</span>              :   at::Tensor sum(at::DimnameList dim, bool keepdim=false, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) const;</span>
<span id="L952"><span class="lineNum">     952</span>              :   at::Tensor nansum(at::OptionalIntArrayRef dim=::std::nullopt, bool keepdim=false, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) const;</span>
<span id="L953"><span class="lineNum">     953</span>              :   at::Tensor sum_to_size(at::IntArrayRef size) const;</span>
<span id="L954"><span class="lineNum">     954</span>              :   at::Tensor sum_to_size_symint(c10::SymIntArrayRef size) const;</span>
<span id="L955"><span class="lineNum">     955</span>              :   at::Tensor sqrt() const;</span>
<span id="L956"><span class="lineNum">     956</span>              :   at::Tensor &amp; sqrt_() const;</span>
<span id="L957"><span class="lineNum">     957</span>              :   at::Tensor square() const;</span>
<span id="L958"><span class="lineNum">     958</span>              :   at::Tensor &amp; square_() const;</span>
<span id="L959"><span class="lineNum">     959</span>              :   at::Tensor std(bool unbiased) const;</span>
<span id="L960"><span class="lineNum">     960</span>              :   at::Tensor std(at::OptionalIntArrayRef dim, bool unbiased, bool keepdim=false) const;</span>
<span id="L961"><span class="lineNum">     961</span>              :   at::Tensor std(at::OptionalIntArrayRef dim=::std::nullopt, const ::std::optional&lt;at::Scalar&gt; &amp; correction=::std::nullopt, bool keepdim=false) const;</span>
<span id="L962"><span class="lineNum">     962</span>              :   at::Tensor std(at::DimnameList dim, bool unbiased, bool keepdim=false) const;</span>
<span id="L963"><span class="lineNum">     963</span>              :   at::Tensor std(at::DimnameList dim, const ::std::optional&lt;at::Scalar&gt; &amp; correction=::std::nullopt, bool keepdim=false) const;</span>
<span id="L964"><span class="lineNum">     964</span>              :   at::Tensor prod(::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) const;</span>
<span id="L965"><span class="lineNum">     965</span>              :   at::Tensor prod(int64_t dim, bool keepdim=false, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) const;</span>
<span id="L966"><span class="lineNum">     966</span>              :   at::Tensor prod(at::Dimname dim, bool keepdim=false, ::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) const;</span>
<span id="L967"><span class="lineNum">     967</span>              :   at::Tensor t() const;</span>
<span id="L968"><span class="lineNum">     968</span>              :   at::Tensor &amp; t_() const;</span>
<span id="L969"><span class="lineNum">     969</span>              :   at::Tensor tan() const;</span>
<span id="L970"><span class="lineNum">     970</span>              :   at::Tensor &amp; tan_() const;</span>
<span id="L971"><span class="lineNum">     971</span>              :   at::Tensor tanh() const;</span>
<span id="L972"><span class="lineNum">     972</span>              :   at::Tensor &amp; tanh_() const;</span>
<span id="L973"><span class="lineNum">     973</span>              :   at::Tensor tile(at::IntArrayRef dims) const;</span>
<span id="L974"><span class="lineNum">     974</span>              :   at::Tensor tile_symint(c10::SymIntArrayRef dims) const;</span>
<span id="L975"><span class="lineNum">     975</span>              :   at::Tensor transpose(int64_t dim0, int64_t dim1) const;</span>
<span id="L976"><span class="lineNum">     976</span>              :   at::Tensor transpose(at::Dimname dim0, at::Dimname dim1) const;</span>
<span id="L977"><span class="lineNum">     977</span>              :   at::Tensor &amp; transpose_(int64_t dim0, int64_t dim1) const;</span>
<span id="L978"><span class="lineNum">     978</span>              :   at::Tensor flip(at::IntArrayRef dims) const;</span>
<span id="L979"><span class="lineNum">     979</span>              :   at::Tensor fliplr() const;</span>
<span id="L980"><span class="lineNum">     980</span>              :   at::Tensor flipud() const;</span>
<span id="L981"><span class="lineNum">     981</span>              :   at::Tensor roll(at::IntArrayRef shifts, at::IntArrayRef dims={}) const;</span>
<span id="L982"><span class="lineNum">     982</span>              :   at::Tensor roll_symint(c10::SymIntArrayRef shifts, at::IntArrayRef dims={}) const;</span>
<span id="L983"><span class="lineNum">     983</span>              :   at::Tensor rot90(int64_t k=1, at::IntArrayRef dims={0,1}) const;</span>
<span id="L984"><span class="lineNum">     984</span>              :   at::Tensor _nested_tensor_size() const;</span>
<span id="L985"><span class="lineNum">     985</span>              :   at::Tensor _nested_tensor_strides() const;</span>
<span id="L986"><span class="lineNum">     986</span>              :   at::Tensor _nested_tensor_storage_offsets() const;</span>
<span id="L987"><span class="lineNum">     987</span>              :   at::Tensor trunc() const;</span>
<span id="L988"><span class="lineNum">     988</span>              :   at::Tensor &amp; trunc_() const;</span>
<span id="L989"><span class="lineNum">     989</span>              :   at::Tensor fix() const;</span>
<span id="L990"><span class="lineNum">     990</span>              :   at::Tensor &amp; fix_() const;</span>
<span id="L991"><span class="lineNum">     991</span>              :   at::Tensor type_as(const at::Tensor &amp; other) const;</span>
<span id="L992"><span class="lineNum">     992</span>              :   at::Tensor unsqueeze(int64_t dim) const;</span>
<span id="L993"><span class="lineNum">     993</span>              :   at::Tensor &amp; unsqueeze_(int64_t dim) const;</span>
<span id="L994"><span class="lineNum">     994</span>              :   at::Tensor var(bool unbiased) const;</span>
<span id="L995"><span class="lineNum">     995</span>              :   at::Tensor var(at::OptionalIntArrayRef dim, bool unbiased, bool keepdim=false) const;</span>
<span id="L996"><span class="lineNum">     996</span>              :   at::Tensor var(at::OptionalIntArrayRef dim=::std::nullopt, const ::std::optional&lt;at::Scalar&gt; &amp; correction=::std::nullopt, bool keepdim=false) const;</span>
<span id="L997"><span class="lineNum">     997</span>              :   at::Tensor var(at::DimnameList dim, bool unbiased, bool keepdim=false) const;</span>
<span id="L998"><span class="lineNum">     998</span>              :   at::Tensor var(at::DimnameList dim, const ::std::optional&lt;at::Scalar&gt; &amp; correction=::std::nullopt, bool keepdim=false) const;</span>
<span id="L999"><span class="lineNum">     999</span>              :   at::Tensor view_as(const at::Tensor &amp; other) const;</span>
<span id="L1000"><span class="lineNum">    1000</span>              :   at::Tensor where(const at::Tensor &amp; condition, const at::Tensor &amp; other) const;</span>
<span id="L1001"><span class="lineNum">    1001</span>              :   at::Tensor where(const at::Tensor &amp; condition, const at::Scalar &amp; other) const;</span>
<span id="L1002"><span class="lineNum">    1002</span>              :   at::Tensor norm(const ::std::optional&lt;at::Scalar&gt; &amp; p, at::ScalarType dtype) const;</span>
<span id="L1003"><span class="lineNum">    1003</span>              :   at::Tensor norm(const at::Scalar &amp; p=2) const;</span>
<span id="L1004"><span class="lineNum">    1004</span>              :   at::Tensor norm(const ::std::optional&lt;at::Scalar&gt; &amp; p, at::IntArrayRef dim, bool keepdim, at::ScalarType dtype) const;</span>
<span id="L1005"><span class="lineNum">    1005</span>              :   at::Tensor norm(const ::std::optional&lt;at::Scalar&gt; &amp; p, at::IntArrayRef dim, bool keepdim=false) const;</span>
<span id="L1006"><span class="lineNum">    1006</span>              :   at::Tensor norm(const ::std::optional&lt;at::Scalar&gt; &amp; p, at::DimnameList dim, bool keepdim, at::ScalarType dtype) const;</span>
<span id="L1007"><span class="lineNum">    1007</span>              :   at::Tensor norm(const ::std::optional&lt;at::Scalar&gt; &amp; p, at::DimnameList dim, bool keepdim=false) const;</span>
<span id="L1008"><span class="lineNum">    1008</span>              :   ::std::tuple&lt;at::Tensor,at::Tensor&gt; frexp() const;</span>
<span id="L1009"><span class="lineNum">    1009</span>              :   at::Tensor clone(::std::optional&lt;at::MemoryFormat&gt; memory_format=::std::nullopt) const;</span>
<span id="L1010"><span class="lineNum">    1010</span>              :   at::Tensor positive() const;</span>
<span id="L1011"><span class="lineNum">    1011</span>              :   const at::Tensor &amp; resize_as_(const at::Tensor &amp; the_template, ::std::optional&lt;at::MemoryFormat&gt; memory_format=::std::nullopt) const;</span>
<span id="L1012"><span class="lineNum">    1012</span>              :   const at::Tensor &amp; resize_as_sparse_(const at::Tensor &amp; the_template) const;</span>
<span id="L1013"><span class="lineNum">    1013</span>              :   at::Tensor &amp; zero_() const;</span>
<span id="L1014"><span class="lineNum">    1014</span>              :   at::Tensor sub(const at::Tensor &amp; other, const at::Scalar &amp; alpha=1) const;</span>
<span id="L1015"><span class="lineNum">    1015</span>              :   at::Tensor &amp; sub_(const at::Tensor &amp; other, const at::Scalar &amp; alpha=1) const;</span>
<span id="L1016"><span class="lineNum">    1016</span>              :   at::Tensor sub(const at::Scalar &amp; other, const at::Scalar &amp; alpha=1) const;</span>
<span id="L1017"><span class="lineNum">    1017</span>              :   at::Tensor &amp; sub_(const at::Scalar &amp; other, const at::Scalar &amp; alpha=1) const;</span>
<span id="L1018"><span class="lineNum">    1018</span>              :   at::Tensor subtract(const at::Tensor &amp; other, const at::Scalar &amp; alpha=1) const;</span>
<span id="L1019"><span class="lineNum">    1019</span>              :   at::Tensor &amp; subtract_(const at::Tensor &amp; other, const at::Scalar &amp; alpha=1) const;</span>
<span id="L1020"><span class="lineNum">    1020</span>              :   at::Tensor subtract(const at::Scalar &amp; other, const at::Scalar &amp; alpha=1) const;</span>
<span id="L1021"><span class="lineNum">    1021</span>              :   at::Tensor &amp; subtract_(const at::Scalar &amp; other, const at::Scalar &amp; alpha=1) const;</span>
<span id="L1022"><span class="lineNum">    1022</span>              :   at::Tensor heaviside(const at::Tensor &amp; values) const;</span>
<span id="L1023"><span class="lineNum">    1023</span>              :   at::Tensor &amp; heaviside_(const at::Tensor &amp; values) const;</span>
<span id="L1024"><span class="lineNum">    1024</span>              :   at::Tensor addmm(const at::Tensor &amp; mat1, const at::Tensor &amp; mat2, const at::Scalar &amp; beta=1, const at::Scalar &amp; alpha=1) const;</span>
<span id="L1025"><span class="lineNum">    1025</span>              :   at::Tensor &amp; addmm_(const at::Tensor &amp; mat1, const at::Tensor &amp; mat2, const at::Scalar &amp; beta=1, const at::Scalar &amp; alpha=1) const;</span>
<span id="L1026"><span class="lineNum">    1026</span>              :   at::Tensor _addmm_activation(const at::Tensor &amp; mat1, const at::Tensor &amp; mat2, const at::Scalar &amp; beta=1, const at::Scalar &amp; alpha=1, bool use_gelu=false) const;</span>
<span id="L1027"><span class="lineNum">    1027</span>              :   const at::Tensor &amp; sparse_resize_(at::IntArrayRef size, int64_t sparse_dim, int64_t dense_dim) const;</span>
<span id="L1028"><span class="lineNum">    1028</span>              :   const at::Tensor &amp; sparse_resize_and_clear_(at::IntArrayRef size, int64_t sparse_dim, int64_t dense_dim) const;</span>
<span id="L1029"><span class="lineNum">    1029</span>              :   at::Tensor sparse_mask(const at::Tensor &amp; mask) const;</span>
<span id="L1030"><span class="lineNum">    1030</span>              :   at::Tensor _sparse_mask_projection(const at::Tensor &amp; mask, bool accumulate_matches=false) const;</span>
<span id="L1031"><span class="lineNum">    1031</span>              :   at::Tensor to_dense(::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt, ::std::optional&lt;bool&gt; masked_grad=::std::nullopt) const;</span>
<span id="L1032"><span class="lineNum">    1032</span>              :   at::Tensor _to_dense(::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt, ::std::optional&lt;bool&gt; masked_grad=::std::nullopt) const;</span>
<span id="L1033"><span class="lineNum">    1033</span>              :   int64_t sparse_dim() const;</span>
<span id="L1034"><span class="lineNum">    1034</span>              :   int64_t _dimI() const;</span>
<span id="L1035"><span class="lineNum">    1035</span>              :   int64_t dense_dim() const;</span>
<span id="L1036"><span class="lineNum">    1036</span>              :   int64_t _dimV() const;</span>
<span id="L1037"><span class="lineNum">    1037</span>              :   int64_t _nnz() const;</span>
<span id="L1038"><span class="lineNum">    1038</span>              :   at::Tensor coalesce() const;</span>
<span id="L1039"><span class="lineNum">    1039</span>              :   bool is_coalesced() const;</span>
<span id="L1040"><span class="lineNum">    1040</span>              :   at::Tensor _indices() const;</span>
<span id="L1041"><span class="lineNum">    1041</span>              :   at::Tensor _values() const;</span>
<span id="L1042"><span class="lineNum">    1042</span>              :   at::Tensor &amp; _coalesced_(bool coalesced) const;</span>
<span id="L1043"><span class="lineNum">    1043</span>              :   at::Tensor indices() const;</span>
<span id="L1044"><span class="lineNum">    1044</span>              :   at::Tensor values() const;</span>
<span id="L1045"><span class="lineNum">    1045</span>              :   at::Tensor crow_indices() const;</span>
<span id="L1046"><span class="lineNum">    1046</span>              :   at::Tensor col_indices() const;</span>
<span id="L1047"><span class="lineNum">    1047</span>              :   at::Tensor ccol_indices() const;</span>
<span id="L1048"><span class="lineNum">    1048</span>              :   at::Tensor row_indices() const;</span>
<span id="L1049"><span class="lineNum">    1049</span>              :   ::std::vector&lt;at::Tensor&gt; unbind(int64_t dim=0) const;</span>
<span id="L1050"><span class="lineNum">    1050</span>              :   ::std::vector&lt;at::Tensor&gt; unbind(at::Dimname dim) const;</span>
<span id="L1051"><span class="lineNum">    1051</span>              :   at::Tensor to_sparse(int64_t sparse_dim) const;</span>
<span id="L1052"><span class="lineNum">    1052</span>              :   at::Tensor _to_sparse(int64_t sparse_dim) const;</span>
<span id="L1053"><span class="lineNum">    1053</span>              :   at::Tensor to_sparse(::std::optional&lt;at::Layout&gt; layout=::std::nullopt, at::OptionalIntArrayRef blocksize=::std::nullopt, ::std::optional&lt;int64_t&gt; dense_dim=::std::nullopt) const;</span>
<span id="L1054"><span class="lineNum">    1054</span>              :   at::Tensor _to_sparse(::std::optional&lt;at::Layout&gt; layout=::std::nullopt, at::OptionalIntArrayRef blocksize=::std::nullopt, ::std::optional&lt;int64_t&gt; dense_dim=::std::nullopt) const;</span>
<span id="L1055"><span class="lineNum">    1055</span>              :   at::Tensor to_sparse_csr(::std::optional&lt;int64_t&gt; dense_dim=::std::nullopt) const;</span>
<span id="L1056"><span class="lineNum">    1056</span>              :   at::Tensor _to_sparse_csr(::std::optional&lt;int64_t&gt; dense_dim=::std::nullopt) const;</span>
<span id="L1057"><span class="lineNum">    1057</span>              :   at::Tensor to_sparse_csc(::std::optional&lt;int64_t&gt; dense_dim=::std::nullopt) const;</span>
<span id="L1058"><span class="lineNum">    1058</span>              :   at::Tensor _to_sparse_csc(::std::optional&lt;int64_t&gt; dense_dim=::std::nullopt) const;</span>
<span id="L1059"><span class="lineNum">    1059</span>              :   at::Tensor to_sparse_bsr(at::IntArrayRef blocksize, ::std::optional&lt;int64_t&gt; dense_dim=::std::nullopt) const;</span>
<span id="L1060"><span class="lineNum">    1060</span>              :   at::Tensor _to_sparse_bsr(at::IntArrayRef blocksize, ::std::optional&lt;int64_t&gt; dense_dim=::std::nullopt) const;</span>
<span id="L1061"><span class="lineNum">    1061</span>              :   at::Tensor to_sparse_bsc(at::IntArrayRef blocksize, ::std::optional&lt;int64_t&gt; dense_dim=::std::nullopt) const;</span>
<span id="L1062"><span class="lineNum">    1062</span>              :   at::Tensor _to_sparse_bsc(at::IntArrayRef blocksize, ::std::optional&lt;int64_t&gt; dense_dim=::std::nullopt) const;</span>
<span id="L1063"><span class="lineNum">    1063</span>              :   at::Tensor to_mkldnn(::std::optional&lt;at::ScalarType&gt; dtype=::std::nullopt) const;</span>
<span id="L1064"><span class="lineNum">    1064</span>              :   at::Tensor dequantize() const;</span>
<span id="L1065"><span class="lineNum">    1065</span>              :   double q_scale() const;</span>
<span id="L1066"><span class="lineNum">    1066</span>              :   int64_t q_zero_point() const;</span>
<span id="L1067"><span class="lineNum">    1067</span>              :   at::Tensor q_per_channel_scales() const;</span>
<span id="L1068"><span class="lineNum">    1068</span>              :   at::Tensor q_per_channel_zero_points() const;</span>
<span id="L1069"><span class="lineNum">    1069</span>              :   int64_t q_per_channel_axis() const;</span>
<span id="L1070"><span class="lineNum">    1070</span>              :   at::Tensor int_repr() const;</span>
<span id="L1071"><span class="lineNum">    1071</span>              :   at::QScheme qscheme() const;</span>
<span id="L1072"><span class="lineNum">    1072</span>              :   at::Tensor _autocast_to_reduced_precision(bool cuda_enabled, bool cpu_enabled, at::ScalarType cuda_dtype, at::ScalarType cpu_dtype) const;</span>
<span id="L1073"><span class="lineNum">    1073</span>              :   at::Tensor _autocast_to_full_precision(bool cuda_enabled, bool cpu_enabled) const;</span>
<span id="L1074"><span class="lineNum">    1074</span>              :   at::Tensor to(at::TensorOptions options={}, bool non_blocking=false, bool copy=false, ::std::optional&lt;at::MemoryFormat&gt; memory_format=::std::nullopt) const;</span>
<span id="L1075"><span class="lineNum">    1075</span>              :   at::Tensor to(::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;bool&gt; pin_memory, bool non_blocking, bool copy, ::std::optional&lt;at::MemoryFormat&gt; memory_format) const;</span>
<span id="L1076"><span class="lineNum">    1076</span>              :   at::Tensor to(at::Device device, at::ScalarType dtype, bool non_blocking=false, bool copy=false, ::std::optional&lt;at::MemoryFormat&gt; memory_format=::std::nullopt) const;</span>
<span id="L1077"><span class="lineNum">    1077</span>              :   at::Tensor to(at::ScalarType dtype, bool non_blocking=false, bool copy=false, ::std::optional&lt;at::MemoryFormat&gt; memory_format=::std::nullopt) const;</span>
<span id="L1078"><span class="lineNum">    1078</span>              :   at::Tensor to(const at::Tensor &amp; other, bool non_blocking=false, bool copy=false, ::std::optional&lt;at::MemoryFormat&gt; memory_format=::std::nullopt) const;</span>
<span id="L1079"><span class="lineNum">    1079</span>              :   at::Scalar item() const;</span>
<span id="L1080"><span class="lineNum">    1080</span>              :   at::Tensor &amp; set_(at::Storage source) const;</span>
<span id="L1081"><span class="lineNum">    1081</span>              :   at::Tensor &amp; set_(at::Storage source, int64_t storage_offset, at::IntArrayRef size, at::IntArrayRef stride={}) const;</span>
<span id="L1082"><span class="lineNum">    1082</span>              :   at::Tensor &amp; set__symint(at::Storage source, c10::SymInt storage_offset, c10::SymIntArrayRef size, c10::SymIntArrayRef stride={}) const;</span>
<span id="L1083"><span class="lineNum">    1083</span>              :   at::Tensor &amp; set_(const at::Tensor &amp; source, int64_t storage_offset, at::IntArrayRef size, at::IntArrayRef stride={}) const;</span>
<span id="L1084"><span class="lineNum">    1084</span>              :   at::Tensor &amp; set__symint(const at::Tensor &amp; source, c10::SymInt storage_offset, c10::SymIntArrayRef size, c10::SymIntArrayRef stride={}) const;</span>
<span id="L1085"><span class="lineNum">    1085</span>              :   at::Tensor &amp; set_(const at::Tensor &amp; source) const;</span>
<span id="L1086"><span class="lineNum">    1086</span>              :   at::Tensor &amp; set_() const;</span>
<span id="L1087"><span class="lineNum">    1087</span>              :   bool is_set_to(const at::Tensor &amp; tensor) const;</span>
<span id="L1088"><span class="lineNum">    1088</span>              :   at::Tensor &amp; masked_fill_(const at::Tensor &amp; mask, const at::Scalar &amp; value) const;</span>
<span id="L1089"><span class="lineNum">    1089</span>              :   at::Tensor masked_fill(const at::Tensor &amp; mask, const at::Scalar &amp; value) const;</span>
<span id="L1090"><span class="lineNum">    1090</span>              :   at::Tensor &amp; masked_fill_(const at::Tensor &amp; mask, const at::Tensor &amp; value) const;</span>
<span id="L1091"><span class="lineNum">    1091</span>              :   at::Tensor masked_fill(const at::Tensor &amp; mask, const at::Tensor &amp; value) const;</span>
<span id="L1092"><span class="lineNum">    1092</span>              :   at::Tensor &amp; masked_scatter_(const at::Tensor &amp; mask, const at::Tensor &amp; source) const;</span>
<span id="L1093"><span class="lineNum">    1093</span>              :   at::Tensor masked_scatter(const at::Tensor &amp; mask, const at::Tensor &amp; source) const;</span>
<span id="L1094"><span class="lineNum">    1094</span>              :   at::Tensor view(at::IntArrayRef size) const;</span>
<span id="L1095"><span class="lineNum">    1095</span>              :   at::Tensor view_symint(c10::SymIntArrayRef size) const;</span>
<span id="L1096"><span class="lineNum">    1096</span>              :   at::Tensor view(at::ScalarType dtype) const;</span>
<span id="L1097"><span class="lineNum">    1097</span>              :   at::Tensor &amp; put_(const at::Tensor &amp; index, const at::Tensor &amp; source, bool accumulate=false) const;</span>
<span id="L1098"><span class="lineNum">    1098</span>              :   at::Tensor put(const at::Tensor &amp; index, const at::Tensor &amp; source, bool accumulate=false) const;</span>
<span id="L1099"><span class="lineNum">    1099</span>              :   at::Tensor &amp; index_add_(int64_t dim, const at::Tensor &amp; index, const at::Tensor &amp; source, const at::Scalar &amp; alpha=1) const;</span>
<span id="L1100"><span class="lineNum">    1100</span>              :   at::Tensor index_add(int64_t dim, const at::Tensor &amp; index, const at::Tensor &amp; source, const at::Scalar &amp; alpha=1) const;</span>
<span id="L1101"><span class="lineNum">    1101</span>              :   at::Tensor index_add(at::Dimname dim, const at::Tensor &amp; index, const at::Tensor &amp; source, const at::Scalar &amp; alpha=1) const;</span>
<span id="L1102"><span class="lineNum">    1102</span>              :   at::Tensor &amp; index_reduce_(int64_t dim, const at::Tensor &amp; index, const at::Tensor &amp; source, c10::string_view reduce, bool include_self=true) const;</span>
<span id="L1103"><span class="lineNum">    1103</span>              :   at::Tensor index_reduce(int64_t dim, const at::Tensor &amp; index, const at::Tensor &amp; source, c10::string_view reduce, bool include_self=true) const;</span>
<span id="L1104"><span class="lineNum">    1104</span>              :   at::Tensor &amp; index_fill_(int64_t dim, const at::Tensor &amp; index, const at::Scalar &amp; value) const;</span>
<span id="L1105"><span class="lineNum">    1105</span>              :   at::Tensor index_fill(int64_t dim, const at::Tensor &amp; index, const at::Scalar &amp; value) const;</span>
<span id="L1106"><span class="lineNum">    1106</span>              :   at::Tensor &amp; index_fill_(int64_t dim, const at::Tensor &amp; index, const at::Tensor &amp; value) const;</span>
<span id="L1107"><span class="lineNum">    1107</span>              :   at::Tensor index_fill(int64_t dim, const at::Tensor &amp; index, const at::Tensor &amp; value) const;</span>
<span id="L1108"><span class="lineNum">    1108</span>              :   at::Tensor &amp; index_fill_(at::Dimname dim, const at::Tensor &amp; index, const at::Scalar &amp; value) const;</span>
<span id="L1109"><span class="lineNum">    1109</span>              :   at::Tensor &amp; index_fill_(at::Dimname dim, const at::Tensor &amp; index, const at::Tensor &amp; value) const;</span>
<span id="L1110"><span class="lineNum">    1110</span>              :   at::Tensor index_fill(at::Dimname dim, const at::Tensor &amp; index, const at::Scalar &amp; value) const;</span>
<span id="L1111"><span class="lineNum">    1111</span>              :   at::Tensor index_fill(at::Dimname dim, const at::Tensor &amp; index, const at::Tensor &amp; value) const;</span>
<span id="L1112"><span class="lineNum">    1112</span>              :   at::Tensor scatter(int64_t dim, const at::Tensor &amp; index, const at::Tensor &amp; src) const;</span>
<span id="L1113"><span class="lineNum">    1113</span>              :   at::Tensor &amp; scatter_(int64_t dim, const at::Tensor &amp; index, const at::Tensor &amp; src) const;</span>
<span id="L1114"><span class="lineNum">    1114</span>              :   at::Tensor scatter(int64_t dim, const at::Tensor &amp; index, const at::Scalar &amp; value) const;</span>
<span id="L1115"><span class="lineNum">    1115</span>              :   at::Tensor &amp; scatter_(int64_t dim, const at::Tensor &amp; index, const at::Scalar &amp; value) const;</span>
<span id="L1116"><span class="lineNum">    1116</span>              :   at::Tensor scatter(int64_t dim, const at::Tensor &amp; index, const at::Tensor &amp; src, c10::string_view reduce) const;</span>
<span id="L1117"><span class="lineNum">    1117</span>              :   at::Tensor &amp; scatter_(int64_t dim, const at::Tensor &amp; index, const at::Tensor &amp; src, c10::string_view reduce) const;</span>
<span id="L1118"><span class="lineNum">    1118</span>              :   at::Tensor scatter(int64_t dim, const at::Tensor &amp; index, const at::Scalar &amp; value, c10::string_view reduce) const;</span>
<span id="L1119"><span class="lineNum">    1119</span>              :   at::Tensor &amp; scatter_(int64_t dim, const at::Tensor &amp; index, const at::Scalar &amp; value, c10::string_view reduce) const;</span>
<span id="L1120"><span class="lineNum">    1120</span>              :   at::Tensor scatter(at::Dimname dim, const at::Tensor &amp; index, const at::Tensor &amp; src) const;</span>
<span id="L1121"><span class="lineNum">    1121</span>              :   at::Tensor scatter(at::Dimname dim, const at::Tensor &amp; index, const at::Scalar &amp; value) const;</span>
<span id="L1122"><span class="lineNum">    1122</span>              :   at::Tensor scatter_add(int64_t dim, const at::Tensor &amp; index, const at::Tensor &amp; src) const;</span>
<span id="L1123"><span class="lineNum">    1123</span>              :   at::Tensor &amp; scatter_add_(int64_t dim, const at::Tensor &amp; index, const at::Tensor &amp; src) const;</span>
<span id="L1124"><span class="lineNum">    1124</span>              :   at::Tensor scatter_add(at::Dimname dim, const at::Tensor &amp; index, const at::Tensor &amp; src) const;</span>
<span id="L1125"><span class="lineNum">    1125</span>              :   at::Tensor scatter_reduce(int64_t dim, const at::Tensor &amp; index, const at::Tensor &amp; src, c10::string_view reduce, bool include_self=true) const;</span>
<span id="L1126"><span class="lineNum">    1126</span>              :   at::Tensor &amp; scatter_reduce_(int64_t dim, const at::Tensor &amp; index, const at::Tensor &amp; src, c10::string_view reduce, bool include_self=true) const;</span>
<span id="L1127"><span class="lineNum">    1127</span>              :   at::Tensor &amp; eq_(const at::Scalar &amp; other) const;</span>
<span id="L1128"><span class="lineNum">    1128</span>              :   at::Tensor &amp; eq_(const at::Tensor &amp; other) const;</span>
<span id="L1129"><span class="lineNum">    1129</span>              :   at::Tensor bitwise_and(const at::Scalar &amp; other) const;</span>
<span id="L1130"><span class="lineNum">    1130</span>              :   at::Tensor bitwise_and(const at::Tensor &amp; other) const;</span>
<span id="L1131"><span class="lineNum">    1131</span>              :   at::Tensor &amp; bitwise_and_(const at::Scalar &amp; other) const;</span>
<span id="L1132"><span class="lineNum">    1132</span>              :   at::Tensor &amp; bitwise_and_(const at::Tensor &amp; other) const;</span>
<span id="L1133"><span class="lineNum">    1133</span>              :   at::Tensor __and__(const at::Scalar &amp; other) const;</span>
<span id="L1134"><span class="lineNum">    1134</span>              :   at::Tensor __and__(const at::Tensor &amp; other) const;</span>
<span id="L1135"><span class="lineNum">    1135</span>              :   at::Tensor &amp; __iand__(const at::Scalar &amp; other) const;</span>
<span id="L1136"><span class="lineNum">    1136</span>              :   at::Tensor &amp; __iand__(const at::Tensor &amp; other) const;</span>
<span id="L1137"><span class="lineNum">    1137</span>              :   at::Tensor bitwise_or(const at::Scalar &amp; other) const;</span>
<span id="L1138"><span class="lineNum">    1138</span>              :   at::Tensor bitwise_or(const at::Tensor &amp; other) const;</span>
<span id="L1139"><span class="lineNum">    1139</span>              :   at::Tensor &amp; bitwise_or_(const at::Scalar &amp; other) const;</span>
<span id="L1140"><span class="lineNum">    1140</span>              :   at::Tensor &amp; bitwise_or_(const at::Tensor &amp; other) const;</span>
<span id="L1141"><span class="lineNum">    1141</span>              :   at::Tensor __or__(const at::Scalar &amp; other) const;</span>
<span id="L1142"><span class="lineNum">    1142</span>              :   at::Tensor __or__(const at::Tensor &amp; other) const;</span>
<span id="L1143"><span class="lineNum">    1143</span>              :   at::Tensor &amp; __ior__(const at::Scalar &amp; other) const;</span>
<span id="L1144"><span class="lineNum">    1144</span>              :   at::Tensor &amp; __ior__(const at::Tensor &amp; other) const;</span>
<span id="L1145"><span class="lineNum">    1145</span>              :   at::Tensor bitwise_xor(const at::Scalar &amp; other) const;</span>
<span id="L1146"><span class="lineNum">    1146</span>              :   at::Tensor bitwise_xor(const at::Tensor &amp; other) const;</span>
<span id="L1147"><span class="lineNum">    1147</span>              :   at::Tensor &amp; bitwise_xor_(const at::Scalar &amp; other) const;</span>
<span id="L1148"><span class="lineNum">    1148</span>              :   at::Tensor &amp; bitwise_xor_(const at::Tensor &amp; other) const;</span>
<span id="L1149"><span class="lineNum">    1149</span>              :   at::Tensor __xor__(const at::Scalar &amp; other) const;</span>
<span id="L1150"><span class="lineNum">    1150</span>              :   at::Tensor __xor__(const at::Tensor &amp; other) const;</span>
<span id="L1151"><span class="lineNum">    1151</span>              :   at::Tensor &amp; __ixor__(const at::Scalar &amp; other) const;</span>
<span id="L1152"><span class="lineNum">    1152</span>              :   at::Tensor &amp; __ixor__(const at::Tensor &amp; other) const;</span>
<span id="L1153"><span class="lineNum">    1153</span>              :   at::Tensor __lshift__(const at::Scalar &amp; other) const;</span>
<span id="L1154"><span class="lineNum">    1154</span>              :   at::Tensor __lshift__(const at::Tensor &amp; other) const;</span>
<span id="L1155"><span class="lineNum">    1155</span>              :   at::Tensor &amp; __ilshift__(const at::Scalar &amp; other) const;</span>
<span id="L1156"><span class="lineNum">    1156</span>              :   at::Tensor &amp; __ilshift__(const at::Tensor &amp; other) const;</span>
<span id="L1157"><span class="lineNum">    1157</span>              :   at::Tensor bitwise_left_shift(const at::Tensor &amp; other) const;</span>
<span id="L1158"><span class="lineNum">    1158</span>              :   at::Tensor &amp; bitwise_left_shift_(const at::Tensor &amp; other) const;</span>
<span id="L1159"><span class="lineNum">    1159</span>              :   at::Tensor bitwise_left_shift(const at::Scalar &amp; other) const;</span>
<span id="L1160"><span class="lineNum">    1160</span>              :   at::Tensor &amp; bitwise_left_shift_(const at::Scalar &amp; other) const;</span>
<span id="L1161"><span class="lineNum">    1161</span>              :   at::Tensor __rshift__(const at::Scalar &amp; other) const;</span>
<span id="L1162"><span class="lineNum">    1162</span>              :   at::Tensor __rshift__(const at::Tensor &amp; other) const;</span>
<span id="L1163"><span class="lineNum">    1163</span>              :   at::Tensor &amp; __irshift__(const at::Scalar &amp; other) const;</span>
<span id="L1164"><span class="lineNum">    1164</span>              :   at::Tensor &amp; __irshift__(const at::Tensor &amp; other) const;</span>
<span id="L1165"><span class="lineNum">    1165</span>              :   at::Tensor bitwise_right_shift(const at::Tensor &amp; other) const;</span>
<span id="L1166"><span class="lineNum">    1166</span>              :   at::Tensor &amp; bitwise_right_shift_(const at::Tensor &amp; other) const;</span>
<span id="L1167"><span class="lineNum">    1167</span>              :   at::Tensor bitwise_right_shift(const at::Scalar &amp; other) const;</span>
<span id="L1168"><span class="lineNum">    1168</span>              :   at::Tensor &amp; bitwise_right_shift_(const at::Scalar &amp; other) const;</span>
<span id="L1169"><span class="lineNum">    1169</span>              :   at::Tensor &amp; tril_(int64_t diagonal=0) const;</span>
<span id="L1170"><span class="lineNum">    1170</span>              :   at::Tensor &amp; triu_(int64_t diagonal=0) const;</span>
<span id="L1171"><span class="lineNum">    1171</span>              :   at::Tensor &amp; digamma_() const;</span>
<span id="L1172"><span class="lineNum">    1172</span>              :   at::Tensor &amp; lerp_(const at::Tensor &amp; end, const at::Scalar &amp; weight) const;</span>
<span id="L1173"><span class="lineNum">    1173</span>              :   at::Tensor &amp; lerp_(const at::Tensor &amp; end, const at::Tensor &amp; weight) const;</span>
<span id="L1174"><span class="lineNum">    1174</span>              :   at::Tensor &amp; addbmm_(const at::Tensor &amp; batch1, const at::Tensor &amp; batch2, const at::Scalar &amp; beta=1, const at::Scalar &amp; alpha=1) const;</span>
<span id="L1175"><span class="lineNum">    1175</span>              :   at::Tensor addbmm(const at::Tensor &amp; batch1, const at::Tensor &amp; batch2, const at::Scalar &amp; beta=1, const at::Scalar &amp; alpha=1) const;</span>
<span id="L1176"><span class="lineNum">    1176</span>              :   at::Tensor &amp; random_(int64_t from, ::std::optional&lt;int64_t&gt; to, ::std::optional&lt;at::Generator&gt; generator=::std::nullopt) const;</span>
<span id="L1177"><span class="lineNum">    1177</span>              :   at::Tensor &amp; random_(int64_t to, ::std::optional&lt;at::Generator&gt; generator=::std::nullopt) const;</span>
<span id="L1178"><span class="lineNum">    1178</span>              :   at::Tensor &amp; random_(::std::optional&lt;at::Generator&gt; generator=::std::nullopt) const;</span>
<span id="L1179"><span class="lineNum">    1179</span>              :   at::Tensor &amp; uniform_(double from=0, double to=1, ::std::optional&lt;at::Generator&gt; generator=::std::nullopt) const;</span>
<span id="L1180"><span class="lineNum">    1180</span>              :   at::Tensor &amp; cauchy_(double median=0, double sigma=1, ::std::optional&lt;at::Generator&gt; generator=::std::nullopt) const;</span>
<span id="L1181"><span class="lineNum">    1181</span>              :   at::Tensor &amp; log_normal_(double mean=1, double std=2, ::std::optional&lt;at::Generator&gt; generator=::std::nullopt) const;</span>
<span id="L1182"><span class="lineNum">    1182</span>              :   at::Tensor &amp; exponential_(double lambd=1, ::std::optional&lt;at::Generator&gt; generator=::std::nullopt) const;</span>
<span id="L1183"><span class="lineNum">    1183</span>              :   at::Tensor &amp; geometric_(double p, ::std::optional&lt;at::Generator&gt; generator=::std::nullopt) const;</span>
<span id="L1184"><span class="lineNum">    1184</span>              :   at::Tensor diag(int64_t diagonal=0) const;</span>
<span id="L1185"><span class="lineNum">    1185</span>              :   at::Tensor cross(const at::Tensor &amp; other, ::std::optional&lt;int64_t&gt; dim=::std::nullopt) const;</span>
<span id="L1186"><span class="lineNum">    1186</span>              :   at::Tensor triu(int64_t diagonal=0) const;</span>
<span id="L1187"><span class="lineNum">    1187</span>              :   at::Tensor tril(int64_t diagonal=0) const;</span>
<span id="L1188"><span class="lineNum">    1188</span>              :   at::Tensor trace() const;</span>
<span id="L1189"><span class="lineNum">    1189</span>              :   at::Tensor ne(const at::Scalar &amp; other) const;</span>
<span id="L1190"><span class="lineNum">    1190</span>              :   at::Tensor ne(const at::Tensor &amp; other) const;</span>
<span id="L1191"><span class="lineNum">    1191</span>              :   at::Tensor &amp; ne_(const at::Scalar &amp; other) const;</span>
<span id="L1192"><span class="lineNum">    1192</span>              :   at::Tensor &amp; ne_(const at::Tensor &amp; other) const;</span>
<span id="L1193"><span class="lineNum">    1193</span>              :   at::Tensor not_equal(const at::Scalar &amp; other) const;</span>
<span id="L1194"><span class="lineNum">    1194</span>              :   at::Tensor not_equal(const at::Tensor &amp; other) const;</span>
<span id="L1195"><span class="lineNum">    1195</span>              :   at::Tensor &amp; not_equal_(const at::Scalar &amp; other) const;</span>
<span id="L1196"><span class="lineNum">    1196</span>              :   at::Tensor &amp; not_equal_(const at::Tensor &amp; other) const;</span>
<span id="L1197"><span class="lineNum">    1197</span>              :   at::Tensor eq(const at::Scalar &amp; other) const;</span>
<span id="L1198"><span class="lineNum">    1198</span>              :   at::Tensor eq(const at::Tensor &amp; other) const;</span>
<span id="L1199"><span class="lineNum">    1199</span>              :   at::Tensor ge(const at::Scalar &amp; other) const;</span>
<span id="L1200"><span class="lineNum">    1200</span>              :   at::Tensor ge(const at::Tensor &amp; other) const;</span>
<span id="L1201"><span class="lineNum">    1201</span>              :   at::Tensor &amp; ge_(const at::Scalar &amp; other) const;</span>
<span id="L1202"><span class="lineNum">    1202</span>              :   at::Tensor &amp; ge_(const at::Tensor &amp; other) const;</span>
<span id="L1203"><span class="lineNum">    1203</span>              :   at::Tensor greater_equal(const at::Scalar &amp; other) const;</span>
<span id="L1204"><span class="lineNum">    1204</span>              :   at::Tensor greater_equal(const at::Tensor &amp; other) const;</span>
<span id="L1205"><span class="lineNum">    1205</span>              :   at::Tensor &amp; greater_equal_(const at::Scalar &amp; other) const;</span>
<span id="L1206"><span class="lineNum">    1206</span>              :   at::Tensor &amp; greater_equal_(const at::Tensor &amp; other) const;</span>
<span id="L1207"><span class="lineNum">    1207</span>              :   at::Tensor le(const at::Scalar &amp; other) const;</span>
<span id="L1208"><span class="lineNum">    1208</span>              :   at::Tensor le(const at::Tensor &amp; other) const;</span>
<span id="L1209"><span class="lineNum">    1209</span>              :   at::Tensor &amp; le_(const at::Scalar &amp; other) const;</span>
<span id="L1210"><span class="lineNum">    1210</span>              :   at::Tensor &amp; le_(const at::Tensor &amp; other) const;</span>
<span id="L1211"><span class="lineNum">    1211</span>              :   at::Tensor less_equal(const at::Scalar &amp; other) const;</span>
<span id="L1212"><span class="lineNum">    1212</span>              :   at::Tensor less_equal(const at::Tensor &amp; other) const;</span>
<span id="L1213"><span class="lineNum">    1213</span>              :   at::Tensor &amp; less_equal_(const at::Scalar &amp; other) const;</span>
<span id="L1214"><span class="lineNum">    1214</span>              :   at::Tensor &amp; less_equal_(const at::Tensor &amp; other) const;</span>
<span id="L1215"><span class="lineNum">    1215</span>              :   at::Tensor gt(const at::Scalar &amp; other) const;</span>
<span id="L1216"><span class="lineNum">    1216</span>              :   at::Tensor gt(const at::Tensor &amp; other) const;</span>
<span id="L1217"><span class="lineNum">    1217</span>              :   at::Tensor &amp; gt_(const at::Scalar &amp; other) const;</span>
<span id="L1218"><span class="lineNum">    1218</span>              :   at::Tensor &amp; gt_(const at::Tensor &amp; other) const;</span>
<span id="L1219"><span class="lineNum">    1219</span>              :   at::Tensor greater(const at::Scalar &amp; other) const;</span>
<span id="L1220"><span class="lineNum">    1220</span>              :   at::Tensor greater(const at::Tensor &amp; other) const;</span>
<span id="L1221"><span class="lineNum">    1221</span>              :   at::Tensor &amp; greater_(const at::Scalar &amp; other) const;</span>
<span id="L1222"><span class="lineNum">    1222</span>              :   at::Tensor &amp; greater_(const at::Tensor &amp; other) const;</span>
<span id="L1223"><span class="lineNum">    1223</span>              :   at::Tensor lt(const at::Scalar &amp; other) const;</span>
<span id="L1224"><span class="lineNum">    1224</span>              :   at::Tensor lt(const at::Tensor &amp; other) const;</span>
<span id="L1225"><span class="lineNum">    1225</span>              :   at::Tensor &amp; lt_(const at::Scalar &amp; other) const;</span>
<span id="L1226"><span class="lineNum">    1226</span>              :   at::Tensor &amp; lt_(const at::Tensor &amp; other) const;</span>
<span id="L1227"><span class="lineNum">    1227</span>              :   at::Tensor less(const at::Scalar &amp; other) const;</span>
<span id="L1228"><span class="lineNum">    1228</span>              :   at::Tensor less(const at::Tensor &amp; other) const;</span>
<span id="L1229"><span class="lineNum">    1229</span>              :   at::Tensor &amp; less_(const at::Scalar &amp; other) const;</span>
<span id="L1230"><span class="lineNum">    1230</span>              :   at::Tensor &amp; less_(const at::Tensor &amp; other) const;</span>
<span id="L1231"><span class="lineNum">    1231</span>              :   at::Tensor take(const at::Tensor &amp; index) const;</span>
<span id="L1232"><span class="lineNum">    1232</span>              :   at::Tensor take_along_dim(const at::Tensor &amp; indices, ::std::optional&lt;int64_t&gt; dim=::std::nullopt) const;</span>
<span id="L1233"><span class="lineNum">    1233</span>              :   at::Tensor index_select(int64_t dim, const at::Tensor &amp; index) const;</span>
<span id="L1234"><span class="lineNum">    1234</span>              :   at::Tensor index_select(at::Dimname dim, const at::Tensor &amp; index) const;</span>
<span id="L1235"><span class="lineNum">    1235</span>              :   at::Tensor masked_select(const at::Tensor &amp; mask) const;</span>
<span id="L1236"><span class="lineNum">    1236</span>              :   at::Tensor nonzero() const;</span>
<span id="L1237"><span class="lineNum">    1237</span>              :   at::Tensor nonzero_static(int64_t size, int64_t fill_value=-1) const;</span>
<span id="L1238"><span class="lineNum">    1238</span>              :   ::std::vector&lt;at::Tensor&gt; nonzero_numpy() const;</span>
<span id="L1239"><span class="lineNum">    1239</span>              :   at::Tensor argwhere() const;</span>
<span id="L1240"><span class="lineNum">    1240</span>              :   at::Tensor gather(int64_t dim, const at::Tensor &amp; index, bool sparse_grad=false) const;</span>
<span id="L1241"><span class="lineNum">    1241</span>              :   at::Tensor gather(at::Dimname dim, const at::Tensor &amp; index, bool sparse_grad=false) const;</span>
<span id="L1242"><span class="lineNum">    1242</span>              :   at::Tensor addcmul(const at::Tensor &amp; tensor1, const at::Tensor &amp; tensor2, const at::Scalar &amp; value=1) const;</span>
<span id="L1243"><span class="lineNum">    1243</span>              :   at::Tensor &amp; addcmul_(const at::Tensor &amp; tensor1, const at::Tensor &amp; tensor2, const at::Scalar &amp; value=1) const;</span>
<span id="L1244"><span class="lineNum">    1244</span>              :   at::Tensor addcdiv(const at::Tensor &amp; tensor1, const at::Tensor &amp; tensor2, const at::Scalar &amp; value=1) const;</span>
<span id="L1245"><span class="lineNum">    1245</span>              :   at::Tensor &amp; addcdiv_(const at::Tensor &amp; tensor1, const at::Tensor &amp; tensor2, const at::Scalar &amp; value=1) const;</span>
<span id="L1246"><span class="lineNum">    1246</span>              :   ::std::tuple&lt;at::Tensor,at::Tensor&gt; triangular_solve(const at::Tensor &amp; A, bool upper=true, bool transpose=false, bool unitriangular=false) const;</span>
<span id="L1247"><span class="lineNum">    1247</span>              :   ::std::tuple&lt;at::Tensor,at::Tensor,at::Tensor&gt; svd(bool some=true, bool compute_uv=true) const;</span>
<span id="L1248"><span class="lineNum">    1248</span>              :   at::Tensor swapaxes(int64_t axis0, int64_t axis1) const;</span>
<span id="L1249"><span class="lineNum">    1249</span>              :   at::Tensor &amp; swapaxes_(int64_t axis0, int64_t axis1) const;</span>
<span id="L1250"><span class="lineNum">    1250</span>              :   at::Tensor swapdims(int64_t dim0, int64_t dim1) const;</span>
<span id="L1251"><span class="lineNum">    1251</span>              :   at::Tensor &amp; swapdims_(int64_t dim0, int64_t dim1) const;</span>
<span id="L1252"><span class="lineNum">    1252</span>              :   at::Tensor cholesky(bool upper=false) const;</span>
<span id="L1253"><span class="lineNum">    1253</span>              :   at::Tensor cholesky_solve(const at::Tensor &amp; input2, bool upper=false) const;</span>
<span id="L1254"><span class="lineNum">    1254</span>              :   at::Tensor cholesky_inverse(bool upper=false) const;</span>
<span id="L1255"><span class="lineNum">    1255</span>              :   ::std::tuple&lt;at::Tensor,at::Tensor&gt; qr(bool some=true) const;</span>
<span id="L1256"><span class="lineNum">    1256</span>              :   ::std::tuple&lt;at::Tensor,at::Tensor&gt; geqrf() const;</span>
<span id="L1257"><span class="lineNum">    1257</span>              :   at::Tensor orgqr(const at::Tensor &amp; input2) const;</span>
<span id="L1258"><span class="lineNum">    1258</span>              :   at::Tensor ormqr(const at::Tensor &amp; input2, const at::Tensor &amp; input3, bool left=true, bool transpose=false) const;</span>
<span id="L1259"><span class="lineNum">    1259</span>              :   at::Tensor lu_solve(const at::Tensor &amp; LU_data, const at::Tensor &amp; LU_pivots) const;</span>
<span id="L1260"><span class="lineNum">    1260</span>              :   at::Tensor multinomial(int64_t num_samples, bool replacement=false, ::std::optional&lt;at::Generator&gt; generator=::std::nullopt) const;</span>
<span id="L1261"><span class="lineNum">    1261</span>              :   at::Tensor &amp; lgamma_() const;</span>
<span id="L1262"><span class="lineNum">    1262</span>              :   at::Tensor lgamma() const;</span>
<span id="L1263"><span class="lineNum">    1263</span>              :   at::Tensor digamma() const;</span>
<span id="L1264"><span class="lineNum">    1264</span>              :   at::Tensor polygamma(int64_t n) const;</span>
<span id="L1265"><span class="lineNum">    1265</span>              :   at::Tensor &amp; polygamma_(int64_t n) const;</span>
<span id="L1266"><span class="lineNum">    1266</span>              :   at::Tensor erfinv() const;</span>
<span id="L1267"><span class="lineNum">    1267</span>              :   at::Tensor &amp; erfinv_() const;</span>
<span id="L1268"><span class="lineNum">    1268</span>              :   at::Tensor i0() const;</span>
<span id="L1269"><span class="lineNum">    1269</span>              :   at::Tensor &amp; i0_() const;</span>
<span id="L1270"><span class="lineNum">    1270</span>              :   at::Tensor sign() const;</span>
<span id="L1271"><span class="lineNum">    1271</span>              :   at::Tensor &amp; sign_() const;</span>
<span id="L1272"><span class="lineNum">    1272</span>              :   at::Tensor signbit() const;</span>
<span id="L1273"><span class="lineNum">    1273</span>              :   at::Tensor dist(const at::Tensor &amp; other, const at::Scalar &amp; p=2) const;</span>
<span id="L1274"><span class="lineNum">    1274</span>              :   at::Tensor &amp; atan2_(const at::Tensor &amp; other) const;</span>
<span id="L1275"><span class="lineNum">    1275</span>              :   at::Tensor atan2(const at::Tensor &amp; other) const;</span>
<span id="L1276"><span class="lineNum">    1276</span>              :   at::Tensor arctan2(const at::Tensor &amp; other) const;</span>
<span id="L1277"><span class="lineNum">    1277</span>              :   at::Tensor &amp; arctan2_(const at::Tensor &amp; other) const;</span>
<span id="L1278"><span class="lineNum">    1278</span>              :   at::Tensor lerp(const at::Tensor &amp; end, const at::Scalar &amp; weight) const;</span>
<span id="L1279"><span class="lineNum">    1279</span>              :   at::Tensor lerp(const at::Tensor &amp; end, const at::Tensor &amp; weight) const;</span>
<span id="L1280"><span class="lineNum">    1280</span>              :   at::Tensor histc(int64_t bins=100, const at::Scalar &amp; min=0, const at::Scalar &amp; max=0) const;</span>
<span id="L1281"><span class="lineNum">    1281</span>              :   ::std::tuple&lt;at::Tensor,at::Tensor&gt; histogram(const at::Tensor &amp; bins, const ::std::optional&lt;at::Tensor&gt; &amp; weight={}, bool density=false) const;</span>
<span id="L1282"><span class="lineNum">    1282</span>              :   ::std::tuple&lt;at::Tensor,at::Tensor&gt; histogram(int64_t bins=100, ::std::optional&lt;at::ArrayRef&lt;double&gt;&gt; range=::std::nullopt, const ::std::optional&lt;at::Tensor&gt; &amp; weight={}, bool density=false) const;</span>
<span id="L1283"><span class="lineNum">    1283</span>              :   at::Tensor fmod(const at::Scalar &amp; other) const;</span>
<span id="L1284"><span class="lineNum">    1284</span>              :   at::Tensor &amp; fmod_(const at::Scalar &amp; other) const;</span>
<span id="L1285"><span class="lineNum">    1285</span>              :   at::Tensor fmod(const at::Tensor &amp; other) const;</span>
<span id="L1286"><span class="lineNum">    1286</span>              :   at::Tensor &amp; fmod_(const at::Tensor &amp; other) const;</span>
<span id="L1287"><span class="lineNum">    1287</span>              :   at::Tensor hypot(const at::Tensor &amp; other) const;</span>
<span id="L1288"><span class="lineNum">    1288</span>              :   at::Tensor &amp; hypot_(const at::Tensor &amp; other) const;</span>
<span id="L1289"><span class="lineNum">    1289</span>              :   at::Tensor igamma(const at::Tensor &amp; other) const;</span>
<span id="L1290"><span class="lineNum">    1290</span>              :   at::Tensor &amp; igamma_(const at::Tensor &amp; other) const;</span>
<span id="L1291"><span class="lineNum">    1291</span>              :   at::Tensor igammac(const at::Tensor &amp; other) const;</span>
<span id="L1292"><span class="lineNum">    1292</span>              :   at::Tensor &amp; igammac_(const at::Tensor &amp; other) const;</span>
<span id="L1293"><span class="lineNum">    1293</span>              :   at::Tensor nextafter(const at::Tensor &amp; other) const;</span>
<span id="L1294"><span class="lineNum">    1294</span>              :   at::Tensor &amp; nextafter_(const at::Tensor &amp; other) const;</span>
<span id="L1295"><span class="lineNum">    1295</span>              :   at::Tensor remainder(const at::Scalar &amp; other) const;</span>
<span id="L1296"><span class="lineNum">    1296</span>              :   at::Tensor &amp; remainder_(const at::Scalar &amp; other) const;</span>
<span id="L1297"><span class="lineNum">    1297</span>              :   at::Tensor remainder(const at::Tensor &amp; other) const;</span>
<span id="L1298"><span class="lineNum">    1298</span>              :   at::Tensor &amp; remainder_(const at::Tensor &amp; other) const;</span>
<span id="L1299"><span class="lineNum">    1299</span>              :   at::Tensor min() const;</span>
<span id="L1300"><span class="lineNum">    1300</span>              :   at::Tensor fmin(const at::Tensor &amp; other) const;</span>
<span id="L1301"><span class="lineNum">    1301</span>              :   at::Tensor max() const;</span>
<span id="L1302"><span class="lineNum">    1302</span>              :   at::Tensor fmax(const at::Tensor &amp; other) const;</span>
<span id="L1303"><span class="lineNum">    1303</span>              :   at::Tensor maximum(const at::Tensor &amp; other) const;</span>
<span id="L1304"><span class="lineNum">    1304</span>              :   at::Tensor max(const at::Tensor &amp; other) const;</span>
<span id="L1305"><span class="lineNum">    1305</span>              :   at::Tensor minimum(const at::Tensor &amp; other) const;</span>
<span id="L1306"><span class="lineNum">    1306</span>              :   at::Tensor min(const at::Tensor &amp; other) const;</span>
<span id="L1307"><span class="lineNum">    1307</span>              :   at::Tensor quantile(const at::Tensor &amp; q, ::std::optional&lt;int64_t&gt; dim=::std::nullopt, bool keepdim=false, c10::string_view interpolation=&quot;linear&quot;) const;</span>
<span id="L1308"><span class="lineNum">    1308</span>              :   at::Tensor quantile(double q, ::std::optional&lt;int64_t&gt; dim=::std::nullopt, bool keepdim=false, c10::string_view interpolation=&quot;linear&quot;) const;</span>
<span id="L1309"><span class="lineNum">    1309</span>              :   at::Tensor nanquantile(const at::Tensor &amp; q, ::std::optional&lt;int64_t&gt; dim=::std::nullopt, bool keepdim=false, c10::string_view interpolation=&quot;linear&quot;) const;</span>
<span id="L1310"><span class="lineNum">    1310</span>              :   at::Tensor nanquantile(double q, ::std::optional&lt;int64_t&gt; dim=::std::nullopt, bool keepdim=false, c10::string_view interpolation=&quot;linear&quot;) const;</span>
<span id="L1311"><span class="lineNum">    1311</span>              :   ::std::tuple&lt;at::Tensor,at::Tensor&gt; sort(int64_t dim=-1, bool descending=false) const;</span>
<span id="L1312"><span class="lineNum">    1312</span>              :   ::std::tuple&lt;at::Tensor,at::Tensor&gt; sort(::std::optional&lt;bool&gt; stable, int64_t dim=-1, bool descending=false) const;</span>
<span id="L1313"><span class="lineNum">    1313</span>              :   ::std::tuple&lt;at::Tensor,at::Tensor&gt; sort(at::Dimname dim, bool descending=false) const;</span>
<span id="L1314"><span class="lineNum">    1314</span>              :   ::std::tuple&lt;at::Tensor,at::Tensor&gt; sort(::std::optional&lt;bool&gt; stable, at::Dimname dim, bool descending=false) const;</span>
<span id="L1315"><span class="lineNum">    1315</span>              :   at::Tensor msort() const;</span>
<span id="L1316"><span class="lineNum">    1316</span>              :   at::Tensor argsort(int64_t dim=-1, bool descending=false) const;</span>
<span id="L1317"><span class="lineNum">    1317</span>              :   at::Tensor argsort(bool stable, int64_t dim=-1, bool descending=false) const;</span>
<span id="L1318"><span class="lineNum">    1318</span>              :   at::Tensor argsort(at::Dimname dim, bool descending=false) const;</span>
<span id="L1319"><span class="lineNum">    1319</span>              :   ::std::tuple&lt;at::Tensor,at::Tensor&gt; topk(int64_t k, int64_t dim=-1, bool largest=true, bool sorted=true) const;</span>
<span id="L1320"><span class="lineNum">    1320</span>              :   ::std::tuple&lt;at::Tensor,at::Tensor&gt; topk_symint(c10::SymInt k, int64_t dim=-1, bool largest=true, bool sorted=true) const;</span>
<span id="L1321"><span class="lineNum">    1321</span>              :   at::Tensor all() const;</span>
<span id="L1322"><span class="lineNum">    1322</span>              :   at::Tensor any() const;</span>
<span id="L1323"><span class="lineNum">    1323</span>              :   at::Tensor renorm(const at::Scalar &amp; p, int64_t dim, const at::Scalar &amp; maxnorm) const;</span>
<span id="L1324"><span class="lineNum">    1324</span>              :   at::Tensor &amp; renorm_(const at::Scalar &amp; p, int64_t dim, const at::Scalar &amp; maxnorm) const;</span>
<span id="L1325"><span class="lineNum">    1325</span>              :   at::Tensor unfold(int64_t dimension, int64_t size, int64_t step) const;</span>
<span id="L1326"><span class="lineNum">    1326</span>              :   bool equal(const at::Tensor &amp; other) const;</span>
<span id="L1327"><span class="lineNum">    1327</span>              :   at::Tensor pow(const at::Tensor &amp; exponent) const;</span>
<span id="L1328"><span class="lineNum">    1328</span>              :   at::Tensor pow(const at::Scalar &amp; exponent) const;</span>
<span id="L1329"><span class="lineNum">    1329</span>              :   at::Tensor &amp; pow_(const at::Scalar &amp; exponent) const;</span>
<span id="L1330"><span class="lineNum">    1330</span>              :   at::Tensor &amp; pow_(const at::Tensor &amp; exponent) const;</span>
<span id="L1331"><span class="lineNum">    1331</span>              :   at::Tensor float_power(const at::Tensor &amp; exponent) const;</span>
<span id="L1332"><span class="lineNum">    1332</span>              :   at::Tensor float_power(const at::Scalar &amp; exponent) const;</span>
<span id="L1333"><span class="lineNum">    1333</span>              :   at::Tensor &amp; float_power_(const at::Scalar &amp; exponent) const;</span>
<span id="L1334"><span class="lineNum">    1334</span>              :   at::Tensor &amp; float_power_(const at::Tensor &amp; exponent) const;</span>
<span id="L1335"><span class="lineNum">    1335</span>              :   at::Tensor &amp; normal_(double mean=0, double std=1, ::std::optional&lt;at::Generator&gt; generator=::std::nullopt) const;</span>
<span id="L1336"><span class="lineNum">    1336</span>              :   at::Tensor alias() const;</span>
<span id="L1337"><span class="lineNum">    1337</span>              :   at::Tensor isfinite() const;</span>
<span id="L1338"><span class="lineNum">    1338</span>              :   at::Tensor isinf() const;</span>
<span id="L1339"><span class="lineNum">    1339</span>              :   void record_stream(at::Stream s) const;</span>
<span id="L1340"><span class="lineNum">    1340</span>              :   at::Tensor isposinf() const;</span>
<span id="L1341"><span class="lineNum">    1341</span>              :   at::Tensor isneginf() const;</span>
<span id="L1342"><span class="lineNum">    1342</span>              :   at::Tensor det() const;</span>
<span id="L1343"><span class="lineNum">    1343</span>              :   ::std::tuple&lt;at::Tensor,at::Tensor&gt; slogdet() const;</span>
<span id="L1344"><span class="lineNum">    1344</span>              :   at::Tensor logdet() const;</span>
<span id="L1345"><span class="lineNum">    1345</span>              :   at::Tensor inverse() const;</span>
<span id="L1346"><span class="lineNum">    1346</span>              :   at::Tensor inner(const at::Tensor &amp; other) const;</span>
<span id="L1347"><span class="lineNum">    1347</span>              :   at::Tensor outer(const at::Tensor &amp; vec2) const;</span>
<span id="L1348"><span class="lineNum">    1348</span>              :   at::Tensor ger(const at::Tensor &amp; vec2) const;</span>
<span id="L1349"><span class="lineNum">    1349</span>              :   at::Tensor to_padded_tensor(double padding, at::OptionalIntArrayRef output_size=::std::nullopt) const;</span>
<span id="L1350"><span class="lineNum">    1350</span>              :   at::Tensor to_padded_tensor_symint(double padding, at::OptionalSymIntArrayRef output_size=::std::nullopt) const;</span>
<span id="L1351"><span class="lineNum">    1351</span>              : </span>
<span id="L1352"><span class="lineNum">    1352</span>              :   // Special C++ only overloads for std()-like functions (See gh-40287)</span>
<span id="L1353"><span class="lineNum">    1353</span>              :   // These are needed because int -&gt; bool conversion takes precedence over int -&gt; IntArrayRef</span>
<span id="L1354"><span class="lineNum">    1354</span>              :   // So, for example std(0) would select the std(unbiased=False) overload</span>
<span id="L1355"><span class="lineNum">    1355</span>              : </span>
<span id="L1356"><span class="lineNum">    1356</span>              :   Tensor var(int dim) const {</span>
<span id="L1357"><span class="lineNum">    1357</span>              :     return var(IntArrayRef{dim});</span>
<span id="L1358"><span class="lineNum">    1358</span>              :   }</span>
<span id="L1359"><span class="lineNum">    1359</span>              : </span>
<span id="L1360"><span class="lineNum">    1360</span>              :   Tensor std(int dim) const {</span>
<span id="L1361"><span class="lineNum">    1361</span>              :     return std(IntArrayRef{dim});</span>
<span id="L1362"><span class="lineNum">    1362</span>              :   }</span>
<span id="L1363"><span class="lineNum">    1363</span>              : </span>
<span id="L1364"><span class="lineNum">    1364</span>              :   // We changed .dtype() to return a TypeMeta in #12766. Ideally, we want the</span>
<span id="L1365"><span class="lineNum">    1365</span>              :   // at::kDouble and its friends to be TypeMeta's, but that hasn't happened yet.</span>
<span id="L1366"><span class="lineNum">    1366</span>              :   // Before that change, we make this method to maintain BC for C++ usage like</span>
<span id="L1367"><span class="lineNum">    1367</span>              :   // `x.to(y.dtype)`.</span>
<span id="L1368"><span class="lineNum">    1368</span>              :   // TODO: remove following two after at::kDouble and its friends are TypeMeta's.</span>
<span id="L1369"><span class="lineNum">    1369</span>              :   inline Tensor to(caffe2::TypeMeta type_meta, bool non_blocking=false, bool copy=false) const {</span>
<span id="L1370"><span class="lineNum">    1370</span>              :     return this-&gt;to(/*scalar_type=*/typeMetaToScalarType(type_meta), non_blocking, copy);</span>
<span id="L1371"><span class="lineNum">    1371</span>              :   }</span>
<span id="L1372"><span class="lineNum">    1372</span>              :   inline Tensor to(Device device, caffe2::TypeMeta type_meta, bool non_blocking=false, bool copy=false) const {</span>
<span id="L1373"><span class="lineNum">    1373</span>              :     return this-&gt;to(device, /*scalar_type=*/typeMetaToScalarType(type_meta), non_blocking, copy);</span>
<span id="L1374"><span class="lineNum">    1374</span>              :   }</span>
<span id="L1375"><span class="lineNum">    1375</span>              : </span>
<span id="L1376"><span class="lineNum">    1376</span>              :   template &lt;typename F, typename... Args&gt;</span>
<span id="L1377"><span class="lineNum">    1377</span>              :   decltype(auto) m(F func, Args&amp;&amp;... params) const {</span>
<span id="L1378"><span class="lineNum">    1378</span>              :     return func(*this, std::forward&lt;Args&gt;(params)...);</span>
<span id="L1379"><span class="lineNum">    1379</span>              :   }</span>
<span id="L1380"><span class="lineNum">    1380</span>              : </span>
<span id="L1381"><span class="lineNum">    1381</span>              :   /// NOTE: This is similar to the legacy `.data()` function on `Variable`, and is intended</span>
<span id="L1382"><span class="lineNum">    1382</span>              :   /// to be used from functions that need to access the `Variable`'s equivalent `Tensor`</span>
<span id="L1383"><span class="lineNum">    1383</span>              :   /// (i.e. `Tensor` that shares the same storage and tensor metadata with the `Variable`).</span>
<span id="L1384"><span class="lineNum">    1384</span>              :   ///</span>
<span id="L1385"><span class="lineNum">    1385</span>              :   /// One notable difference with the legacy `.data()` function is that changes to the</span>
<span id="L1386"><span class="lineNum">    1386</span>              :   /// returned `Tensor`'s tensor metadata (e.g. sizes / strides / storage / storage_offset)</span>
<span id="L1387"><span class="lineNum">    1387</span>              :   /// will not update the original `Variable`, due to the fact that this function</span>
<span id="L1388"><span class="lineNum">    1388</span>              :   /// shallow-copies the `Variable`'s underlying TensorImpl.</span>
<span id="L1389"><span class="lineNum">    1389</span>              :   at::Tensor tensor_data() const {</span>
<span id="L1390"><span class="lineNum">    1390</span>              :     return TensorBase::tensor_data();</span>
<span id="L1391"><span class="lineNum">    1391</span>              :   }</span>
<span id="L1392"><span class="lineNum">    1392</span>              : </span>
<span id="L1393"><span class="lineNum">    1393</span>              :   /// NOTE: `var.variable_data()` in C++ has the same semantics as `tensor.data`</span>
<span id="L1394"><span class="lineNum">    1394</span>              :   /// in Python, which create a new `Variable` that shares the same storage and</span>
<span id="L1395"><span class="lineNum">    1395</span>              :   /// tensor metadata with the original `Variable`, but with a completely new</span>
<span id="L1396"><span class="lineNum">    1396</span>              :   /// autograd history.</span>
<span id="L1397"><span class="lineNum">    1397</span>              :   ///</span>
<span id="L1398"><span class="lineNum">    1398</span>              :   /// NOTE: If we change the tensor metadata (e.g. sizes / strides /</span>
<span id="L1399"><span class="lineNum">    1399</span>              :   /// storage / storage_offset) of a variable created from `var.variable_data()`, those</span>
<span id="L1400"><span class="lineNum">    1400</span>              :   /// changes will not update the original variable `var`. In `.variable_data()`, we set</span>
<span id="L1401"><span class="lineNum">    1401</span>              :   /// `allow_tensor_metadata_change_` to false to make such changes explicitly illegal,</span>
<span id="L1402"><span class="lineNum">    1402</span>              :   /// in order to prevent users from changing metadata of `var.variable_data()`</span>
<span id="L1403"><span class="lineNum">    1403</span>              :   /// and expecting the original variable `var` to also be updated.</span>
<span id="L1404"><span class="lineNum">    1404</span>              :   at::Tensor variable_data() const {</span>
<span id="L1405"><span class="lineNum">    1405</span>              :     return TensorBase::variable_data();</span>
<span id="L1406"><span class="lineNum">    1406</span>              :   }</span>
<span id="L1407"><span class="lineNum">    1407</span>              : </span>
<span id="L1408"><span class="lineNum">    1408</span>              :   // Hooks</span>
<span id="L1409"><span class="lineNum">    1409</span>              :   //~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span>
<span id="L1410"><span class="lineNum">    1410</span>              : </span>
<span id="L1411"><span class="lineNum">    1411</span>              :   template &lt;typename T&gt;</span>
<span id="L1412"><span class="lineNum">    1412</span>              :   using hook_return_void_t = std::enable_if_t&lt;std::is_void&lt;typename std::invoke_result_t&lt;T&amp;, Tensor&gt;&gt;::value, unsigned&gt;;</span>
<span id="L1413"><span class="lineNum">    1413</span>              :   template &lt;typename T&gt;</span>
<span id="L1414"><span class="lineNum">    1414</span>              :   using hook_return_var_t = std::enable_if_t&lt;std::is_same&lt;typename std::invoke_result_t&lt;T&amp;, Tensor&gt;, Tensor&gt;::value, unsigned&gt;;</span>
<span id="L1415"><span class="lineNum">    1415</span>              : </span>
<span id="L1416"><span class="lineNum">    1416</span>              :   /// Registers a backward hook.</span>
<span id="L1417"><span class="lineNum">    1417</span>              :   ///</span>
<span id="L1418"><span class="lineNum">    1418</span>              :   /// The hook will be called every time a gradient with respect to the Tensor is computed.</span>
<span id="L1419"><span class="lineNum">    1419</span>              :   /// The hook should have one of the following signature:</span>
<span id="L1420"><span class="lineNum">    1420</span>              :   /// ```</span>
<span id="L1421"><span class="lineNum">    1421</span>              :   /// hook(Tensor grad) -&gt; Tensor</span>
<span id="L1422"><span class="lineNum">    1422</span>              :   /// ```</span>
<span id="L1423"><span class="lineNum">    1423</span>              :   /// ```</span>
<span id="L1424"><span class="lineNum">    1424</span>              :   /// hook(Tensor grad) -&gt; void</span>
<span id="L1425"><span class="lineNum">    1425</span>              :   /// ```</span>
<span id="L1426"><span class="lineNum">    1426</span>              :   /// The hook should not modify its argument, but it can optionally return a new gradient</span>
<span id="L1427"><span class="lineNum">    1427</span>              :   /// which will be used in place of `grad`.</span>
<span id="L1428"><span class="lineNum">    1428</span>              :   ///</span>
<span id="L1429"><span class="lineNum">    1429</span>              :   /// This function returns the index of the hook in the list which can be used to remove hook.</span>
<span id="L1430"><span class="lineNum">    1430</span>              :   ///</span>
<span id="L1431"><span class="lineNum">    1431</span>              :   /// Example:</span>
<span id="L1432"><span class="lineNum">    1432</span>              :   /// @code</span>
<span id="L1433"><span class="lineNum">    1433</span>              :   /// auto v = torch::tensor({0., 0., 0.}, torch::requires_grad());</span>
<span id="L1434"><span class="lineNum">    1434</span>              :   /// auto h = v.register_hook([](torch::Tensor grad){ return grad * 2; }); // double the gradient</span>
<span id="L1435"><span class="lineNum">    1435</span>              :   /// v.backward(torch::tensor({1., 2., 3.}));</span>
<span id="L1436"><span class="lineNum">    1436</span>              :   /// // This prints:</span>
<span id="L1437"><span class="lineNum">    1437</span>              :   /// // ```</span>
<span id="L1438"><span class="lineNum">    1438</span>              :   /// //  2</span>
<span id="L1439"><span class="lineNum">    1439</span>              :   /// //  4</span>
<span id="L1440"><span class="lineNum">    1440</span>              :   /// //  6</span>
<span id="L1441"><span class="lineNum">    1441</span>              :   /// // [ CPUFloatType{3} ]</span>
<span id="L1442"><span class="lineNum">    1442</span>              :   /// // ```</span>
<span id="L1443"><span class="lineNum">    1443</span>              :   /// std::cout &lt;&lt; v.grad() &lt;&lt; std::endl;</span>
<span id="L1444"><span class="lineNum">    1444</span>              :   /// v.remove_hook(h);  // removes the hook</span>
<span id="L1445"><span class="lineNum">    1445</span>              :   /// @endcode</span>
<span id="L1446"><span class="lineNum">    1446</span>              :   template &lt;typename T&gt;</span>
<span id="L1447"><span class="lineNum">    1447</span>              :   hook_return_void_t&lt;T&gt; register_hook(T&amp;&amp; hook) const;</span>
<span id="L1448"><span class="lineNum">    1448</span>              :   template &lt;typename T&gt;</span>
<span id="L1449"><span class="lineNum">    1449</span>              :   hook_return_var_t&lt;T&gt; register_hook(T&amp;&amp; hook) const;</span>
<span id="L1450"><span class="lineNum">    1450</span>              : </span>
<span id="L1451"><span class="lineNum">    1451</span>              :   // Variable methods</span>
<span id="L1452"><span class="lineNum">    1452</span>              :   //~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span>
<span id="L1453"><span class="lineNum">    1453</span>              : </span>
<span id="L1454"><span class="lineNum">    1454</span>              :   Tensor data() const {</span>
<span id="L1455"><span class="lineNum">    1455</span>              :     return TensorBase::data();</span>
<span id="L1456"><span class="lineNum">    1456</span>              :   }</span>
<span id="L1457"><span class="lineNum">    1457</span>              : </span>
<span id="L1458"><span class="lineNum">    1458</span>              :   void _backward(TensorList inputs, const std::optional&lt;Tensor&gt;&amp; gradient, std::optional&lt;bool&gt; keep_graph, bool create_graph) const;</span>
<span id="L1459"><span class="lineNum">    1459</span>              : </span>
<span id="L1460"><span class="lineNum">    1460</span>              :   const Tensor&amp; requires_grad_(bool _requires_grad=true) const {</span>
<span id="L1461"><span class="lineNum">    1461</span>              :     TensorBase::requires_grad_(_requires_grad);</span>
<span id="L1462"><span class="lineNum">    1462</span>              :     return *this;</span>
<span id="L1463"><span class="lineNum">    1463</span>              :   }</span>
<span id="L1464"><span class="lineNum">    1464</span>              : };</span>
<span id="L1465"><span class="lineNum">    1465</span>              : </span>
<span id="L1466"><span class="lineNum">    1466</span>              : namespace detail {</span>
<span id="L1467"><span class="lineNum">    1467</span>              : // Helper creator for Tensor class which doesn't requires the users to pass</span>
<span id="L1468"><span class="lineNum">    1468</span>              : // in an intrusive_ptr instead it just converts the argument passed to</span>
<span id="L1469"><span class="lineNum">    1469</span>              : // requested intrusive_ptr type.</span>
<span id="L1470"><span class="lineNum">    1470</span>              : template &lt;typename T, typename... Args&gt;</span>
<span id="L1471"><span class="lineNum">    1471</span>              : Tensor make_tensor(Args&amp;&amp;... args) {</span>
<span id="L1472"><span class="lineNum">    1472</span>              :   return Tensor(c10::make_intrusive&lt;T&gt;(std::forward&lt;Args&gt;(args)...));</span>
<span id="L1473"><span class="lineNum">    1473</span>              : }</span>
<span id="L1474"><span class="lineNum">    1474</span>              : </span>
<span id="L1475"><span class="lineNum">    1475</span>              : } // namespace detail</span>
<span id="L1476"><span class="lineNum">    1476</span>              : </span>
<span id="L1477"><span class="lineNum">    1477</span>              : } // namespace at</span>
<span id="L1478"><span class="lineNum">    1478</span>              : </span>
<span id="L1479"><span class="lineNum">    1479</span>              : </span>
<span id="L1480"><span class="lineNum">    1480</span>              : namespace at {</span>
<span id="L1481"><span class="lineNum">    1481</span>              : </span>
<span id="L1482"><span class="lineNum">    1482</span>              : // aten::_backward(Tensor self, Tensor[] inputs, Tensor? gradient=None, bool? retain_graph=None, bool create_graph=False) -&gt; ()</span>
<span id="L1483"><span class="lineNum">    1483</span>              : inline void Tensor::__dispatch__backward(at::TensorList inputs, const ::std::optional&lt;at::Tensor&gt; &amp; gradient, ::std::optional&lt;bool&gt; retain_graph, bool create_graph) const {</span>
<span id="L1484"><span class="lineNum">    1484</span>              :     return at::_ops::_backward::call(const_cast&lt;Tensor&amp;&gt;(*this), inputs, gradient, retain_graph, create_graph);</span>
<span id="L1485"><span class="lineNum">    1485</span>              : }</span>
<span id="L1486"><span class="lineNum">    1486</span>              : </span>
<span id="L1487"><span class="lineNum">    1487</span>              : // aten::set_data(Tensor(a!) self, Tensor new_data) -&gt; ()</span>
<span id="L1488"><span class="lineNum">    1488</span>              : inline void Tensor::__dispatch_set_data(const at::Tensor &amp; new_data) const {</span>
<span id="L1489"><span class="lineNum">    1489</span>              :     return at::_ops::set_data::call(const_cast&lt;Tensor&amp;&gt;(*this), new_data);</span>
<span id="L1490"><span class="lineNum">    1490</span>              : }</span>
<span id="L1491"><span class="lineNum">    1491</span>              : </span>
<span id="L1492"><span class="lineNum">    1492</span>              : // aten::data(Tensor self) -&gt; Tensor</span>
<span id="L1493"><span class="lineNum">    1493</span>              : inline at::Tensor Tensor::__dispatch_data() const {</span>
<span id="L1494"><span class="lineNum">    1494</span>              :     return at::_ops::data::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1495"><span class="lineNum">    1495</span>              : }</span>
<span id="L1496"><span class="lineNum">    1496</span>              : </span>
<span id="L1497"><span class="lineNum">    1497</span>              : // aten::is_leaf(Tensor self) -&gt; bool</span>
<span id="L1498"><span class="lineNum">    1498</span>              : inline bool Tensor::__dispatch_is_leaf() const {</span>
<span id="L1499"><span class="lineNum">    1499</span>              :     return at::_ops::is_leaf::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1500"><span class="lineNum">    1500</span>              : }</span>
<span id="L1501"><span class="lineNum">    1501</span>              : </span>
<span id="L1502"><span class="lineNum">    1502</span>              : // aten::output_nr(Tensor self) -&gt; int</span>
<span id="L1503"><span class="lineNum">    1503</span>              : inline int64_t Tensor::__dispatch_output_nr() const {</span>
<span id="L1504"><span class="lineNum">    1504</span>              :     return at::_ops::output_nr::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1505"><span class="lineNum">    1505</span>              : }</span>
<span id="L1506"><span class="lineNum">    1506</span>              : </span>
<span id="L1507"><span class="lineNum">    1507</span>              : // aten::_version(Tensor self) -&gt; int</span>
<span id="L1508"><span class="lineNum">    1508</span>              : inline int64_t Tensor::__dispatch__version() const {</span>
<span id="L1509"><span class="lineNum">    1509</span>              :     return at::_ops::_version::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1510"><span class="lineNum">    1510</span>              : }</span>
<span id="L1511"><span class="lineNum">    1511</span>              : </span>
<span id="L1512"><span class="lineNum">    1512</span>              : // aten::requires_grad_(Tensor(a!) self, bool requires_grad=True) -&gt; Tensor(a!)</span>
<span id="L1513"><span class="lineNum">    1513</span>              : inline at::Tensor &amp; Tensor::__dispatch_requires_grad_(bool requires_grad) const {</span>
<span id="L1514"><span class="lineNum">    1514</span>              :     return at::_ops::requires_grad_::call(const_cast&lt;Tensor&amp;&gt;(*this), requires_grad);</span>
<span id="L1515"><span class="lineNum">    1515</span>              : }</span>
<span id="L1516"><span class="lineNum">    1516</span>              : </span>
<span id="L1517"><span class="lineNum">    1517</span>              : // aten::retain_grad(Tensor(a!) self) -&gt; ()</span>
<span id="L1518"><span class="lineNum">    1518</span>              : inline void Tensor::__dispatch_retain_grad() const {</span>
<span id="L1519"><span class="lineNum">    1519</span>              :     return at::_ops::retain_grad::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1520"><span class="lineNum">    1520</span>              : }</span>
<span id="L1521"><span class="lineNum">    1521</span>              : </span>
<span id="L1522"><span class="lineNum">    1522</span>              : // aten::retains_grad(Tensor self) -&gt; bool</span>
<span id="L1523"><span class="lineNum">    1523</span>              : inline bool Tensor::__dispatch_retains_grad() const {</span>
<span id="L1524"><span class="lineNum">    1524</span>              :     return at::_ops::retains_grad::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1525"><span class="lineNum">    1525</span>              : }</span>
<span id="L1526"><span class="lineNum">    1526</span>              : </span>
<span id="L1527"><span class="lineNum">    1527</span>              : // aten::_fw_primal(Tensor(a) self, int level) -&gt; Tensor(a)</span>
<span id="L1528"><span class="lineNum">    1528</span>              : inline at::Tensor Tensor::_fw_primal(int64_t level) const {</span>
<span id="L1529"><span class="lineNum">    1529</span>              :     return at::_ops::_fw_primal::call(const_cast&lt;Tensor&amp;&gt;(*this), level);</span>
<span id="L1530"><span class="lineNum">    1530</span>              : }</span>
<span id="L1531"><span class="lineNum">    1531</span>              : </span>
<span id="L1532"><span class="lineNum">    1532</span>              : // aten::rename_(Tensor(a!) self, Dimname[]? names) -&gt; Tensor(a!)</span>
<span id="L1533"><span class="lineNum">    1533</span>              : inline at::Tensor &amp; Tensor::rename_(::std::optional&lt;at::DimnameList&gt; names) const {</span>
<span id="L1534"><span class="lineNum">    1534</span>              :     return at::_ops::rename_::call(const_cast&lt;Tensor&amp;&gt;(*this), names);</span>
<span id="L1535"><span class="lineNum">    1535</span>              : }</span>
<span id="L1536"><span class="lineNum">    1536</span>              : </span>
<span id="L1537"><span class="lineNum">    1537</span>              : // aten::rename(Tensor(a) self, Dimname[]? names) -&gt; Tensor(a)</span>
<span id="L1538"><span class="lineNum">    1538</span>              : inline at::Tensor Tensor::rename(::std::optional&lt;at::DimnameList&gt; names) const {</span>
<span id="L1539"><span class="lineNum">    1539</span>              :     return at::_ops::rename::call(const_cast&lt;Tensor&amp;&gt;(*this), names);</span>
<span id="L1540"><span class="lineNum">    1540</span>              : }</span>
<span id="L1541"><span class="lineNum">    1541</span>              : </span>
<span id="L1542"><span class="lineNum">    1542</span>              : // aten::align_to(Tensor(a) self, Dimname[] names) -&gt; Tensor(a)</span>
<span id="L1543"><span class="lineNum">    1543</span>              : inline at::Tensor Tensor::align_to(at::DimnameList names) const {</span>
<span id="L1544"><span class="lineNum">    1544</span>              :     return at::_ops::align_to::call(const_cast&lt;Tensor&amp;&gt;(*this), names);</span>
<span id="L1545"><span class="lineNum">    1545</span>              : }</span>
<span id="L1546"><span class="lineNum">    1546</span>              : </span>
<span id="L1547"><span class="lineNum">    1547</span>              : // aten::align_to.ellipsis_idx(Tensor(a) self, Dimname[] order, int ellipsis_idx) -&gt; Tensor(a)</span>
<span id="L1548"><span class="lineNum">    1548</span>              : inline at::Tensor Tensor::align_to(at::DimnameList order, int64_t ellipsis_idx) const {</span>
<span id="L1549"><span class="lineNum">    1549</span>              :     return at::_ops::align_to_ellipsis_idx::call(const_cast&lt;Tensor&amp;&gt;(*this), order, ellipsis_idx);</span>
<span id="L1550"><span class="lineNum">    1550</span>              : }</span>
<span id="L1551"><span class="lineNum">    1551</span>              : </span>
<span id="L1552"><span class="lineNum">    1552</span>              : // aten::align_as(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L1553"><span class="lineNum">    1553</span>              : inline at::Tensor Tensor::align_as(const at::Tensor &amp; other) const {</span>
<span id="L1554"><span class="lineNum">    1554</span>              :     return at::_ops::align_as::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L1555"><span class="lineNum">    1555</span>              : }</span>
<span id="L1556"><span class="lineNum">    1556</span>              : </span>
<span id="L1557"><span class="lineNum">    1557</span>              : // aten::refine_names(Tensor(a) self, Dimname[] names) -&gt; Tensor(a)</span>
<span id="L1558"><span class="lineNum">    1558</span>              : inline at::Tensor Tensor::refine_names(at::DimnameList names) const {</span>
<span id="L1559"><span class="lineNum">    1559</span>              :     return at::_ops::refine_names::call(const_cast&lt;Tensor&amp;&gt;(*this), names);</span>
<span id="L1560"><span class="lineNum">    1560</span>              : }</span>
<span id="L1561"><span class="lineNum">    1561</span>              : </span>
<span id="L1562"><span class="lineNum">    1562</span>              : // aten::abs(Tensor self) -&gt; Tensor</span>
<span id="L1563"><span class="lineNum">    1563</span>              : inline at::Tensor Tensor::abs() const {</span>
<span id="L1564"><span class="lineNum">    1564</span>              :     return at::_ops::abs::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1565"><span class="lineNum">    1565</span>              : }</span>
<span id="L1566"><span class="lineNum">    1566</span>              : </span>
<span id="L1567"><span class="lineNum">    1567</span>              : // aten::abs_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L1568"><span class="lineNum">    1568</span>              : inline at::Tensor &amp; Tensor::abs_() const {</span>
<span id="L1569"><span class="lineNum">    1569</span>              :     return at::_ops::abs_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1570"><span class="lineNum">    1570</span>              : }</span>
<span id="L1571"><span class="lineNum">    1571</span>              : </span>
<span id="L1572"><span class="lineNum">    1572</span>              : // aten::absolute(Tensor self) -&gt; Tensor</span>
<span id="L1573"><span class="lineNum">    1573</span>              : inline at::Tensor Tensor::absolute() const {</span>
<span id="L1574"><span class="lineNum">    1574</span>              :     return at::_ops::absolute::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1575"><span class="lineNum">    1575</span>              : }</span>
<span id="L1576"><span class="lineNum">    1576</span>              : </span>
<span id="L1577"><span class="lineNum">    1577</span>              : // aten::absolute_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L1578"><span class="lineNum">    1578</span>              : inline at::Tensor &amp; Tensor::absolute_() const {</span>
<span id="L1579"><span class="lineNum">    1579</span>              :     return at::_ops::absolute_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1580"><span class="lineNum">    1580</span>              : }</span>
<span id="L1581"><span class="lineNum">    1581</span>              : </span>
<span id="L1582"><span class="lineNum">    1582</span>              : // aten::angle(Tensor self) -&gt; Tensor</span>
<span id="L1583"><span class="lineNum">    1583</span>              : inline at::Tensor Tensor::angle() const {</span>
<span id="L1584"><span class="lineNum">    1584</span>              :     return at::_ops::angle::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1585"><span class="lineNum">    1585</span>              : }</span>
<span id="L1586"><span class="lineNum">    1586</span>              : </span>
<span id="L1587"><span class="lineNum">    1587</span>              : // aten::sgn(Tensor self) -&gt; Tensor</span>
<span id="L1588"><span class="lineNum">    1588</span>              : inline at::Tensor Tensor::sgn() const {</span>
<span id="L1589"><span class="lineNum">    1589</span>              :     return at::_ops::sgn::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1590"><span class="lineNum">    1590</span>              : }</span>
<span id="L1591"><span class="lineNum">    1591</span>              : </span>
<span id="L1592"><span class="lineNum">    1592</span>              : // aten::sgn_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L1593"><span class="lineNum">    1593</span>              : inline at::Tensor &amp; Tensor::sgn_() const {</span>
<span id="L1594"><span class="lineNum">    1594</span>              :     return at::_ops::sgn_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1595"><span class="lineNum">    1595</span>              : }</span>
<span id="L1596"><span class="lineNum">    1596</span>              : </span>
<span id="L1597"><span class="lineNum">    1597</span>              : // aten::chalf(Tensor self, *, MemoryFormat? memory_format=None) -&gt; Tensor</span>
<span id="L1598"><span class="lineNum">    1598</span>              : inline at::Tensor Tensor::chalf(::std::optional&lt;at::MemoryFormat&gt; memory_format) const {</span>
<span id="L1599"><span class="lineNum">    1599</span>              :     return at::_ops::chalf::call(const_cast&lt;Tensor&amp;&gt;(*this), memory_format);</span>
<span id="L1600"><span class="lineNum">    1600</span>              : }</span>
<span id="L1601"><span class="lineNum">    1601</span>              : </span>
<span id="L1602"><span class="lineNum">    1602</span>              : // aten::_conj(Tensor(a) self) -&gt; Tensor(a)</span>
<span id="L1603"><span class="lineNum">    1603</span>              : inline at::Tensor Tensor::_conj() const {</span>
<span id="L1604"><span class="lineNum">    1604</span>              :     return at::_ops::_conj::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1605"><span class="lineNum">    1605</span>              : }</span>
<span id="L1606"><span class="lineNum">    1606</span>              : </span>
<span id="L1607"><span class="lineNum">    1607</span>              : // aten::conj(Tensor(a) self) -&gt; Tensor(a)</span>
<span id="L1608"><span class="lineNum">    1608</span>              : inline at::Tensor Tensor::__dispatch_conj() const {</span>
<span id="L1609"><span class="lineNum">    1609</span>              :     return at::_ops::conj::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1610"><span class="lineNum">    1610</span>              : }</span>
<span id="L1611"><span class="lineNum">    1611</span>              : </span>
<span id="L1612"><span class="lineNum">    1612</span>              : // aten::_conj_physical(Tensor self) -&gt; Tensor</span>
<span id="L1613"><span class="lineNum">    1613</span>              : inline at::Tensor Tensor::_conj_physical() const {</span>
<span id="L1614"><span class="lineNum">    1614</span>              :     return at::_ops::_conj_physical::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1615"><span class="lineNum">    1615</span>              : }</span>
<span id="L1616"><span class="lineNum">    1616</span>              : </span>
<span id="L1617"><span class="lineNum">    1617</span>              : // aten::conj_physical(Tensor self) -&gt; Tensor</span>
<span id="L1618"><span class="lineNum">    1618</span>              : inline at::Tensor Tensor::conj_physical() const {</span>
<span id="L1619"><span class="lineNum">    1619</span>              :     return at::_ops::conj_physical::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1620"><span class="lineNum">    1620</span>              : }</span>
<span id="L1621"><span class="lineNum">    1621</span>              : </span>
<span id="L1622"><span class="lineNum">    1622</span>              : // aten::conj_physical_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L1623"><span class="lineNum">    1623</span>              : inline at::Tensor &amp; Tensor::conj_physical_() const {</span>
<span id="L1624"><span class="lineNum">    1624</span>              :     return at::_ops::conj_physical_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1625"><span class="lineNum">    1625</span>              : }</span>
<span id="L1626"><span class="lineNum">    1626</span>              : </span>
<span id="L1627"><span class="lineNum">    1627</span>              : // aten::resolve_conj(Tensor(a) self) -&gt; Tensor(a)</span>
<span id="L1628"><span class="lineNum">    1628</span>              : inline at::Tensor Tensor::resolve_conj() const {</span>
<span id="L1629"><span class="lineNum">    1629</span>              :     return at::_ops::resolve_conj::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1630"><span class="lineNum">    1630</span>              : }</span>
<span id="L1631"><span class="lineNum">    1631</span>              : </span>
<span id="L1632"><span class="lineNum">    1632</span>              : // aten::resolve_neg(Tensor(a) self) -&gt; Tensor(a)</span>
<span id="L1633"><span class="lineNum">    1633</span>              : inline at::Tensor Tensor::resolve_neg() const {</span>
<span id="L1634"><span class="lineNum">    1634</span>              :     return at::_ops::resolve_neg::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1635"><span class="lineNum">    1635</span>              : }</span>
<span id="L1636"><span class="lineNum">    1636</span>              : </span>
<span id="L1637"><span class="lineNum">    1637</span>              : // aten::_neg_view(Tensor(a) self) -&gt; Tensor(a)</span>
<span id="L1638"><span class="lineNum">    1638</span>              : inline at::Tensor Tensor::_neg_view() const {</span>
<span id="L1639"><span class="lineNum">    1639</span>              :     return at::_ops::_neg_view::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1640"><span class="lineNum">    1640</span>              : }</span>
<span id="L1641"><span class="lineNum">    1641</span>              : </span>
<span id="L1642"><span class="lineNum">    1642</span>              : // aten::acos(Tensor self) -&gt; Tensor</span>
<span id="L1643"><span class="lineNum">    1643</span>              : inline at::Tensor Tensor::acos() const {</span>
<span id="L1644"><span class="lineNum">    1644</span>              :     return at::_ops::acos::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1645"><span class="lineNum">    1645</span>              : }</span>
<span id="L1646"><span class="lineNum">    1646</span>              : </span>
<span id="L1647"><span class="lineNum">    1647</span>              : // aten::acos_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L1648"><span class="lineNum">    1648</span>              : inline at::Tensor &amp; Tensor::acos_() const {</span>
<span id="L1649"><span class="lineNum">    1649</span>              :     return at::_ops::acos_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1650"><span class="lineNum">    1650</span>              : }</span>
<span id="L1651"><span class="lineNum">    1651</span>              : </span>
<span id="L1652"><span class="lineNum">    1652</span>              : // aten::arccos(Tensor self) -&gt; Tensor</span>
<span id="L1653"><span class="lineNum">    1653</span>              : inline at::Tensor Tensor::arccos() const {</span>
<span id="L1654"><span class="lineNum">    1654</span>              :     return at::_ops::arccos::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1655"><span class="lineNum">    1655</span>              : }</span>
<span id="L1656"><span class="lineNum">    1656</span>              : </span>
<span id="L1657"><span class="lineNum">    1657</span>              : // aten::arccos_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L1658"><span class="lineNum">    1658</span>              : inline at::Tensor &amp; Tensor::arccos_() const {</span>
<span id="L1659"><span class="lineNum">    1659</span>              :     return at::_ops::arccos_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1660"><span class="lineNum">    1660</span>              : }</span>
<span id="L1661"><span class="lineNum">    1661</span>              : </span>
<span id="L1662"><span class="lineNum">    1662</span>              : // aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -&gt; Tensor</span>
<span id="L1663"><span class="lineNum">    1663</span>              : inline at::Tensor Tensor::add(const at::Tensor &amp; other, const at::Scalar &amp; alpha) const {</span>
<span id="L1664"><span class="lineNum">    1664</span>              :     return at::_ops::add_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other, alpha);</span>
<span id="L1665"><span class="lineNum">    1665</span>              : }</span>
<span id="L1666"><span class="lineNum">    1666</span>              : </span>
<span id="L1667"><span class="lineNum">    1667</span>              : // aten::add_.Tensor(Tensor(a!) self, Tensor other, *, Scalar alpha=1) -&gt; Tensor(a!)</span>
<span id="L1668"><span class="lineNum">    1668</span>              : inline at::Tensor &amp; Tensor::add_(const at::Tensor &amp; other, const at::Scalar &amp; alpha) const {</span>
<span id="L1669"><span class="lineNum">    1669</span>              :     return at::_ops::add__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other, alpha);</span>
<span id="L1670"><span class="lineNum">    1670</span>              : }</span>
<span id="L1671"><span class="lineNum">    1671</span>              : </span>
<span id="L1672"><span class="lineNum">    1672</span>              : // aten::add.Scalar(Tensor self, Scalar other, Scalar alpha=1) -&gt; Tensor</span>
<span id="L1673"><span class="lineNum">    1673</span>              : inline at::Tensor Tensor::add(const at::Scalar &amp; other, const at::Scalar &amp; alpha) const {</span>
<span id="L1674"><span class="lineNum">    1674</span>              :     return at::_ops::add_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other, alpha);</span>
<span id="L1675"><span class="lineNum">    1675</span>              : }</span>
<span id="L1676"><span class="lineNum">    1676</span>              : </span>
<span id="L1677"><span class="lineNum">    1677</span>              : // aten::add_.Scalar(Tensor(a!) self, Scalar other, Scalar alpha=1) -&gt; Tensor(a!)</span>
<span id="L1678"><span class="lineNum">    1678</span>              : inline at::Tensor &amp; Tensor::add_(const at::Scalar &amp; other, const at::Scalar &amp; alpha) const {</span>
<span id="L1679"><span class="lineNum">    1679</span>              :     return at::_ops::add__Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other, alpha);</span>
<span id="L1680"><span class="lineNum">    1680</span>              : }</span>
<span id="L1681"><span class="lineNum">    1681</span>              : </span>
<span id="L1682"><span class="lineNum">    1682</span>              : // aten::addmv(Tensor self, Tensor mat, Tensor vec, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor</span>
<span id="L1683"><span class="lineNum">    1683</span>              : inline at::Tensor Tensor::addmv(const at::Tensor &amp; mat, const at::Tensor &amp; vec, const at::Scalar &amp; beta, const at::Scalar &amp; alpha) const {</span>
<span id="L1684"><span class="lineNum">    1684</span>              :     return at::_ops::addmv::call(const_cast&lt;Tensor&amp;&gt;(*this), mat, vec, beta, alpha);</span>
<span id="L1685"><span class="lineNum">    1685</span>              : }</span>
<span id="L1686"><span class="lineNum">    1686</span>              : </span>
<span id="L1687"><span class="lineNum">    1687</span>              : // aten::addmv_(Tensor(a!) self, Tensor mat, Tensor vec, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor(a!)</span>
<span id="L1688"><span class="lineNum">    1688</span>              : inline at::Tensor &amp; Tensor::addmv_(const at::Tensor &amp; mat, const at::Tensor &amp; vec, const at::Scalar &amp; beta, const at::Scalar &amp; alpha) const {</span>
<span id="L1689"><span class="lineNum">    1689</span>              :     return at::_ops::addmv_::call(const_cast&lt;Tensor&amp;&gt;(*this), mat, vec, beta, alpha);</span>
<span id="L1690"><span class="lineNum">    1690</span>              : }</span>
<span id="L1691"><span class="lineNum">    1691</span>              : </span>
<span id="L1692"><span class="lineNum">    1692</span>              : // aten::addr(Tensor self, Tensor vec1, Tensor vec2, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor</span>
<span id="L1693"><span class="lineNum">    1693</span>              : inline at::Tensor Tensor::addr(const at::Tensor &amp; vec1, const at::Tensor &amp; vec2, const at::Scalar &amp; beta, const at::Scalar &amp; alpha) const {</span>
<span id="L1694"><span class="lineNum">    1694</span>              :     return at::_ops::addr::call(const_cast&lt;Tensor&amp;&gt;(*this), vec1, vec2, beta, alpha);</span>
<span id="L1695"><span class="lineNum">    1695</span>              : }</span>
<span id="L1696"><span class="lineNum">    1696</span>              : </span>
<span id="L1697"><span class="lineNum">    1697</span>              : // aten::addr_(Tensor(a!) self, Tensor vec1, Tensor vec2, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor(a!)</span>
<span id="L1698"><span class="lineNum">    1698</span>              : inline at::Tensor &amp; Tensor::addr_(const at::Tensor &amp; vec1, const at::Tensor &amp; vec2, const at::Scalar &amp; beta, const at::Scalar &amp; alpha) const {</span>
<span id="L1699"><span class="lineNum">    1699</span>              :     return at::_ops::addr_::call(const_cast&lt;Tensor&amp;&gt;(*this), vec1, vec2, beta, alpha);</span>
<span id="L1700"><span class="lineNum">    1700</span>              : }</span>
<span id="L1701"><span class="lineNum">    1701</span>              : </span>
<span id="L1702"><span class="lineNum">    1702</span>              : // aten::_is_all_true(Tensor self) -&gt; Tensor</span>
<span id="L1703"><span class="lineNum">    1703</span>              : inline at::Tensor Tensor::_is_all_true() const {</span>
<span id="L1704"><span class="lineNum">    1704</span>              :     return at::_ops::_is_all_true::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1705"><span class="lineNum">    1705</span>              : }</span>
<span id="L1706"><span class="lineNum">    1706</span>              : </span>
<span id="L1707"><span class="lineNum">    1707</span>              : // aten::_is_any_true(Tensor self) -&gt; Tensor</span>
<span id="L1708"><span class="lineNum">    1708</span>              : inline at::Tensor Tensor::_is_any_true() const {</span>
<span id="L1709"><span class="lineNum">    1709</span>              :     return at::_ops::_is_any_true::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1710"><span class="lineNum">    1710</span>              : }</span>
<span id="L1711"><span class="lineNum">    1711</span>              : </span>
<span id="L1712"><span class="lineNum">    1712</span>              : // aten::all.dim(Tensor self, int dim, bool keepdim=False) -&gt; Tensor</span>
<span id="L1713"><span class="lineNum">    1713</span>              : inline at::Tensor Tensor::all(int64_t dim, bool keepdim) const {</span>
<span id="L1714"><span class="lineNum">    1714</span>              :     return at::_ops::all_dim::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, keepdim);</span>
<span id="L1715"><span class="lineNum">    1715</span>              : }</span>
<span id="L1716"><span class="lineNum">    1716</span>              : </span>
<span id="L1717"><span class="lineNum">    1717</span>              : // aten::all.dims(Tensor self, int[]? dim=None, bool keepdim=False) -&gt; Tensor</span>
<span id="L1718"><span class="lineNum">    1718</span>              : inline at::Tensor Tensor::all(at::OptionalIntArrayRef dim, bool keepdim) const {</span>
<span id="L1719"><span class="lineNum">    1719</span>              :     return at::_ops::all_dims::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, keepdim);</span>
<span id="L1720"><span class="lineNum">    1720</span>              : }</span>
<span id="L1721"><span class="lineNum">    1721</span>              : </span>
<span id="L1722"><span class="lineNum">    1722</span>              : // aten::all.dimname(Tensor self, Dimname dim, bool keepdim=False) -&gt; Tensor</span>
<span id="L1723"><span class="lineNum">    1723</span>              : inline at::Tensor Tensor::all(at::Dimname dim, bool keepdim) const {</span>
<span id="L1724"><span class="lineNum">    1724</span>              :     return at::_ops::all_dimname::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, keepdim);</span>
<span id="L1725"><span class="lineNum">    1725</span>              : }</span>
<span id="L1726"><span class="lineNum">    1726</span>              : </span>
<span id="L1727"><span class="lineNum">    1727</span>              : // aten::allclose(Tensor self, Tensor other, float rtol=1e-05, float atol=1e-08, bool equal_nan=False) -&gt; bool</span>
<span id="L1728"><span class="lineNum">    1728</span>              : inline bool Tensor::allclose(const at::Tensor &amp; other, double rtol, double atol, bool equal_nan) const {</span>
<span id="L1729"><span class="lineNum">    1729</span>              :     return at::_ops::allclose::call(const_cast&lt;Tensor&amp;&gt;(*this), other, rtol, atol, equal_nan);</span>
<span id="L1730"><span class="lineNum">    1730</span>              : }</span>
<span id="L1731"><span class="lineNum">    1731</span>              : </span>
<span id="L1732"><span class="lineNum">    1732</span>              : // aten::any.dim(Tensor self, int dim, bool keepdim=False) -&gt; Tensor</span>
<span id="L1733"><span class="lineNum">    1733</span>              : inline at::Tensor Tensor::any(int64_t dim, bool keepdim) const {</span>
<span id="L1734"><span class="lineNum">    1734</span>              :     return at::_ops::any_dim::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, keepdim);</span>
<span id="L1735"><span class="lineNum">    1735</span>              : }</span>
<span id="L1736"><span class="lineNum">    1736</span>              : </span>
<span id="L1737"><span class="lineNum">    1737</span>              : // aten::any.dims(Tensor self, int[]? dim=None, bool keepdim=False) -&gt; Tensor</span>
<span id="L1738"><span class="lineNum">    1738</span>              : inline at::Tensor Tensor::any(at::OptionalIntArrayRef dim, bool keepdim) const {</span>
<span id="L1739"><span class="lineNum">    1739</span>              :     return at::_ops::any_dims::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, keepdim);</span>
<span id="L1740"><span class="lineNum">    1740</span>              : }</span>
<span id="L1741"><span class="lineNum">    1741</span>              : </span>
<span id="L1742"><span class="lineNum">    1742</span>              : // aten::any.dimname(Tensor self, Dimname dim, bool keepdim=False) -&gt; Tensor</span>
<span id="L1743"><span class="lineNum">    1743</span>              : inline at::Tensor Tensor::any(at::Dimname dim, bool keepdim) const {</span>
<span id="L1744"><span class="lineNum">    1744</span>              :     return at::_ops::any_dimname::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, keepdim);</span>
<span id="L1745"><span class="lineNum">    1745</span>              : }</span>
<span id="L1746"><span class="lineNum">    1746</span>              : </span>
<span id="L1747"><span class="lineNum">    1747</span>              : // aten::argmax(Tensor self, int? dim=None, bool keepdim=False) -&gt; Tensor</span>
<span id="L1748"><span class="lineNum">    1748</span>              : inline at::Tensor Tensor::argmax(::std::optional&lt;int64_t&gt; dim, bool keepdim) const {</span>
<span id="L1749"><span class="lineNum">    1749</span>              :     return at::_ops::argmax::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, keepdim);</span>
<span id="L1750"><span class="lineNum">    1750</span>              : }</span>
<span id="L1751"><span class="lineNum">    1751</span>              : </span>
<span id="L1752"><span class="lineNum">    1752</span>              : // aten::argmin(Tensor self, int? dim=None, bool keepdim=False) -&gt; Tensor</span>
<span id="L1753"><span class="lineNum">    1753</span>              : inline at::Tensor Tensor::argmin(::std::optional&lt;int64_t&gt; dim, bool keepdim) const {</span>
<span id="L1754"><span class="lineNum">    1754</span>              :     return at::_ops::argmin::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, keepdim);</span>
<span id="L1755"><span class="lineNum">    1755</span>              : }</span>
<span id="L1756"><span class="lineNum">    1756</span>              : </span>
<span id="L1757"><span class="lineNum">    1757</span>              : // aten::acosh(Tensor self) -&gt; Tensor</span>
<span id="L1758"><span class="lineNum">    1758</span>              : inline at::Tensor Tensor::acosh() const {</span>
<span id="L1759"><span class="lineNum">    1759</span>              :     return at::_ops::acosh::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1760"><span class="lineNum">    1760</span>              : }</span>
<span id="L1761"><span class="lineNum">    1761</span>              : </span>
<span id="L1762"><span class="lineNum">    1762</span>              : // aten::acosh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L1763"><span class="lineNum">    1763</span>              : inline at::Tensor &amp; Tensor::acosh_() const {</span>
<span id="L1764"><span class="lineNum">    1764</span>              :     return at::_ops::acosh_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1765"><span class="lineNum">    1765</span>              : }</span>
<span id="L1766"><span class="lineNum">    1766</span>              : </span>
<span id="L1767"><span class="lineNum">    1767</span>              : // aten::arccosh(Tensor self) -&gt; Tensor</span>
<span id="L1768"><span class="lineNum">    1768</span>              : inline at::Tensor Tensor::arccosh() const {</span>
<span id="L1769"><span class="lineNum">    1769</span>              :     return at::_ops::arccosh::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1770"><span class="lineNum">    1770</span>              : }</span>
<span id="L1771"><span class="lineNum">    1771</span>              : </span>
<span id="L1772"><span class="lineNum">    1772</span>              : // aten::arccosh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L1773"><span class="lineNum">    1773</span>              : inline at::Tensor &amp; Tensor::arccosh_() const {</span>
<span id="L1774"><span class="lineNum">    1774</span>              :     return at::_ops::arccosh_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1775"><span class="lineNum">    1775</span>              : }</span>
<span id="L1776"><span class="lineNum">    1776</span>              : </span>
<span id="L1777"><span class="lineNum">    1777</span>              : // aten::asinh(Tensor self) -&gt; Tensor</span>
<span id="L1778"><span class="lineNum">    1778</span>              : inline at::Tensor Tensor::asinh() const {</span>
<span id="L1779"><span class="lineNum">    1779</span>              :     return at::_ops::asinh::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1780"><span class="lineNum">    1780</span>              : }</span>
<span id="L1781"><span class="lineNum">    1781</span>              : </span>
<span id="L1782"><span class="lineNum">    1782</span>              : // aten::asinh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L1783"><span class="lineNum">    1783</span>              : inline at::Tensor &amp; Tensor::asinh_() const {</span>
<span id="L1784"><span class="lineNum">    1784</span>              :     return at::_ops::asinh_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1785"><span class="lineNum">    1785</span>              : }</span>
<span id="L1786"><span class="lineNum">    1786</span>              : </span>
<span id="L1787"><span class="lineNum">    1787</span>              : // aten::arcsinh(Tensor self) -&gt; Tensor</span>
<span id="L1788"><span class="lineNum">    1788</span>              : inline at::Tensor Tensor::arcsinh() const {</span>
<span id="L1789"><span class="lineNum">    1789</span>              :     return at::_ops::arcsinh::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1790"><span class="lineNum">    1790</span>              : }</span>
<span id="L1791"><span class="lineNum">    1791</span>              : </span>
<span id="L1792"><span class="lineNum">    1792</span>              : // aten::arcsinh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L1793"><span class="lineNum">    1793</span>              : inline at::Tensor &amp; Tensor::arcsinh_() const {</span>
<span id="L1794"><span class="lineNum">    1794</span>              :     return at::_ops::arcsinh_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1795"><span class="lineNum">    1795</span>              : }</span>
<span id="L1796"><span class="lineNum">    1796</span>              : </span>
<span id="L1797"><span class="lineNum">    1797</span>              : // aten::atanh(Tensor self) -&gt; Tensor</span>
<span id="L1798"><span class="lineNum">    1798</span>              : inline at::Tensor Tensor::atanh() const {</span>
<span id="L1799"><span class="lineNum">    1799</span>              :     return at::_ops::atanh::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1800"><span class="lineNum">    1800</span>              : }</span>
<span id="L1801"><span class="lineNum">    1801</span>              : </span>
<span id="L1802"><span class="lineNum">    1802</span>              : // aten::atanh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L1803"><span class="lineNum">    1803</span>              : inline at::Tensor &amp; Tensor::atanh_() const {</span>
<span id="L1804"><span class="lineNum">    1804</span>              :     return at::_ops::atanh_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1805"><span class="lineNum">    1805</span>              : }</span>
<span id="L1806"><span class="lineNum">    1806</span>              : </span>
<span id="L1807"><span class="lineNum">    1807</span>              : // aten::arctanh(Tensor self) -&gt; Tensor</span>
<span id="L1808"><span class="lineNum">    1808</span>              : inline at::Tensor Tensor::arctanh() const {</span>
<span id="L1809"><span class="lineNum">    1809</span>              :     return at::_ops::arctanh::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1810"><span class="lineNum">    1810</span>              : }</span>
<span id="L1811"><span class="lineNum">    1811</span>              : </span>
<span id="L1812"><span class="lineNum">    1812</span>              : // aten::arctanh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L1813"><span class="lineNum">    1813</span>              : inline at::Tensor &amp; Tensor::arctanh_() const {</span>
<span id="L1814"><span class="lineNum">    1814</span>              :     return at::_ops::arctanh_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1815"><span class="lineNum">    1815</span>              : }</span>
<span id="L1816"><span class="lineNum">    1816</span>              : </span>
<span id="L1817"><span class="lineNum">    1817</span>              : // aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -&gt; Tensor(a)</span>
<span id="L1818"><span class="lineNum">    1818</span>              : inline at::Tensor Tensor::as_strided(at::IntArrayRef size, at::IntArrayRef stride, ::std::optional&lt;int64_t&gt; storage_offset) const {</span>
<span id="L1819"><span class="lineNum">    1819</span>              :     return at::_ops::as_strided::call(const_cast&lt;Tensor&amp;&gt;(*this), c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride), storage_offset.has_value() ? ::std::make_optional(c10::SymInt(*storage_offset)) : ::std::nullopt);</span>
<span id="L1820"><span class="lineNum">    1820</span>              : }</span>
<span id="L1821"><span class="lineNum">    1821</span>              : </span>
<span id="L1822"><span class="lineNum">    1822</span>              : // aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -&gt; Tensor(a)</span>
<span id="L1823"><span class="lineNum">    1823</span>              : inline at::Tensor Tensor::as_strided_symint(c10::SymIntArrayRef size, c10::SymIntArrayRef stride, ::std::optional&lt;c10::SymInt&gt; storage_offset) const {</span>
<span id="L1824"><span class="lineNum">    1824</span>              :     return at::_ops::as_strided::call(const_cast&lt;Tensor&amp;&gt;(*this), size, stride, storage_offset);</span>
<span id="L1825"><span class="lineNum">    1825</span>              : }</span>
<span id="L1826"><span class="lineNum">    1826</span>              : </span>
<span id="L1827"><span class="lineNum">    1827</span>              : // aten::as_strided_(Tensor(a!) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -&gt; Tensor(a!)</span>
<span id="L1828"><span class="lineNum">    1828</span>              : inline const at::Tensor &amp; Tensor::as_strided_(at::IntArrayRef size, at::IntArrayRef stride, ::std::optional&lt;int64_t&gt; storage_offset) const {</span>
<span id="L1829"><span class="lineNum">    1829</span>              :     return at::_ops::as_strided_::call(const_cast&lt;Tensor&amp;&gt;(*this), c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride), storage_offset.has_value() ? ::std::make_optional(c10::SymInt(*storage_offset)) : ::std::nullopt);</span>
<span id="L1830"><span class="lineNum">    1830</span>              : }</span>
<span id="L1831"><span class="lineNum">    1831</span>              : </span>
<span id="L1832"><span class="lineNum">    1832</span>              : // aten::as_strided_(Tensor(a!) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -&gt; Tensor(a!)</span>
<span id="L1833"><span class="lineNum">    1833</span>              : inline const at::Tensor &amp; Tensor::as_strided__symint(c10::SymIntArrayRef size, c10::SymIntArrayRef stride, ::std::optional&lt;c10::SymInt&gt; storage_offset) const {</span>
<span id="L1834"><span class="lineNum">    1834</span>              :     return at::_ops::as_strided_::call(const_cast&lt;Tensor&amp;&gt;(*this), size, stride, storage_offset);</span>
<span id="L1835"><span class="lineNum">    1835</span>              : }</span>
<span id="L1836"><span class="lineNum">    1836</span>              : </span>
<span id="L1837"><span class="lineNum">    1837</span>              : // aten::asin(Tensor self) -&gt; Tensor</span>
<span id="L1838"><span class="lineNum">    1838</span>              : inline at::Tensor Tensor::asin() const {</span>
<span id="L1839"><span class="lineNum">    1839</span>              :     return at::_ops::asin::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1840"><span class="lineNum">    1840</span>              : }</span>
<span id="L1841"><span class="lineNum">    1841</span>              : </span>
<span id="L1842"><span class="lineNum">    1842</span>              : // aten::asin_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L1843"><span class="lineNum">    1843</span>              : inline at::Tensor &amp; Tensor::asin_() const {</span>
<span id="L1844"><span class="lineNum">    1844</span>              :     return at::_ops::asin_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1845"><span class="lineNum">    1845</span>              : }</span>
<span id="L1846"><span class="lineNum">    1846</span>              : </span>
<span id="L1847"><span class="lineNum">    1847</span>              : // aten::arcsin(Tensor self) -&gt; Tensor</span>
<span id="L1848"><span class="lineNum">    1848</span>              : inline at::Tensor Tensor::arcsin() const {</span>
<span id="L1849"><span class="lineNum">    1849</span>              :     return at::_ops::arcsin::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1850"><span class="lineNum">    1850</span>              : }</span>
<span id="L1851"><span class="lineNum">    1851</span>              : </span>
<span id="L1852"><span class="lineNum">    1852</span>              : // aten::arcsin_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L1853"><span class="lineNum">    1853</span>              : inline at::Tensor &amp; Tensor::arcsin_() const {</span>
<span id="L1854"><span class="lineNum">    1854</span>              :     return at::_ops::arcsin_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1855"><span class="lineNum">    1855</span>              : }</span>
<span id="L1856"><span class="lineNum">    1856</span>              : </span>
<span id="L1857"><span class="lineNum">    1857</span>              : // aten::atan(Tensor self) -&gt; Tensor</span>
<span id="L1858"><span class="lineNum">    1858</span>              : inline at::Tensor Tensor::atan() const {</span>
<span id="L1859"><span class="lineNum">    1859</span>              :     return at::_ops::atan::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1860"><span class="lineNum">    1860</span>              : }</span>
<span id="L1861"><span class="lineNum">    1861</span>              : </span>
<span id="L1862"><span class="lineNum">    1862</span>              : // aten::atan_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L1863"><span class="lineNum">    1863</span>              : inline at::Tensor &amp; Tensor::atan_() const {</span>
<span id="L1864"><span class="lineNum">    1864</span>              :     return at::_ops::atan_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1865"><span class="lineNum">    1865</span>              : }</span>
<span id="L1866"><span class="lineNum">    1866</span>              : </span>
<span id="L1867"><span class="lineNum">    1867</span>              : // aten::arctan(Tensor self) -&gt; Tensor</span>
<span id="L1868"><span class="lineNum">    1868</span>              : inline at::Tensor Tensor::arctan() const {</span>
<span id="L1869"><span class="lineNum">    1869</span>              :     return at::_ops::arctan::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1870"><span class="lineNum">    1870</span>              : }</span>
<span id="L1871"><span class="lineNum">    1871</span>              : </span>
<span id="L1872"><span class="lineNum">    1872</span>              : // aten::arctan_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L1873"><span class="lineNum">    1873</span>              : inline at::Tensor &amp; Tensor::arctan_() const {</span>
<span id="L1874"><span class="lineNum">    1874</span>              :     return at::_ops::arctan_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1875"><span class="lineNum">    1875</span>              : }</span>
<span id="L1876"><span class="lineNum">    1876</span>              : </span>
<span id="L1877"><span class="lineNum">    1877</span>              : // aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor</span>
<span id="L1878"><span class="lineNum">    1878</span>              : inline at::Tensor Tensor::baddbmm(const at::Tensor &amp; batch1, const at::Tensor &amp; batch2, const at::Scalar &amp; beta, const at::Scalar &amp; alpha) const {</span>
<span id="L1879"><span class="lineNum">    1879</span>              :     return at::_ops::baddbmm::call(const_cast&lt;Tensor&amp;&gt;(*this), batch1, batch2, beta, alpha);</span>
<span id="L1880"><span class="lineNum">    1880</span>              : }</span>
<span id="L1881"><span class="lineNum">    1881</span>              : </span>
<span id="L1882"><span class="lineNum">    1882</span>              : // aten::baddbmm_(Tensor(a!) self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor(a!)</span>
<span id="L1883"><span class="lineNum">    1883</span>              : inline at::Tensor &amp; Tensor::baddbmm_(const at::Tensor &amp; batch1, const at::Tensor &amp; batch2, const at::Scalar &amp; beta, const at::Scalar &amp; alpha) const {</span>
<span id="L1884"><span class="lineNum">    1884</span>              :     return at::_ops::baddbmm_::call(const_cast&lt;Tensor&amp;&gt;(*this), batch1, batch2, beta, alpha);</span>
<span id="L1885"><span class="lineNum">    1885</span>              : }</span>
<span id="L1886"><span class="lineNum">    1886</span>              : </span>
<span id="L1887"><span class="lineNum">    1887</span>              : // aten::bernoulli(Tensor self, *, Generator? generator=None) -&gt; Tensor</span>
<span id="L1888"><span class="lineNum">    1888</span>              : inline at::Tensor Tensor::bernoulli(::std::optional&lt;at::Generator&gt; generator) const {</span>
<span id="L1889"><span class="lineNum">    1889</span>              :     return at::_ops::bernoulli::call(const_cast&lt;Tensor&amp;&gt;(*this), generator);</span>
<span id="L1890"><span class="lineNum">    1890</span>              : }</span>
<span id="L1891"><span class="lineNum">    1891</span>              : </span>
<span id="L1892"><span class="lineNum">    1892</span>              : // aten::bernoulli_.Tensor(Tensor(a!) self, Tensor p, *, Generator? generator=None) -&gt; Tensor(a!)</span>
<span id="L1893"><span class="lineNum">    1893</span>              : inline at::Tensor &amp; Tensor::bernoulli_(const at::Tensor &amp; p, ::std::optional&lt;at::Generator&gt; generator) const {</span>
<span id="L1894"><span class="lineNum">    1894</span>              :     return at::_ops::bernoulli__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), p, generator);</span>
<span id="L1895"><span class="lineNum">    1895</span>              : }</span>
<span id="L1896"><span class="lineNum">    1896</span>              : </span>
<span id="L1897"><span class="lineNum">    1897</span>              : // aten::bernoulli_.float(Tensor(a!) self, float p=0.5, *, Generator? generator=None) -&gt; Tensor(a!)</span>
<span id="L1898"><span class="lineNum">    1898</span>              : inline at::Tensor &amp; Tensor::bernoulli_(double p, ::std::optional&lt;at::Generator&gt; generator) const {</span>
<span id="L1899"><span class="lineNum">    1899</span>              :     return at::_ops::bernoulli__float::call(const_cast&lt;Tensor&amp;&gt;(*this), p, generator);</span>
<span id="L1900"><span class="lineNum">    1900</span>              : }</span>
<span id="L1901"><span class="lineNum">    1901</span>              : </span>
<span id="L1902"><span class="lineNum">    1902</span>              : // aten::bernoulli.p(Tensor self, float p, *, Generator? generator=None) -&gt; Tensor</span>
<span id="L1903"><span class="lineNum">    1903</span>              : inline at::Tensor Tensor::bernoulli(double p, ::std::optional&lt;at::Generator&gt; generator) const {</span>
<span id="L1904"><span class="lineNum">    1904</span>              :     return at::_ops::bernoulli_p::call(const_cast&lt;Tensor&amp;&gt;(*this), p, generator);</span>
<span id="L1905"><span class="lineNum">    1905</span>              : }</span>
<span id="L1906"><span class="lineNum">    1906</span>              : </span>
<span id="L1907"><span class="lineNum">    1907</span>              : // aten::bincount(Tensor self, Tensor? weights=None, int minlength=0) -&gt; Tensor</span>
<span id="L1908"><span class="lineNum">    1908</span>              : inline at::Tensor Tensor::bincount(const ::std::optional&lt;at::Tensor&gt; &amp; weights, int64_t minlength) const {</span>
<span id="L1909"><span class="lineNum">    1909</span>              :     return at::_ops::bincount::call(const_cast&lt;Tensor&amp;&gt;(*this), weights, minlength);</span>
<span id="L1910"><span class="lineNum">    1910</span>              : }</span>
<span id="L1911"><span class="lineNum">    1911</span>              : </span>
<span id="L1912"><span class="lineNum">    1912</span>              : // aten::bitwise_not(Tensor self) -&gt; Tensor</span>
<span id="L1913"><span class="lineNum">    1913</span>              : inline at::Tensor Tensor::bitwise_not() const {</span>
<span id="L1914"><span class="lineNum">    1914</span>              :     return at::_ops::bitwise_not::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1915"><span class="lineNum">    1915</span>              : }</span>
<span id="L1916"><span class="lineNum">    1916</span>              : </span>
<span id="L1917"><span class="lineNum">    1917</span>              : // aten::bitwise_not_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L1918"><span class="lineNum">    1918</span>              : inline at::Tensor &amp; Tensor::bitwise_not_() const {</span>
<span id="L1919"><span class="lineNum">    1919</span>              :     return at::_ops::bitwise_not_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1920"><span class="lineNum">    1920</span>              : }</span>
<span id="L1921"><span class="lineNum">    1921</span>              : </span>
<span id="L1922"><span class="lineNum">    1922</span>              : // aten::copysign.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L1923"><span class="lineNum">    1923</span>              : inline at::Tensor Tensor::copysign(const at::Tensor &amp; other) const {</span>
<span id="L1924"><span class="lineNum">    1924</span>              :     return at::_ops::copysign_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L1925"><span class="lineNum">    1925</span>              : }</span>
<span id="L1926"><span class="lineNum">    1926</span>              : </span>
<span id="L1927"><span class="lineNum">    1927</span>              : // aten::copysign_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L1928"><span class="lineNum">    1928</span>              : inline at::Tensor &amp; Tensor::copysign_(const at::Tensor &amp; other) const {</span>
<span id="L1929"><span class="lineNum">    1929</span>              :     return at::_ops::copysign__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L1930"><span class="lineNum">    1930</span>              : }</span>
<span id="L1931"><span class="lineNum">    1931</span>              : </span>
<span id="L1932"><span class="lineNum">    1932</span>              : // aten::copysign.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span id="L1933"><span class="lineNum">    1933</span>              : inline at::Tensor Tensor::copysign(const at::Scalar &amp; other) const {</span>
<span id="L1934"><span class="lineNum">    1934</span>              :     return at::_ops::copysign_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L1935"><span class="lineNum">    1935</span>              : }</span>
<span id="L1936"><span class="lineNum">    1936</span>              : </span>
<span id="L1937"><span class="lineNum">    1937</span>              : // aten::copysign_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span id="L1938"><span class="lineNum">    1938</span>              : inline at::Tensor &amp; Tensor::copysign_(const at::Scalar &amp; other) const {</span>
<span id="L1939"><span class="lineNum">    1939</span>              :     return at::_ops::copysign__Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L1940"><span class="lineNum">    1940</span>              : }</span>
<span id="L1941"><span class="lineNum">    1941</span>              : </span>
<span id="L1942"><span class="lineNum">    1942</span>              : // aten::_lazy_clone(Tensor self) -&gt; Tensor</span>
<span id="L1943"><span class="lineNum">    1943</span>              : inline at::Tensor Tensor::_lazy_clone() const {</span>
<span id="L1944"><span class="lineNum">    1944</span>              :     return at::_ops::_lazy_clone::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1945"><span class="lineNum">    1945</span>              : }</span>
<span id="L1946"><span class="lineNum">    1946</span>              : </span>
<span id="L1947"><span class="lineNum">    1947</span>              : // aten::logical_not(Tensor self) -&gt; Tensor</span>
<span id="L1948"><span class="lineNum">    1948</span>              : inline at::Tensor Tensor::logical_not() const {</span>
<span id="L1949"><span class="lineNum">    1949</span>              :     return at::_ops::logical_not::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1950"><span class="lineNum">    1950</span>              : }</span>
<span id="L1951"><span class="lineNum">    1951</span>              : </span>
<span id="L1952"><span class="lineNum">    1952</span>              : // aten::logical_not_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L1953"><span class="lineNum">    1953</span>              : inline at::Tensor &amp; Tensor::logical_not_() const {</span>
<span id="L1954"><span class="lineNum">    1954</span>              :     return at::_ops::logical_not_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L1955"><span class="lineNum">    1955</span>              : }</span>
<span id="L1956"><span class="lineNum">    1956</span>              : </span>
<span id="L1957"><span class="lineNum">    1957</span>              : // aten::logical_xor(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L1958"><span class="lineNum">    1958</span>              : inline at::Tensor Tensor::logical_xor(const at::Tensor &amp; other) const {</span>
<span id="L1959"><span class="lineNum">    1959</span>              :     return at::_ops::logical_xor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L1960"><span class="lineNum">    1960</span>              : }</span>
<span id="L1961"><span class="lineNum">    1961</span>              : </span>
<span id="L1962"><span class="lineNum">    1962</span>              : // aten::logical_xor_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L1963"><span class="lineNum">    1963</span>              : inline at::Tensor &amp; Tensor::logical_xor_(const at::Tensor &amp; other) const {</span>
<span id="L1964"><span class="lineNum">    1964</span>              :     return at::_ops::logical_xor_::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L1965"><span class="lineNum">    1965</span>              : }</span>
<span id="L1966"><span class="lineNum">    1966</span>              : </span>
<span id="L1967"><span class="lineNum">    1967</span>              : // aten::logical_and(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L1968"><span class="lineNum">    1968</span>              : inline at::Tensor Tensor::logical_and(const at::Tensor &amp; other) const {</span>
<span id="L1969"><span class="lineNum">    1969</span>              :     return at::_ops::logical_and::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L1970"><span class="lineNum">    1970</span>              : }</span>
<span id="L1971"><span class="lineNum">    1971</span>              : </span>
<span id="L1972"><span class="lineNum">    1972</span>              : // aten::logical_and_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L1973"><span class="lineNum">    1973</span>              : inline at::Tensor &amp; Tensor::logical_and_(const at::Tensor &amp; other) const {</span>
<span id="L1974"><span class="lineNum">    1974</span>              :     return at::_ops::logical_and_::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L1975"><span class="lineNum">    1975</span>              : }</span>
<span id="L1976"><span class="lineNum">    1976</span>              : </span>
<span id="L1977"><span class="lineNum">    1977</span>              : // aten::logical_or(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L1978"><span class="lineNum">    1978</span>              : inline at::Tensor Tensor::logical_or(const at::Tensor &amp; other) const {</span>
<span id="L1979"><span class="lineNum">    1979</span>              :     return at::_ops::logical_or::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L1980"><span class="lineNum">    1980</span>              : }</span>
<span id="L1981"><span class="lineNum">    1981</span>              : </span>
<span id="L1982"><span class="lineNum">    1982</span>              : // aten::logical_or_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L1983"><span class="lineNum">    1983</span>              : inline at::Tensor &amp; Tensor::logical_or_(const at::Tensor &amp; other) const {</span>
<span id="L1984"><span class="lineNum">    1984</span>              :     return at::_ops::logical_or_::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L1985"><span class="lineNum">    1985</span>              : }</span>
<span id="L1986"><span class="lineNum">    1986</span>              : </span>
<span id="L1987"><span class="lineNum">    1987</span>              : // aten::bmm(Tensor self, Tensor mat2) -&gt; Tensor</span>
<span id="L1988"><span class="lineNum">    1988</span>              : inline at::Tensor Tensor::bmm(const at::Tensor &amp; mat2) const {</span>
<span id="L1989"><span class="lineNum">    1989</span>              :     return at::_ops::bmm::call(const_cast&lt;Tensor&amp;&gt;(*this), mat2);</span>
<span id="L1990"><span class="lineNum">    1990</span>              : }</span>
<span id="L1991"><span class="lineNum">    1991</span>              : </span>
<span id="L1992"><span class="lineNum">    1992</span>              : // aten::broadcast_to(Tensor(a) self, SymInt[] size) -&gt; Tensor(a)</span>
<span id="L1993"><span class="lineNum">    1993</span>              : inline at::Tensor Tensor::broadcast_to(at::IntArrayRef size) const {</span>
<span id="L1994"><span class="lineNum">    1994</span>              :     return at::_ops::broadcast_to::call(const_cast&lt;Tensor&amp;&gt;(*this), c10::fromIntArrayRefSlow(size));</span>
<span id="L1995"><span class="lineNum">    1995</span>              : }</span>
<span id="L1996"><span class="lineNum">    1996</span>              : </span>
<span id="L1997"><span class="lineNum">    1997</span>              : // aten::broadcast_to(Tensor(a) self, SymInt[] size) -&gt; Tensor(a)</span>
<span id="L1998"><span class="lineNum">    1998</span>              : inline at::Tensor Tensor::broadcast_to_symint(c10::SymIntArrayRef size) const {</span>
<span id="L1999"><span class="lineNum">    1999</span>              :     return at::_ops::broadcast_to::call(const_cast&lt;Tensor&amp;&gt;(*this), size);</span>
<span id="L2000"><span class="lineNum">    2000</span>              : }</span>
<span id="L2001"><span class="lineNum">    2001</span>              : </span>
<span id="L2002"><span class="lineNum">    2002</span>              : // aten::ceil(Tensor self) -&gt; Tensor</span>
<span id="L2003"><span class="lineNum">    2003</span>              : inline at::Tensor Tensor::ceil() const {</span>
<span id="L2004"><span class="lineNum">    2004</span>              :     return at::_ops::ceil::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2005"><span class="lineNum">    2005</span>              : }</span>
<span id="L2006"><span class="lineNum">    2006</span>              : </span>
<span id="L2007"><span class="lineNum">    2007</span>              : // aten::ceil_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L2008"><span class="lineNum">    2008</span>              : inline at::Tensor &amp; Tensor::ceil_() const {</span>
<span id="L2009"><span class="lineNum">    2009</span>              :     return at::_ops::ceil_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2010"><span class="lineNum">    2010</span>              : }</span>
<span id="L2011"><span class="lineNum">    2011</span>              : </span>
<span id="L2012"><span class="lineNum">    2012</span>              : // aten::unsafe_chunk(Tensor self, int chunks, int dim=0) -&gt; Tensor[]</span>
<span id="L2013"><span class="lineNum">    2013</span>              : inline ::std::vector&lt;at::Tensor&gt; Tensor::unsafe_chunk(int64_t chunks, int64_t dim) const {</span>
<span id="L2014"><span class="lineNum">    2014</span>              :     return at::_ops::unsafe_chunk::call(const_cast&lt;Tensor&amp;&gt;(*this), chunks, dim);</span>
<span id="L2015"><span class="lineNum">    2015</span>              : }</span>
<span id="L2016"><span class="lineNum">    2016</span>              : </span>
<span id="L2017"><span class="lineNum">    2017</span>              : // aten::chunk(Tensor(a -&gt; *) self, int chunks, int dim=0) -&gt; Tensor(a)[]</span>
<span id="L2018"><span class="lineNum">    2018</span>              : inline ::std::vector&lt;at::Tensor&gt; Tensor::chunk(int64_t chunks, int64_t dim) const {</span>
<span id="L2019"><span class="lineNum">    2019</span>              :     return at::_ops::chunk::call(const_cast&lt;Tensor&amp;&gt;(*this), chunks, dim);</span>
<span id="L2020"><span class="lineNum">    2020</span>              : }</span>
<span id="L2021"><span class="lineNum">    2021</span>              : </span>
<span id="L2022"><span class="lineNum">    2022</span>              : // aten::tensor_split.sections(Tensor(a -&gt; *) self, SymInt sections, int dim=0) -&gt; Tensor(a)[]</span>
<span id="L2023"><span class="lineNum">    2023</span>              : inline ::std::vector&lt;at::Tensor&gt; Tensor::tensor_split(int64_t sections, int64_t dim) const {</span>
<span id="L2024"><span class="lineNum">    2024</span>              :     return at::_ops::tensor_split_sections::call(const_cast&lt;Tensor&amp;&gt;(*this), sections, dim);</span>
<span id="L2025"><span class="lineNum">    2025</span>              : }</span>
<span id="L2026"><span class="lineNum">    2026</span>              : </span>
<span id="L2027"><span class="lineNum">    2027</span>              : // aten::tensor_split.sections(Tensor(a -&gt; *) self, SymInt sections, int dim=0) -&gt; Tensor(a)[]</span>
<span id="L2028"><span class="lineNum">    2028</span>              : inline ::std::vector&lt;at::Tensor&gt; Tensor::tensor_split_symint(c10::SymInt sections, int64_t dim) const {</span>
<span id="L2029"><span class="lineNum">    2029</span>              :     return at::_ops::tensor_split_sections::call(const_cast&lt;Tensor&amp;&gt;(*this), sections, dim);</span>
<span id="L2030"><span class="lineNum">    2030</span>              : }</span>
<span id="L2031"><span class="lineNum">    2031</span>              : </span>
<span id="L2032"><span class="lineNum">    2032</span>              : // aten::tensor_split.indices(Tensor(a -&gt; *) self, SymInt[] indices, int dim=0) -&gt; Tensor(a)[]</span>
<span id="L2033"><span class="lineNum">    2033</span>              : inline ::std::vector&lt;at::Tensor&gt; Tensor::tensor_split(at::IntArrayRef indices, int64_t dim) const {</span>
<span id="L2034"><span class="lineNum">    2034</span>              :     return at::_ops::tensor_split_indices::call(const_cast&lt;Tensor&amp;&gt;(*this), c10::fromIntArrayRefSlow(indices), dim);</span>
<span id="L2035"><span class="lineNum">    2035</span>              : }</span>
<span id="L2036"><span class="lineNum">    2036</span>              : </span>
<span id="L2037"><span class="lineNum">    2037</span>              : // aten::tensor_split.indices(Tensor(a -&gt; *) self, SymInt[] indices, int dim=0) -&gt; Tensor(a)[]</span>
<span id="L2038"><span class="lineNum">    2038</span>              : inline ::std::vector&lt;at::Tensor&gt; Tensor::tensor_split_symint(c10::SymIntArrayRef indices, int64_t dim) const {</span>
<span id="L2039"><span class="lineNum">    2039</span>              :     return at::_ops::tensor_split_indices::call(const_cast&lt;Tensor&amp;&gt;(*this), indices, dim);</span>
<span id="L2040"><span class="lineNum">    2040</span>              : }</span>
<span id="L2041"><span class="lineNum">    2041</span>              : </span>
<span id="L2042"><span class="lineNum">    2042</span>              : // aten::tensor_split.tensor_indices_or_sections(Tensor(a -&gt; *) self, Tensor tensor_indices_or_sections, int dim=0) -&gt; Tensor(a)[]</span>
<span id="L2043"><span class="lineNum">    2043</span>              : inline ::std::vector&lt;at::Tensor&gt; Tensor::tensor_split(const at::Tensor &amp; tensor_indices_or_sections, int64_t dim) const {</span>
<span id="L2044"><span class="lineNum">    2044</span>              :     return at::_ops::tensor_split_tensor_indices_or_sections::call(const_cast&lt;Tensor&amp;&gt;(*this), tensor_indices_or_sections, dim);</span>
<span id="L2045"><span class="lineNum">    2045</span>              : }</span>
<span id="L2046"><span class="lineNum">    2046</span>              : </span>
<span id="L2047"><span class="lineNum">    2047</span>              : // aten::clamp(Tensor self, Scalar? min=None, Scalar? max=None) -&gt; Tensor</span>
<span id="L2048"><span class="lineNum">    2048</span>              : inline at::Tensor Tensor::clamp(const ::std::optional&lt;at::Scalar&gt; &amp; min, const ::std::optional&lt;at::Scalar&gt; &amp; max) const {</span>
<span id="L2049"><span class="lineNum">    2049</span>              :     return at::_ops::clamp::call(const_cast&lt;Tensor&amp;&gt;(*this), min, max);</span>
<span id="L2050"><span class="lineNum">    2050</span>              : }</span>
<span id="L2051"><span class="lineNum">    2051</span>              : </span>
<span id="L2052"><span class="lineNum">    2052</span>              : // aten::clamp.Tensor(Tensor self, Tensor? min=None, Tensor? max=None) -&gt; Tensor</span>
<span id="L2053"><span class="lineNum">    2053</span>              : inline at::Tensor Tensor::clamp(const ::std::optional&lt;at::Tensor&gt; &amp; min, const ::std::optional&lt;at::Tensor&gt; &amp; max) const {</span>
<span id="L2054"><span class="lineNum">    2054</span>              :     return at::_ops::clamp_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), min, max);</span>
<span id="L2055"><span class="lineNum">    2055</span>              : }</span>
<span id="L2056"><span class="lineNum">    2056</span>              : </span>
<span id="L2057"><span class="lineNum">    2057</span>              : // aten::clamp_(Tensor(a!) self, Scalar? min=None, Scalar? max=None) -&gt; Tensor(a!)</span>
<span id="L2058"><span class="lineNum">    2058</span>              : inline at::Tensor &amp; Tensor::clamp_(const ::std::optional&lt;at::Scalar&gt; &amp; min, const ::std::optional&lt;at::Scalar&gt; &amp; max) const {</span>
<span id="L2059"><span class="lineNum">    2059</span>              :     return at::_ops::clamp_::call(const_cast&lt;Tensor&amp;&gt;(*this), min, max);</span>
<span id="L2060"><span class="lineNum">    2060</span>              : }</span>
<span id="L2061"><span class="lineNum">    2061</span>              : </span>
<span id="L2062"><span class="lineNum">    2062</span>              : // aten::clamp_.Tensor(Tensor(a!) self, Tensor? min=None, Tensor? max=None) -&gt; Tensor(a!)</span>
<span id="L2063"><span class="lineNum">    2063</span>              : inline at::Tensor &amp; Tensor::clamp_(const ::std::optional&lt;at::Tensor&gt; &amp; min, const ::std::optional&lt;at::Tensor&gt; &amp; max) const {</span>
<span id="L2064"><span class="lineNum">    2064</span>              :     return at::_ops::clamp__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), min, max);</span>
<span id="L2065"><span class="lineNum">    2065</span>              : }</span>
<span id="L2066"><span class="lineNum">    2066</span>              : </span>
<span id="L2067"><span class="lineNum">    2067</span>              : // aten::clamp_max(Tensor self, Scalar max) -&gt; Tensor</span>
<span id="L2068"><span class="lineNum">    2068</span>              : inline at::Tensor Tensor::clamp_max(const at::Scalar &amp; max) const {</span>
<span id="L2069"><span class="lineNum">    2069</span>              :     return at::_ops::clamp_max::call(const_cast&lt;Tensor&amp;&gt;(*this), max);</span>
<span id="L2070"><span class="lineNum">    2070</span>              : }</span>
<span id="L2071"><span class="lineNum">    2071</span>              : </span>
<span id="L2072"><span class="lineNum">    2072</span>              : // aten::clamp_max.Tensor(Tensor self, Tensor max) -&gt; Tensor</span>
<span id="L2073"><span class="lineNum">    2073</span>              : inline at::Tensor Tensor::clamp_max(const at::Tensor &amp; max) const {</span>
<span id="L2074"><span class="lineNum">    2074</span>              :     return at::_ops::clamp_max_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), max);</span>
<span id="L2075"><span class="lineNum">    2075</span>              : }</span>
<span id="L2076"><span class="lineNum">    2076</span>              : </span>
<span id="L2077"><span class="lineNum">    2077</span>              : // aten::clamp_max_(Tensor(a!) self, Scalar max) -&gt; Tensor(a!)</span>
<span id="L2078"><span class="lineNum">    2078</span>              : inline at::Tensor &amp; Tensor::clamp_max_(const at::Scalar &amp; max) const {</span>
<span id="L2079"><span class="lineNum">    2079</span>              :     return at::_ops::clamp_max_::call(const_cast&lt;Tensor&amp;&gt;(*this), max);</span>
<span id="L2080"><span class="lineNum">    2080</span>              : }</span>
<span id="L2081"><span class="lineNum">    2081</span>              : </span>
<span id="L2082"><span class="lineNum">    2082</span>              : // aten::clamp_max_.Tensor(Tensor(a!) self, Tensor max) -&gt; Tensor(a!)</span>
<span id="L2083"><span class="lineNum">    2083</span>              : inline at::Tensor &amp; Tensor::clamp_max_(const at::Tensor &amp; max) const {</span>
<span id="L2084"><span class="lineNum">    2084</span>              :     return at::_ops::clamp_max__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), max);</span>
<span id="L2085"><span class="lineNum">    2085</span>              : }</span>
<span id="L2086"><span class="lineNum">    2086</span>              : </span>
<span id="L2087"><span class="lineNum">    2087</span>              : // aten::clamp_min(Tensor self, Scalar min) -&gt; Tensor</span>
<span id="L2088"><span class="lineNum">    2088</span>              : inline at::Tensor Tensor::clamp_min(const at::Scalar &amp; min) const {</span>
<span id="L2089"><span class="lineNum">    2089</span>              :     return at::_ops::clamp_min::call(const_cast&lt;Tensor&amp;&gt;(*this), min);</span>
<span id="L2090"><span class="lineNum">    2090</span>              : }</span>
<span id="L2091"><span class="lineNum">    2091</span>              : </span>
<span id="L2092"><span class="lineNum">    2092</span>              : // aten::clamp_min.Tensor(Tensor self, Tensor min) -&gt; Tensor</span>
<span id="L2093"><span class="lineNum">    2093</span>              : inline at::Tensor Tensor::clamp_min(const at::Tensor &amp; min) const {</span>
<span id="L2094"><span class="lineNum">    2094</span>              :     return at::_ops::clamp_min_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), min);</span>
<span id="L2095"><span class="lineNum">    2095</span>              : }</span>
<span id="L2096"><span class="lineNum">    2096</span>              : </span>
<span id="L2097"><span class="lineNum">    2097</span>              : // aten::clamp_min_(Tensor(a!) self, Scalar min) -&gt; Tensor(a!)</span>
<span id="L2098"><span class="lineNum">    2098</span>              : inline at::Tensor &amp; Tensor::clamp_min_(const at::Scalar &amp; min) const {</span>
<span id="L2099"><span class="lineNum">    2099</span>              :     return at::_ops::clamp_min_::call(const_cast&lt;Tensor&amp;&gt;(*this), min);</span>
<span id="L2100"><span class="lineNum">    2100</span>              : }</span>
<span id="L2101"><span class="lineNum">    2101</span>              : </span>
<span id="L2102"><span class="lineNum">    2102</span>              : // aten::clamp_min_.Tensor(Tensor(a!) self, Tensor min) -&gt; Tensor(a!)</span>
<span id="L2103"><span class="lineNum">    2103</span>              : inline at::Tensor &amp; Tensor::clamp_min_(const at::Tensor &amp; min) const {</span>
<span id="L2104"><span class="lineNum">    2104</span>              :     return at::_ops::clamp_min__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), min);</span>
<span id="L2105"><span class="lineNum">    2105</span>              : }</span>
<span id="L2106"><span class="lineNum">    2106</span>              : </span>
<span id="L2107"><span class="lineNum">    2107</span>              : // aten::clip(Tensor self, Scalar? min=None, Scalar? max=None) -&gt; Tensor</span>
<span id="L2108"><span class="lineNum">    2108</span>              : inline at::Tensor Tensor::clip(const ::std::optional&lt;at::Scalar&gt; &amp; min, const ::std::optional&lt;at::Scalar&gt; &amp; max) const {</span>
<span id="L2109"><span class="lineNum">    2109</span>              :     return at::_ops::clip::call(const_cast&lt;Tensor&amp;&gt;(*this), min, max);</span>
<span id="L2110"><span class="lineNum">    2110</span>              : }</span>
<span id="L2111"><span class="lineNum">    2111</span>              : </span>
<span id="L2112"><span class="lineNum">    2112</span>              : // aten::clip.Tensor(Tensor self, Tensor? min=None, Tensor? max=None) -&gt; Tensor</span>
<span id="L2113"><span class="lineNum">    2113</span>              : inline at::Tensor Tensor::clip(const ::std::optional&lt;at::Tensor&gt; &amp; min, const ::std::optional&lt;at::Tensor&gt; &amp; max) const {</span>
<span id="L2114"><span class="lineNum">    2114</span>              :     return at::_ops::clip_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), min, max);</span>
<span id="L2115"><span class="lineNum">    2115</span>              : }</span>
<span id="L2116"><span class="lineNum">    2116</span>              : </span>
<span id="L2117"><span class="lineNum">    2117</span>              : // aten::clip_(Tensor(a!) self, Scalar? min=None, Scalar? max=None) -&gt; Tensor(a!)</span>
<span id="L2118"><span class="lineNum">    2118</span>              : inline at::Tensor &amp; Tensor::clip_(const ::std::optional&lt;at::Scalar&gt; &amp; min, const ::std::optional&lt;at::Scalar&gt; &amp; max) const {</span>
<span id="L2119"><span class="lineNum">    2119</span>              :     return at::_ops::clip_::call(const_cast&lt;Tensor&amp;&gt;(*this), min, max);</span>
<span id="L2120"><span class="lineNum">    2120</span>              : }</span>
<span id="L2121"><span class="lineNum">    2121</span>              : </span>
<span id="L2122"><span class="lineNum">    2122</span>              : // aten::clip_.Tensor(Tensor(a!) self, Tensor? min=None, Tensor? max=None) -&gt; Tensor(a!)</span>
<span id="L2123"><span class="lineNum">    2123</span>              : inline at::Tensor &amp; Tensor::clip_(const ::std::optional&lt;at::Tensor&gt; &amp; min, const ::std::optional&lt;at::Tensor&gt; &amp; max) const {</span>
<span id="L2124"><span class="lineNum">    2124</span>              :     return at::_ops::clip__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), min, max);</span>
<span id="L2125"><span class="lineNum">    2125</span>              : }</span>
<span id="L2126"><span class="lineNum">    2126</span>              : </span>
<span id="L2127"><span class="lineNum">    2127</span>              : // aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=contiguous_format) -&gt; Tensor(a)</span>
<span id="L2128"><span class="lineNum">    2128</span>              : inline at::Tensor Tensor::__dispatch_contiguous(at::MemoryFormat memory_format) const {</span>
<span id="L2129"><span class="lineNum">    2129</span>              :     return at::_ops::contiguous::call(const_cast&lt;Tensor&amp;&gt;(*this), memory_format);</span>
<span id="L2130"><span class="lineNum">    2130</span>              : }</span>
<span id="L2131"><span class="lineNum">    2131</span>              : </span>
<span id="L2132"><span class="lineNum">    2132</span>              : // aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -&gt; Tensor(a!)</span>
<span id="L2133"><span class="lineNum">    2133</span>              : inline at::Tensor &amp; Tensor::copy_(const at::Tensor &amp; src, bool non_blocking) const {</span>
<span id="L2134"><span class="lineNum">    2134</span>              :     return at::_ops::copy_::call(const_cast&lt;Tensor&amp;&gt;(*this), src, non_blocking);</span>
<span id="L2135"><span class="lineNum">    2135</span>              : }</span>
<span id="L2136"><span class="lineNum">    2136</span>              : </span>
<span id="L2137"><span class="lineNum">    2137</span>              : // aten::cos(Tensor self) -&gt; Tensor</span>
<span id="L2138"><span class="lineNum">    2138</span>              : inline at::Tensor Tensor::cos() const {</span>
<span id="L2139"><span class="lineNum">    2139</span>              :     return at::_ops::cos::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2140"><span class="lineNum">    2140</span>              : }</span>
<span id="L2141"><span class="lineNum">    2141</span>              : </span>
<span id="L2142"><span class="lineNum">    2142</span>              : // aten::cos_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L2143"><span class="lineNum">    2143</span>              : inline at::Tensor &amp; Tensor::cos_() const {</span>
<span id="L2144"><span class="lineNum">    2144</span>              :     return at::_ops::cos_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2145"><span class="lineNum">    2145</span>              : }</span>
<span id="L2146"><span class="lineNum">    2146</span>              : </span>
<span id="L2147"><span class="lineNum">    2147</span>              : // aten::cosh(Tensor self) -&gt; Tensor</span>
<span id="L2148"><span class="lineNum">    2148</span>              : inline at::Tensor Tensor::cosh() const {</span>
<span id="L2149"><span class="lineNum">    2149</span>              :     return at::_ops::cosh::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2150"><span class="lineNum">    2150</span>              : }</span>
<span id="L2151"><span class="lineNum">    2151</span>              : </span>
<span id="L2152"><span class="lineNum">    2152</span>              : // aten::cosh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L2153"><span class="lineNum">    2153</span>              : inline at::Tensor &amp; Tensor::cosh_() const {</span>
<span id="L2154"><span class="lineNum">    2154</span>              :     return at::_ops::cosh_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2155"><span class="lineNum">    2155</span>              : }</span>
<span id="L2156"><span class="lineNum">    2156</span>              : </span>
<span id="L2157"><span class="lineNum">    2157</span>              : // aten::count_nonzero.dim_IntList(Tensor self, int[] dim) -&gt; Tensor</span>
<span id="L2158"><span class="lineNum">    2158</span>              : inline at::Tensor Tensor::count_nonzero(at::IntArrayRef dim) const {</span>
<span id="L2159"><span class="lineNum">    2159</span>              :     return at::_ops::count_nonzero_dim_IntList::call(const_cast&lt;Tensor&amp;&gt;(*this), dim);</span>
<span id="L2160"><span class="lineNum">    2160</span>              : }</span>
<span id="L2161"><span class="lineNum">    2161</span>              : </span>
<span id="L2162"><span class="lineNum">    2162</span>              : // aten::count_nonzero(Tensor self, int? dim=None) -&gt; Tensor</span>
<span id="L2163"><span class="lineNum">    2163</span>              : inline at::Tensor Tensor::count_nonzero(::std::optional&lt;int64_t&gt; dim) const {</span>
<span id="L2164"><span class="lineNum">    2164</span>              :     return at::_ops::count_nonzero::call(const_cast&lt;Tensor&amp;&gt;(*this), dim);</span>
<span id="L2165"><span class="lineNum">    2165</span>              : }</span>
<span id="L2166"><span class="lineNum">    2166</span>              : </span>
<span id="L2167"><span class="lineNum">    2167</span>              : // aten::cov(Tensor self, *, int correction=1, Tensor? fweights=None, Tensor? aweights=None) -&gt; Tensor</span>
<span id="L2168"><span class="lineNum">    2168</span>              : inline at::Tensor Tensor::cov(int64_t correction, const ::std::optional&lt;at::Tensor&gt; &amp; fweights, const ::std::optional&lt;at::Tensor&gt; &amp; aweights) const {</span>
<span id="L2169"><span class="lineNum">    2169</span>              :     return at::_ops::cov::call(const_cast&lt;Tensor&amp;&gt;(*this), correction, fweights, aweights);</span>
<span id="L2170"><span class="lineNum">    2170</span>              : }</span>
<span id="L2171"><span class="lineNum">    2171</span>              : </span>
<span id="L2172"><span class="lineNum">    2172</span>              : // aten::corrcoef(Tensor self) -&gt; Tensor</span>
<span id="L2173"><span class="lineNum">    2173</span>              : inline at::Tensor Tensor::corrcoef() const {</span>
<span id="L2174"><span class="lineNum">    2174</span>              :     return at::_ops::corrcoef::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2175"><span class="lineNum">    2175</span>              : }</span>
<span id="L2176"><span class="lineNum">    2176</span>              : </span>
<span id="L2177"><span class="lineNum">    2177</span>              : // aten::cummax(Tensor self, int dim) -&gt; (Tensor values, Tensor indices)</span>
<span id="L2178"><span class="lineNum">    2178</span>              : inline ::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::cummax(int64_t dim) const {</span>
<span id="L2179"><span class="lineNum">    2179</span>              :     return at::_ops::cummax::call(const_cast&lt;Tensor&amp;&gt;(*this), dim);</span>
<span id="L2180"><span class="lineNum">    2180</span>              : }</span>
<span id="L2181"><span class="lineNum">    2181</span>              : </span>
<span id="L2182"><span class="lineNum">    2182</span>              : // aten::cummax.dimname(Tensor self, Dimname dim) -&gt; (Tensor values, Tensor indices)</span>
<span id="L2183"><span class="lineNum">    2183</span>              : inline ::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::cummax(at::Dimname dim) const {</span>
<span id="L2184"><span class="lineNum">    2184</span>              :     return at::_ops::cummax_dimname::call(const_cast&lt;Tensor&amp;&gt;(*this), dim);</span>
<span id="L2185"><span class="lineNum">    2185</span>              : }</span>
<span id="L2186"><span class="lineNum">    2186</span>              : </span>
<span id="L2187"><span class="lineNum">    2187</span>              : // aten::cummin(Tensor self, int dim) -&gt; (Tensor values, Tensor indices)</span>
<span id="L2188"><span class="lineNum">    2188</span>              : inline ::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::cummin(int64_t dim) const {</span>
<span id="L2189"><span class="lineNum">    2189</span>              :     return at::_ops::cummin::call(const_cast&lt;Tensor&amp;&gt;(*this), dim);</span>
<span id="L2190"><span class="lineNum">    2190</span>              : }</span>
<span id="L2191"><span class="lineNum">    2191</span>              : </span>
<span id="L2192"><span class="lineNum">    2192</span>              : // aten::cummin.dimname(Tensor self, Dimname dim) -&gt; (Tensor values, Tensor indices)</span>
<span id="L2193"><span class="lineNum">    2193</span>              : inline ::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::cummin(at::Dimname dim) const {</span>
<span id="L2194"><span class="lineNum">    2194</span>              :     return at::_ops::cummin_dimname::call(const_cast&lt;Tensor&amp;&gt;(*this), dim);</span>
<span id="L2195"><span class="lineNum">    2195</span>              : }</span>
<span id="L2196"><span class="lineNum">    2196</span>              : </span>
<span id="L2197"><span class="lineNum">    2197</span>              : // aten::cumprod(Tensor self, int dim, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span id="L2198"><span class="lineNum">    2198</span>              : inline at::Tensor Tensor::cumprod(int64_t dim, ::std::optional&lt;at::ScalarType&gt; dtype) const {</span>
<span id="L2199"><span class="lineNum">    2199</span>              :     return at::_ops::cumprod::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, dtype);</span>
<span id="L2200"><span class="lineNum">    2200</span>              : }</span>
<span id="L2201"><span class="lineNum">    2201</span>              : </span>
<span id="L2202"><span class="lineNum">    2202</span>              : // aten::cumprod_(Tensor(a!) self, int dim, *, ScalarType? dtype=None) -&gt; Tensor(a!)</span>
<span id="L2203"><span class="lineNum">    2203</span>              : inline at::Tensor &amp; Tensor::cumprod_(int64_t dim, ::std::optional&lt;at::ScalarType&gt; dtype) const {</span>
<span id="L2204"><span class="lineNum">    2204</span>              :     return at::_ops::cumprod_::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, dtype);</span>
<span id="L2205"><span class="lineNum">    2205</span>              : }</span>
<span id="L2206"><span class="lineNum">    2206</span>              : </span>
<span id="L2207"><span class="lineNum">    2207</span>              : // aten::cumprod.dimname(Tensor self, Dimname dim, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span id="L2208"><span class="lineNum">    2208</span>              : inline at::Tensor Tensor::cumprod(at::Dimname dim, ::std::optional&lt;at::ScalarType&gt; dtype) const {</span>
<span id="L2209"><span class="lineNum">    2209</span>              :     return at::_ops::cumprod_dimname::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, dtype);</span>
<span id="L2210"><span class="lineNum">    2210</span>              : }</span>
<span id="L2211"><span class="lineNum">    2211</span>              : </span>
<span id="L2212"><span class="lineNum">    2212</span>              : // aten::cumprod_.dimname(Tensor(a!) self, Dimname dim, *, ScalarType? dtype=None) -&gt; Tensor(a!)</span>
<span id="L2213"><span class="lineNum">    2213</span>              : inline at::Tensor &amp; Tensor::cumprod_(at::Dimname dim, ::std::optional&lt;at::ScalarType&gt; dtype) const {</span>
<span id="L2214"><span class="lineNum">    2214</span>              :     return at::_ops::cumprod__dimname::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, dtype);</span>
<span id="L2215"><span class="lineNum">    2215</span>              : }</span>
<span id="L2216"><span class="lineNum">    2216</span>              : </span>
<span id="L2217"><span class="lineNum">    2217</span>              : // aten::cumsum(Tensor self, int dim, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span id="L2218"><span class="lineNum">    2218</span>              : inline at::Tensor Tensor::cumsum(int64_t dim, ::std::optional&lt;at::ScalarType&gt; dtype) const {</span>
<span id="L2219"><span class="lineNum">    2219</span>              :     return at::_ops::cumsum::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, dtype);</span>
<span id="L2220"><span class="lineNum">    2220</span>              : }</span>
<span id="L2221"><span class="lineNum">    2221</span>              : </span>
<span id="L2222"><span class="lineNum">    2222</span>              : // aten::cumsum_(Tensor(a!) self, int dim, *, ScalarType? dtype=None) -&gt; Tensor(a!)</span>
<span id="L2223"><span class="lineNum">    2223</span>              : inline at::Tensor &amp; Tensor::cumsum_(int64_t dim, ::std::optional&lt;at::ScalarType&gt; dtype) const {</span>
<span id="L2224"><span class="lineNum">    2224</span>              :     return at::_ops::cumsum_::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, dtype);</span>
<span id="L2225"><span class="lineNum">    2225</span>              : }</span>
<span id="L2226"><span class="lineNum">    2226</span>              : </span>
<span id="L2227"><span class="lineNum">    2227</span>              : // aten::cumsum.dimname(Tensor self, Dimname dim, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span id="L2228"><span class="lineNum">    2228</span>              : inline at::Tensor Tensor::cumsum(at::Dimname dim, ::std::optional&lt;at::ScalarType&gt; dtype) const {</span>
<span id="L2229"><span class="lineNum">    2229</span>              :     return at::_ops::cumsum_dimname::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, dtype);</span>
<span id="L2230"><span class="lineNum">    2230</span>              : }</span>
<span id="L2231"><span class="lineNum">    2231</span>              : </span>
<span id="L2232"><span class="lineNum">    2232</span>              : // aten::cumsum_.dimname(Tensor(a!) self, Dimname dim, *, ScalarType? dtype=None) -&gt; Tensor(a!)</span>
<span id="L2233"><span class="lineNum">    2233</span>              : inline at::Tensor &amp; Tensor::cumsum_(at::Dimname dim, ::std::optional&lt;at::ScalarType&gt; dtype) const {</span>
<span id="L2234"><span class="lineNum">    2234</span>              :     return at::_ops::cumsum__dimname::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, dtype);</span>
<span id="L2235"><span class="lineNum">    2235</span>              : }</span>
<span id="L2236"><span class="lineNum">    2236</span>              : </span>
<span id="L2237"><span class="lineNum">    2237</span>              : // aten::diag_embed(Tensor self, int offset=0, int dim1=-2, int dim2=-1) -&gt; Tensor</span>
<span id="L2238"><span class="lineNum">    2238</span>              : inline at::Tensor Tensor::diag_embed(int64_t offset, int64_t dim1, int64_t dim2) const {</span>
<span id="L2239"><span class="lineNum">    2239</span>              :     return at::_ops::diag_embed::call(const_cast&lt;Tensor&amp;&gt;(*this), offset, dim1, dim2);</span>
<span id="L2240"><span class="lineNum">    2240</span>              : }</span>
<span id="L2241"><span class="lineNum">    2241</span>              : </span>
<span id="L2242"><span class="lineNum">    2242</span>              : // aten::diagflat(Tensor self, int offset=0) -&gt; Tensor</span>
<span id="L2243"><span class="lineNum">    2243</span>              : inline at::Tensor Tensor::diagflat(int64_t offset) const {</span>
<span id="L2244"><span class="lineNum">    2244</span>              :     return at::_ops::diagflat::call(const_cast&lt;Tensor&amp;&gt;(*this), offset);</span>
<span id="L2245"><span class="lineNum">    2245</span>              : }</span>
<span id="L2246"><span class="lineNum">    2246</span>              : </span>
<span id="L2247"><span class="lineNum">    2247</span>              : // aten::diagonal(Tensor(a) self, int offset=0, int dim1=0, int dim2=1) -&gt; Tensor(a)</span>
<span id="L2248"><span class="lineNum">    2248</span>              : inline at::Tensor Tensor::diagonal(int64_t offset, int64_t dim1, int64_t dim2) const {</span>
<span id="L2249"><span class="lineNum">    2249</span>              :     return at::_ops::diagonal::call(const_cast&lt;Tensor&amp;&gt;(*this), offset, dim1, dim2);</span>
<span id="L2250"><span class="lineNum">    2250</span>              : }</span>
<span id="L2251"><span class="lineNum">    2251</span>              : </span>
<span id="L2252"><span class="lineNum">    2252</span>              : // aten::diagonal.Dimname(Tensor(a) self, *, Dimname outdim, Dimname dim1, Dimname dim2, int offset=0) -&gt; Tensor(a)</span>
<span id="L2253"><span class="lineNum">    2253</span>              : inline at::Tensor Tensor::diagonal(at::Dimname outdim, at::Dimname dim1, at::Dimname dim2, int64_t offset) const {</span>
<span id="L2254"><span class="lineNum">    2254</span>              :     return at::_ops::diagonal_Dimname::call(const_cast&lt;Tensor&amp;&gt;(*this), outdim, dim1, dim2, offset);</span>
<span id="L2255"><span class="lineNum">    2255</span>              : }</span>
<span id="L2256"><span class="lineNum">    2256</span>              : </span>
<span id="L2257"><span class="lineNum">    2257</span>              : // aten::fill_diagonal_(Tensor(a!) self, Scalar fill_value, bool wrap=False) -&gt; Tensor(a!)</span>
<span id="L2258"><span class="lineNum">    2258</span>              : inline at::Tensor &amp; Tensor::fill_diagonal_(const at::Scalar &amp; fill_value, bool wrap) const {</span>
<span id="L2259"><span class="lineNum">    2259</span>              :     return at::_ops::fill_diagonal_::call(const_cast&lt;Tensor&amp;&gt;(*this), fill_value, wrap);</span>
<span id="L2260"><span class="lineNum">    2260</span>              : }</span>
<span id="L2261"><span class="lineNum">    2261</span>              : </span>
<span id="L2262"><span class="lineNum">    2262</span>              : // aten::diff(Tensor self, int n=1, int dim=-1, Tensor? prepend=None, Tensor? append=None) -&gt; Tensor</span>
<span id="L2263"><span class="lineNum">    2263</span>              : inline at::Tensor Tensor::diff(int64_t n, int64_t dim, const ::std::optional&lt;at::Tensor&gt; &amp; prepend, const ::std::optional&lt;at::Tensor&gt; &amp; append) const {</span>
<span id="L2264"><span class="lineNum">    2264</span>              :     return at::_ops::diff::call(const_cast&lt;Tensor&amp;&gt;(*this), n, dim, prepend, append);</span>
<span id="L2265"><span class="lineNum">    2265</span>              : }</span>
<span id="L2266"><span class="lineNum">    2266</span>              : </span>
<span id="L2267"><span class="lineNum">    2267</span>              : // aten::div.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L2268"><span class="lineNum">    2268</span>              : inline at::Tensor Tensor::div(const at::Tensor &amp; other) const {</span>
<span id="L2269"><span class="lineNum">    2269</span>              :     return at::_ops::div_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L2270"><span class="lineNum">    2270</span>              : }</span>
<span id="L2271"><span class="lineNum">    2271</span>              : </span>
<span id="L2272"><span class="lineNum">    2272</span>              : // aten::div_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L2273"><span class="lineNum">    2273</span>              : inline at::Tensor &amp; Tensor::div_(const at::Tensor &amp; other) const {</span>
<span id="L2274"><span class="lineNum">    2274</span>              :     return at::_ops::div__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L2275"><span class="lineNum">    2275</span>              : }</span>
<span id="L2276"><span class="lineNum">    2276</span>              : </span>
<span id="L2277"><span class="lineNum">    2277</span>              : // aten::div.Tensor_mode(Tensor self, Tensor other, *, str? rounding_mode) -&gt; Tensor</span>
<span id="L2278"><span class="lineNum">    2278</span>              : inline at::Tensor Tensor::div(const at::Tensor &amp; other, ::std::optional&lt;c10::string_view&gt; rounding_mode) const {</span>
<span id="L2279"><span class="lineNum">    2279</span>              :     return at::_ops::div_Tensor_mode::call(const_cast&lt;Tensor&amp;&gt;(*this), other, rounding_mode);</span>
<span id="L2280"><span class="lineNum">    2280</span>              : }</span>
<span id="L2281"><span class="lineNum">    2281</span>              : </span>
<span id="L2282"><span class="lineNum">    2282</span>              : // aten::div_.Tensor_mode(Tensor(a!) self, Tensor other, *, str? rounding_mode) -&gt; Tensor(a!)</span>
<span id="L2283"><span class="lineNum">    2283</span>              : inline at::Tensor &amp; Tensor::div_(const at::Tensor &amp; other, ::std::optional&lt;c10::string_view&gt; rounding_mode) const {</span>
<span id="L2284"><span class="lineNum">    2284</span>              :     return at::_ops::div__Tensor_mode::call(const_cast&lt;Tensor&amp;&gt;(*this), other, rounding_mode);</span>
<span id="L2285"><span class="lineNum">    2285</span>              : }</span>
<span id="L2286"><span class="lineNum">    2286</span>              : </span>
<span id="L2287"><span class="lineNum">    2287</span>              : // aten::div.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span id="L2288"><span class="lineNum">    2288</span>              : inline at::Tensor Tensor::div(const at::Scalar &amp; other) const {</span>
<span id="L2289"><span class="lineNum">    2289</span>              :     return at::_ops::div_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L2290"><span class="lineNum">    2290</span>              : }</span>
<span id="L2291"><span class="lineNum">    2291</span>              : </span>
<span id="L2292"><span class="lineNum">    2292</span>              : // aten::div_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span id="L2293"><span class="lineNum">    2293</span>              : inline at::Tensor &amp; Tensor::div_(const at::Scalar &amp; other) const {</span>
<span id="L2294"><span class="lineNum">    2294</span>              :     return at::_ops::div__Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L2295"><span class="lineNum">    2295</span>              : }</span>
<span id="L2296"><span class="lineNum">    2296</span>              : </span>
<span id="L2297"><span class="lineNum">    2297</span>              : // aten::div.Scalar_mode(Tensor self, Scalar other, *, str? rounding_mode) -&gt; Tensor</span>
<span id="L2298"><span class="lineNum">    2298</span>              : inline at::Tensor Tensor::div(const at::Scalar &amp; other, ::std::optional&lt;c10::string_view&gt; rounding_mode) const {</span>
<span id="L2299"><span class="lineNum">    2299</span>              :     return at::_ops::div_Scalar_mode::call(const_cast&lt;Tensor&amp;&gt;(*this), other, rounding_mode);</span>
<span id="L2300"><span class="lineNum">    2300</span>              : }</span>
<span id="L2301"><span class="lineNum">    2301</span>              : </span>
<span id="L2302"><span class="lineNum">    2302</span>              : // aten::div_.Scalar_mode(Tensor(a!) self, Scalar other, *, str? rounding_mode) -&gt; Tensor(a!)</span>
<span id="L2303"><span class="lineNum">    2303</span>              : inline at::Tensor &amp; Tensor::div_(const at::Scalar &amp; other, ::std::optional&lt;c10::string_view&gt; rounding_mode) const {</span>
<span id="L2304"><span class="lineNum">    2304</span>              :     return at::_ops::div__Scalar_mode::call(const_cast&lt;Tensor&amp;&gt;(*this), other, rounding_mode);</span>
<span id="L2305"><span class="lineNum">    2305</span>              : }</span>
<span id="L2306"><span class="lineNum">    2306</span>              : </span>
<span id="L2307"><span class="lineNum">    2307</span>              : // aten::divide.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L2308"><span class="lineNum">    2308</span>              : inline at::Tensor Tensor::divide(const at::Tensor &amp; other) const {</span>
<span id="L2309"><span class="lineNum">    2309</span>              :     return at::_ops::divide_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L2310"><span class="lineNum">    2310</span>              : }</span>
<span id="L2311"><span class="lineNum">    2311</span>              : </span>
<span id="L2312"><span class="lineNum">    2312</span>              : // aten::divide_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L2313"><span class="lineNum">    2313</span>              : inline at::Tensor &amp; Tensor::divide_(const at::Tensor &amp; other) const {</span>
<span id="L2314"><span class="lineNum">    2314</span>              :     return at::_ops::divide__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L2315"><span class="lineNum">    2315</span>              : }</span>
<span id="L2316"><span class="lineNum">    2316</span>              : </span>
<span id="L2317"><span class="lineNum">    2317</span>              : // aten::divide.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span id="L2318"><span class="lineNum">    2318</span>              : inline at::Tensor Tensor::divide(const at::Scalar &amp; other) const {</span>
<span id="L2319"><span class="lineNum">    2319</span>              :     return at::_ops::divide_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L2320"><span class="lineNum">    2320</span>              : }</span>
<span id="L2321"><span class="lineNum">    2321</span>              : </span>
<span id="L2322"><span class="lineNum">    2322</span>              : // aten::divide_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span id="L2323"><span class="lineNum">    2323</span>              : inline at::Tensor &amp; Tensor::divide_(const at::Scalar &amp; other) const {</span>
<span id="L2324"><span class="lineNum">    2324</span>              :     return at::_ops::divide__Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L2325"><span class="lineNum">    2325</span>              : }</span>
<span id="L2326"><span class="lineNum">    2326</span>              : </span>
<span id="L2327"><span class="lineNum">    2327</span>              : // aten::divide.Tensor_mode(Tensor self, Tensor other, *, str? rounding_mode) -&gt; Tensor</span>
<span id="L2328"><span class="lineNum">    2328</span>              : inline at::Tensor Tensor::divide(const at::Tensor &amp; other, ::std::optional&lt;c10::string_view&gt; rounding_mode) const {</span>
<span id="L2329"><span class="lineNum">    2329</span>              :     return at::_ops::divide_Tensor_mode::call(const_cast&lt;Tensor&amp;&gt;(*this), other, rounding_mode);</span>
<span id="L2330"><span class="lineNum">    2330</span>              : }</span>
<span id="L2331"><span class="lineNum">    2331</span>              : </span>
<span id="L2332"><span class="lineNum">    2332</span>              : // aten::divide_.Tensor_mode(Tensor(a!) self, Tensor other, *, str? rounding_mode) -&gt; Tensor(a!)</span>
<span id="L2333"><span class="lineNum">    2333</span>              : inline at::Tensor &amp; Tensor::divide_(const at::Tensor &amp; other, ::std::optional&lt;c10::string_view&gt; rounding_mode) const {</span>
<span id="L2334"><span class="lineNum">    2334</span>              :     return at::_ops::divide__Tensor_mode::call(const_cast&lt;Tensor&amp;&gt;(*this), other, rounding_mode);</span>
<span id="L2335"><span class="lineNum">    2335</span>              : }</span>
<span id="L2336"><span class="lineNum">    2336</span>              : </span>
<span id="L2337"><span class="lineNum">    2337</span>              : // aten::divide.Scalar_mode(Tensor self, Scalar other, *, str? rounding_mode) -&gt; Tensor</span>
<span id="L2338"><span class="lineNum">    2338</span>              : inline at::Tensor Tensor::divide(const at::Scalar &amp; other, ::std::optional&lt;c10::string_view&gt; rounding_mode) const {</span>
<span id="L2339"><span class="lineNum">    2339</span>              :     return at::_ops::divide_Scalar_mode::call(const_cast&lt;Tensor&amp;&gt;(*this), other, rounding_mode);</span>
<span id="L2340"><span class="lineNum">    2340</span>              : }</span>
<span id="L2341"><span class="lineNum">    2341</span>              : </span>
<span id="L2342"><span class="lineNum">    2342</span>              : // aten::divide_.Scalar_mode(Tensor(a!) self, Scalar other, *, str? rounding_mode) -&gt; Tensor(a!)</span>
<span id="L2343"><span class="lineNum">    2343</span>              : inline at::Tensor &amp; Tensor::divide_(const at::Scalar &amp; other, ::std::optional&lt;c10::string_view&gt; rounding_mode) const {</span>
<span id="L2344"><span class="lineNum">    2344</span>              :     return at::_ops::divide__Scalar_mode::call(const_cast&lt;Tensor&amp;&gt;(*this), other, rounding_mode);</span>
<span id="L2345"><span class="lineNum">    2345</span>              : }</span>
<span id="L2346"><span class="lineNum">    2346</span>              : </span>
<span id="L2347"><span class="lineNum">    2347</span>              : // aten::true_divide.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L2348"><span class="lineNum">    2348</span>              : inline at::Tensor Tensor::true_divide(const at::Tensor &amp; other) const {</span>
<span id="L2349"><span class="lineNum">    2349</span>              :     return at::_ops::true_divide_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L2350"><span class="lineNum">    2350</span>              : }</span>
<span id="L2351"><span class="lineNum">    2351</span>              : </span>
<span id="L2352"><span class="lineNum">    2352</span>              : // aten::true_divide_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L2353"><span class="lineNum">    2353</span>              : inline at::Tensor &amp; Tensor::true_divide_(const at::Tensor &amp; other) const {</span>
<span id="L2354"><span class="lineNum">    2354</span>              :     return at::_ops::true_divide__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L2355"><span class="lineNum">    2355</span>              : }</span>
<span id="L2356"><span class="lineNum">    2356</span>              : </span>
<span id="L2357"><span class="lineNum">    2357</span>              : // aten::true_divide.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span id="L2358"><span class="lineNum">    2358</span>              : inline at::Tensor Tensor::true_divide(const at::Scalar &amp; other) const {</span>
<span id="L2359"><span class="lineNum">    2359</span>              :     return at::_ops::true_divide_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L2360"><span class="lineNum">    2360</span>              : }</span>
<span id="L2361"><span class="lineNum">    2361</span>              : </span>
<span id="L2362"><span class="lineNum">    2362</span>              : // aten::true_divide_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span id="L2363"><span class="lineNum">    2363</span>              : inline at::Tensor &amp; Tensor::true_divide_(const at::Scalar &amp; other) const {</span>
<span id="L2364"><span class="lineNum">    2364</span>              :     return at::_ops::true_divide__Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L2365"><span class="lineNum">    2365</span>              : }</span>
<span id="L2366"><span class="lineNum">    2366</span>              : </span>
<span id="L2367"><span class="lineNum">    2367</span>              : // aten::dot(Tensor self, Tensor tensor) -&gt; Tensor</span>
<span id="L2368"><span class="lineNum">    2368</span>              : inline at::Tensor Tensor::dot(const at::Tensor &amp; tensor) const {</span>
<span id="L2369"><span class="lineNum">    2369</span>              :     return at::_ops::dot::call(const_cast&lt;Tensor&amp;&gt;(*this), tensor);</span>
<span id="L2370"><span class="lineNum">    2370</span>              : }</span>
<span id="L2371"><span class="lineNum">    2371</span>              : </span>
<span id="L2372"><span class="lineNum">    2372</span>              : // aten::vdot(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L2373"><span class="lineNum">    2373</span>              : inline at::Tensor Tensor::vdot(const at::Tensor &amp; other) const {</span>
<span id="L2374"><span class="lineNum">    2374</span>              :     return at::_ops::vdot::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L2375"><span class="lineNum">    2375</span>              : }</span>
<span id="L2376"><span class="lineNum">    2376</span>              : </span>
<span id="L2377"><span class="lineNum">    2377</span>              : // aten::new_empty(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span id="L2378"><span class="lineNum">    2378</span>              : inline at::Tensor Tensor::new_empty(at::IntArrayRef size, at::TensorOptions options) const {</span>
<span id="L2379"><span class="lineNum">    2379</span>              :     return at::_ops::new_empty::call(const_cast&lt;Tensor&amp;&gt;(*this), c10::fromIntArrayRefSlow(size), c10::optTypeMetaToScalarType(options.dtype_opt()), options.layout_opt(), options.device_opt(), options.pinned_memory_opt());</span>
<span id="L2380"><span class="lineNum">    2380</span>              : }</span>
<span id="L2381"><span class="lineNum">    2381</span>              : </span>
<span id="L2382"><span class="lineNum">    2382</span>              : // aten::new_empty(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span id="L2383"><span class="lineNum">    2383</span>              : inline at::Tensor Tensor::new_empty(at::IntArrayRef size, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;bool&gt; pin_memory) const {</span>
<span id="L2384"><span class="lineNum">    2384</span>              :     return at::_ops::new_empty::call(const_cast&lt;Tensor&amp;&gt;(*this), c10::fromIntArrayRefSlow(size), dtype, layout, device, pin_memory);</span>
<span id="L2385"><span class="lineNum">    2385</span>              : }</span>
<span id="L2386"><span class="lineNum">    2386</span>              : </span>
<span id="L2387"><span class="lineNum">    2387</span>              : // aten::new_empty(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span id="L2388"><span class="lineNum">    2388</span>              : inline at::Tensor Tensor::new_empty_symint(c10::SymIntArrayRef size, at::TensorOptions options) const {</span>
<span id="L2389"><span class="lineNum">    2389</span>              :     return at::_ops::new_empty::call(const_cast&lt;Tensor&amp;&gt;(*this), size, c10::optTypeMetaToScalarType(options.dtype_opt()), options.layout_opt(), options.device_opt(), options.pinned_memory_opt());</span>
<span id="L2390"><span class="lineNum">    2390</span>              : }</span>
<span id="L2391"><span class="lineNum">    2391</span>              : </span>
<span id="L2392"><span class="lineNum">    2392</span>              : // aten::new_empty(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span id="L2393"><span class="lineNum">    2393</span>              : inline at::Tensor Tensor::new_empty_symint(c10::SymIntArrayRef size, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;bool&gt; pin_memory) const {</span>
<span id="L2394"><span class="lineNum">    2394</span>              :     return at::_ops::new_empty::call(const_cast&lt;Tensor&amp;&gt;(*this), size, dtype, layout, device, pin_memory);</span>
<span id="L2395"><span class="lineNum">    2395</span>              : }</span>
<span id="L2396"><span class="lineNum">    2396</span>              : </span>
<span id="L2397"><span class="lineNum">    2397</span>              : // aten::new_empty_strided(Tensor self, SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span id="L2398"><span class="lineNum">    2398</span>              : inline at::Tensor Tensor::new_empty_strided(at::IntArrayRef size, at::IntArrayRef stride, at::TensorOptions options) const {</span>
<span id="L2399"><span class="lineNum">    2399</span>              :     return at::_ops::new_empty_strided::call(const_cast&lt;Tensor&amp;&gt;(*this), c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride), c10::optTypeMetaToScalarType(options.dtype_opt()), options.layout_opt(), options.device_opt(), options.pinned_memory_opt());</span>
<span id="L2400"><span class="lineNum">    2400</span>              : }</span>
<span id="L2401"><span class="lineNum">    2401</span>              : </span>
<span id="L2402"><span class="lineNum">    2402</span>              : // aten::new_empty_strided(Tensor self, SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span id="L2403"><span class="lineNum">    2403</span>              : inline at::Tensor Tensor::new_empty_strided(at::IntArrayRef size, at::IntArrayRef stride, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;bool&gt; pin_memory) const {</span>
<span id="L2404"><span class="lineNum">    2404</span>              :     return at::_ops::new_empty_strided::call(const_cast&lt;Tensor&amp;&gt;(*this), c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride), dtype, layout, device, pin_memory);</span>
<span id="L2405"><span class="lineNum">    2405</span>              : }</span>
<span id="L2406"><span class="lineNum">    2406</span>              : </span>
<span id="L2407"><span class="lineNum">    2407</span>              : // aten::new_empty_strided(Tensor self, SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span id="L2408"><span class="lineNum">    2408</span>              : inline at::Tensor Tensor::new_empty_strided_symint(c10::SymIntArrayRef size, c10::SymIntArrayRef stride, at::TensorOptions options) const {</span>
<span id="L2409"><span class="lineNum">    2409</span>              :     return at::_ops::new_empty_strided::call(const_cast&lt;Tensor&amp;&gt;(*this), size, stride, c10::optTypeMetaToScalarType(options.dtype_opt()), options.layout_opt(), options.device_opt(), options.pinned_memory_opt());</span>
<span id="L2410"><span class="lineNum">    2410</span>              : }</span>
<span id="L2411"><span class="lineNum">    2411</span>              : </span>
<span id="L2412"><span class="lineNum">    2412</span>              : // aten::new_empty_strided(Tensor self, SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span id="L2413"><span class="lineNum">    2413</span>              : inline at::Tensor Tensor::new_empty_strided_symint(c10::SymIntArrayRef size, c10::SymIntArrayRef stride, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;bool&gt; pin_memory) const {</span>
<span id="L2414"><span class="lineNum">    2414</span>              :     return at::_ops::new_empty_strided::call(const_cast&lt;Tensor&amp;&gt;(*this), size, stride, dtype, layout, device, pin_memory);</span>
<span id="L2415"><span class="lineNum">    2415</span>              : }</span>
<span id="L2416"><span class="lineNum">    2416</span>              : </span>
<span id="L2417"><span class="lineNum">    2417</span>              : // aten::new_full(Tensor self, SymInt[] size, Scalar fill_value, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span id="L2418"><span class="lineNum">    2418</span>              : inline at::Tensor Tensor::new_full(at::IntArrayRef size, const at::Scalar &amp; fill_value, at::TensorOptions options) const {</span>
<span id="L2419"><span class="lineNum">    2419</span>              :     return at::_ops::new_full::call(const_cast&lt;Tensor&amp;&gt;(*this), c10::fromIntArrayRefSlow(size), fill_value, c10::optTypeMetaToScalarType(options.dtype_opt()), options.layout_opt(), options.device_opt(), options.pinned_memory_opt());</span>
<span id="L2420"><span class="lineNum">    2420</span>              : }</span>
<span id="L2421"><span class="lineNum">    2421</span>              : </span>
<span id="L2422"><span class="lineNum">    2422</span>              : // aten::new_full(Tensor self, SymInt[] size, Scalar fill_value, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span id="L2423"><span class="lineNum">    2423</span>              : inline at::Tensor Tensor::new_full(at::IntArrayRef size, const at::Scalar &amp; fill_value, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;bool&gt; pin_memory) const {</span>
<span id="L2424"><span class="lineNum">    2424</span>              :     return at::_ops::new_full::call(const_cast&lt;Tensor&amp;&gt;(*this), c10::fromIntArrayRefSlow(size), fill_value, dtype, layout, device, pin_memory);</span>
<span id="L2425"><span class="lineNum">    2425</span>              : }</span>
<span id="L2426"><span class="lineNum">    2426</span>              : </span>
<span id="L2427"><span class="lineNum">    2427</span>              : // aten::new_full(Tensor self, SymInt[] size, Scalar fill_value, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span id="L2428"><span class="lineNum">    2428</span>              : inline at::Tensor Tensor::new_full_symint(c10::SymIntArrayRef size, const at::Scalar &amp; fill_value, at::TensorOptions options) const {</span>
<span id="L2429"><span class="lineNum">    2429</span>              :     return at::_ops::new_full::call(const_cast&lt;Tensor&amp;&gt;(*this), size, fill_value, c10::optTypeMetaToScalarType(options.dtype_opt()), options.layout_opt(), options.device_opt(), options.pinned_memory_opt());</span>
<span id="L2430"><span class="lineNum">    2430</span>              : }</span>
<span id="L2431"><span class="lineNum">    2431</span>              : </span>
<span id="L2432"><span class="lineNum">    2432</span>              : // aten::new_full(Tensor self, SymInt[] size, Scalar fill_value, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span id="L2433"><span class="lineNum">    2433</span>              : inline at::Tensor Tensor::new_full_symint(c10::SymIntArrayRef size, const at::Scalar &amp; fill_value, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;bool&gt; pin_memory) const {</span>
<span id="L2434"><span class="lineNum">    2434</span>              :     return at::_ops::new_full::call(const_cast&lt;Tensor&amp;&gt;(*this), size, fill_value, dtype, layout, device, pin_memory);</span>
<span id="L2435"><span class="lineNum">    2435</span>              : }</span>
<span id="L2436"><span class="lineNum">    2436</span>              : </span>
<span id="L2437"><span class="lineNum">    2437</span>              : // aten::new_zeros(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span id="L2438"><span class="lineNum">    2438</span>              : inline at::Tensor Tensor::new_zeros(at::IntArrayRef size, at::TensorOptions options) const {</span>
<span id="L2439"><span class="lineNum">    2439</span>              :     return at::_ops::new_zeros::call(const_cast&lt;Tensor&amp;&gt;(*this), c10::fromIntArrayRefSlow(size), c10::optTypeMetaToScalarType(options.dtype_opt()), options.layout_opt(), options.device_opt(), options.pinned_memory_opt());</span>
<span id="L2440"><span class="lineNum">    2440</span>              : }</span>
<span id="L2441"><span class="lineNum">    2441</span>              : </span>
<span id="L2442"><span class="lineNum">    2442</span>              : // aten::new_zeros(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span id="L2443"><span class="lineNum">    2443</span>              : inline at::Tensor Tensor::new_zeros(at::IntArrayRef size, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;bool&gt; pin_memory) const {</span>
<span id="L2444"><span class="lineNum">    2444</span>              :     return at::_ops::new_zeros::call(const_cast&lt;Tensor&amp;&gt;(*this), c10::fromIntArrayRefSlow(size), dtype, layout, device, pin_memory);</span>
<span id="L2445"><span class="lineNum">    2445</span>              : }</span>
<span id="L2446"><span class="lineNum">    2446</span>              : </span>
<span id="L2447"><span class="lineNum">    2447</span>              : // aten::new_zeros(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span id="L2448"><span class="lineNum">    2448</span>              : inline at::Tensor Tensor::new_zeros_symint(c10::SymIntArrayRef size, at::TensorOptions options) const {</span>
<span id="L2449"><span class="lineNum">    2449</span>              :     return at::_ops::new_zeros::call(const_cast&lt;Tensor&amp;&gt;(*this), size, c10::optTypeMetaToScalarType(options.dtype_opt()), options.layout_opt(), options.device_opt(), options.pinned_memory_opt());</span>
<span id="L2450"><span class="lineNum">    2450</span>              : }</span>
<span id="L2451"><span class="lineNum">    2451</span>              : </span>
<span id="L2452"><span class="lineNum">    2452</span>              : // aten::new_zeros(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span id="L2453"><span class="lineNum">    2453</span>              : inline at::Tensor Tensor::new_zeros_symint(c10::SymIntArrayRef size, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;bool&gt; pin_memory) const {</span>
<span id="L2454"><span class="lineNum">    2454</span>              :     return at::_ops::new_zeros::call(const_cast&lt;Tensor&amp;&gt;(*this), size, dtype, layout, device, pin_memory);</span>
<span id="L2455"><span class="lineNum">    2455</span>              : }</span>
<span id="L2456"><span class="lineNum">    2456</span>              : </span>
<span id="L2457"><span class="lineNum">    2457</span>              : // aten::new_ones(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span id="L2458"><span class="lineNum">    2458</span>              : inline at::Tensor Tensor::new_ones(at::IntArrayRef size, at::TensorOptions options) const {</span>
<span id="L2459"><span class="lineNum">    2459</span>              :     return at::_ops::new_ones::call(const_cast&lt;Tensor&amp;&gt;(*this), c10::fromIntArrayRefSlow(size), c10::optTypeMetaToScalarType(options.dtype_opt()), options.layout_opt(), options.device_opt(), options.pinned_memory_opt());</span>
<span id="L2460"><span class="lineNum">    2460</span>              : }</span>
<span id="L2461"><span class="lineNum">    2461</span>              : </span>
<span id="L2462"><span class="lineNum">    2462</span>              : // aten::new_ones(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span id="L2463"><span class="lineNum">    2463</span>              : inline at::Tensor Tensor::new_ones(at::IntArrayRef size, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;bool&gt; pin_memory) const {</span>
<span id="L2464"><span class="lineNum">    2464</span>              :     return at::_ops::new_ones::call(const_cast&lt;Tensor&amp;&gt;(*this), c10::fromIntArrayRefSlow(size), dtype, layout, device, pin_memory);</span>
<span id="L2465"><span class="lineNum">    2465</span>              : }</span>
<span id="L2466"><span class="lineNum">    2466</span>              : </span>
<span id="L2467"><span class="lineNum">    2467</span>              : // aten::new_ones(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span id="L2468"><span class="lineNum">    2468</span>              : inline at::Tensor Tensor::new_ones_symint(c10::SymIntArrayRef size, at::TensorOptions options) const {</span>
<span id="L2469"><span class="lineNum">    2469</span>              :     return at::_ops::new_ones::call(const_cast&lt;Tensor&amp;&gt;(*this), size, c10::optTypeMetaToScalarType(options.dtype_opt()), options.layout_opt(), options.device_opt(), options.pinned_memory_opt());</span>
<span id="L2470"><span class="lineNum">    2470</span>              : }</span>
<span id="L2471"><span class="lineNum">    2471</span>              : </span>
<span id="L2472"><span class="lineNum">    2472</span>              : // aten::new_ones(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span id="L2473"><span class="lineNum">    2473</span>              : inline at::Tensor Tensor::new_ones_symint(c10::SymIntArrayRef size, ::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;bool&gt; pin_memory) const {</span>
<span id="L2474"><span class="lineNum">    2474</span>              :     return at::_ops::new_ones::call(const_cast&lt;Tensor&amp;&gt;(*this), size, dtype, layout, device, pin_memory);</span>
<span id="L2475"><span class="lineNum">    2475</span>              : }</span>
<span id="L2476"><span class="lineNum">    2476</span>              : </span>
<span id="L2477"><span class="lineNum">    2477</span>              : // aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -&gt; Tensor(a!)</span>
<span id="L2478"><span class="lineNum">    2478</span>              : inline const at::Tensor &amp; Tensor::resize_(at::IntArrayRef size, ::std::optional&lt;at::MemoryFormat&gt; memory_format) const {</span>
<span id="L2479"><span class="lineNum">    2479</span>              :     return at::_ops::resize_::call(const_cast&lt;Tensor&amp;&gt;(*this), c10::fromIntArrayRefSlow(size), memory_format);</span>
<span id="L2480"><span class="lineNum">    2480</span>              : }</span>
<span id="L2481"><span class="lineNum">    2481</span>              : </span>
<span id="L2482"><span class="lineNum">    2482</span>              : // aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -&gt; Tensor(a!)</span>
<span id="L2483"><span class="lineNum">    2483</span>              : inline const at::Tensor &amp; Tensor::resize__symint(c10::SymIntArrayRef size, ::std::optional&lt;at::MemoryFormat&gt; memory_format) const {</span>
<span id="L2484"><span class="lineNum">    2484</span>              :     return at::_ops::resize_::call(const_cast&lt;Tensor&amp;&gt;(*this), size, memory_format);</span>
<span id="L2485"><span class="lineNum">    2485</span>              : }</span>
<span id="L2486"><span class="lineNum">    2486</span>              : </span>
<span id="L2487"><span class="lineNum">    2487</span>              : // aten::erf(Tensor self) -&gt; Tensor</span>
<span id="L2488"><span class="lineNum">    2488</span>              : inline at::Tensor Tensor::erf() const {</span>
<span id="L2489"><span class="lineNum">    2489</span>              :     return at::_ops::erf::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2490"><span class="lineNum">    2490</span>              : }</span>
<span id="L2491"><span class="lineNum">    2491</span>              : </span>
<span id="L2492"><span class="lineNum">    2492</span>              : // aten::erf_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L2493"><span class="lineNum">    2493</span>              : inline at::Tensor &amp; Tensor::erf_() const {</span>
<span id="L2494"><span class="lineNum">    2494</span>              :     return at::_ops::erf_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2495"><span class="lineNum">    2495</span>              : }</span>
<span id="L2496"><span class="lineNum">    2496</span>              : </span>
<span id="L2497"><span class="lineNum">    2497</span>              : // aten::erfc(Tensor self) -&gt; Tensor</span>
<span id="L2498"><span class="lineNum">    2498</span>              : inline at::Tensor Tensor::erfc() const {</span>
<span id="L2499"><span class="lineNum">    2499</span>              :     return at::_ops::erfc::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2500"><span class="lineNum">    2500</span>              : }</span>
<span id="L2501"><span class="lineNum">    2501</span>              : </span>
<span id="L2502"><span class="lineNum">    2502</span>              : // aten::erfc_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L2503"><span class="lineNum">    2503</span>              : inline at::Tensor &amp; Tensor::erfc_() const {</span>
<span id="L2504"><span class="lineNum">    2504</span>              :     return at::_ops::erfc_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2505"><span class="lineNum">    2505</span>              : }</span>
<span id="L2506"><span class="lineNum">    2506</span>              : </span>
<span id="L2507"><span class="lineNum">    2507</span>              : // aten::exp(Tensor self) -&gt; Tensor</span>
<span id="L2508"><span class="lineNum">    2508</span>              : inline at::Tensor Tensor::exp() const {</span>
<span id="L2509"><span class="lineNum">    2509</span>              :     return at::_ops::exp::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2510"><span class="lineNum">    2510</span>              : }</span>
<span id="L2511"><span class="lineNum">    2511</span>              : </span>
<span id="L2512"><span class="lineNum">    2512</span>              : // aten::exp_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L2513"><span class="lineNum">    2513</span>              : inline at::Tensor &amp; Tensor::exp_() const {</span>
<span id="L2514"><span class="lineNum">    2514</span>              :     return at::_ops::exp_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2515"><span class="lineNum">    2515</span>              : }</span>
<span id="L2516"><span class="lineNum">    2516</span>              : </span>
<span id="L2517"><span class="lineNum">    2517</span>              : // aten::exp2(Tensor self) -&gt; Tensor</span>
<span id="L2518"><span class="lineNum">    2518</span>              : inline at::Tensor Tensor::exp2() const {</span>
<span id="L2519"><span class="lineNum">    2519</span>              :     return at::_ops::exp2::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2520"><span class="lineNum">    2520</span>              : }</span>
<span id="L2521"><span class="lineNum">    2521</span>              : </span>
<span id="L2522"><span class="lineNum">    2522</span>              : // aten::exp2_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L2523"><span class="lineNum">    2523</span>              : inline at::Tensor &amp; Tensor::exp2_() const {</span>
<span id="L2524"><span class="lineNum">    2524</span>              :     return at::_ops::exp2_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2525"><span class="lineNum">    2525</span>              : }</span>
<span id="L2526"><span class="lineNum">    2526</span>              : </span>
<span id="L2527"><span class="lineNum">    2527</span>              : // aten::expm1(Tensor self) -&gt; Tensor</span>
<span id="L2528"><span class="lineNum">    2528</span>              : inline at::Tensor Tensor::expm1() const {</span>
<span id="L2529"><span class="lineNum">    2529</span>              :     return at::_ops::expm1::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2530"><span class="lineNum">    2530</span>              : }</span>
<span id="L2531"><span class="lineNum">    2531</span>              : </span>
<span id="L2532"><span class="lineNum">    2532</span>              : // aten::expm1_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L2533"><span class="lineNum">    2533</span>              : inline at::Tensor &amp; Tensor::expm1_() const {</span>
<span id="L2534"><span class="lineNum">    2534</span>              :     return at::_ops::expm1_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2535"><span class="lineNum">    2535</span>              : }</span>
<span id="L2536"><span class="lineNum">    2536</span>              : </span>
<span id="L2537"><span class="lineNum">    2537</span>              : // aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -&gt; Tensor(a)</span>
<span id="L2538"><span class="lineNum">    2538</span>              : inline at::Tensor Tensor::expand(at::IntArrayRef size, bool implicit) const {</span>
<span id="L2539"><span class="lineNum">    2539</span>              :     return at::_ops::expand::call(const_cast&lt;Tensor&amp;&gt;(*this), c10::fromIntArrayRefSlow(size), implicit);</span>
<span id="L2540"><span class="lineNum">    2540</span>              : }</span>
<span id="L2541"><span class="lineNum">    2541</span>              : </span>
<span id="L2542"><span class="lineNum">    2542</span>              : // aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -&gt; Tensor(a)</span>
<span id="L2543"><span class="lineNum">    2543</span>              : inline at::Tensor Tensor::expand_symint(c10::SymIntArrayRef size, bool implicit) const {</span>
<span id="L2544"><span class="lineNum">    2544</span>              :     return at::_ops::expand::call(const_cast&lt;Tensor&amp;&gt;(*this), size, implicit);</span>
<span id="L2545"><span class="lineNum">    2545</span>              : }</span>
<span id="L2546"><span class="lineNum">    2546</span>              : </span>
<span id="L2547"><span class="lineNum">    2547</span>              : // aten::expand_as(Tensor(a) self, Tensor other) -&gt; Tensor(a)</span>
<span id="L2548"><span class="lineNum">    2548</span>              : inline at::Tensor Tensor::expand_as(const at::Tensor &amp; other) const {</span>
<span id="L2549"><span class="lineNum">    2549</span>              :     return at::_ops::expand_as::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L2550"><span class="lineNum">    2550</span>              : }</span>
<span id="L2551"><span class="lineNum">    2551</span>              : </span>
<span id="L2552"><span class="lineNum">    2552</span>              : // aten::flatten.using_ints(Tensor(a) self, int start_dim=0, int end_dim=-1) -&gt; Tensor(a)</span>
<span id="L2553"><span class="lineNum">    2553</span>              : inline at::Tensor Tensor::flatten(int64_t start_dim, int64_t end_dim) const {</span>
<span id="L2554"><span class="lineNum">    2554</span>              :     return at::_ops::flatten_using_ints::call(const_cast&lt;Tensor&amp;&gt;(*this), start_dim, end_dim);</span>
<span id="L2555"><span class="lineNum">    2555</span>              : }</span>
<span id="L2556"><span class="lineNum">    2556</span>              : </span>
<span id="L2557"><span class="lineNum">    2557</span>              : // aten::flatten.named_out_dim(Tensor(a) self, int start_dim, int end_dim, Dimname out_dim) -&gt; Tensor(a)</span>
<span id="L2558"><span class="lineNum">    2558</span>              : inline at::Tensor Tensor::flatten(int64_t start_dim, int64_t end_dim, at::Dimname out_dim) const {</span>
<span id="L2559"><span class="lineNum">    2559</span>              :     return at::_ops::flatten_named_out_dim::call(const_cast&lt;Tensor&amp;&gt;(*this), start_dim, end_dim, out_dim);</span>
<span id="L2560"><span class="lineNum">    2560</span>              : }</span>
<span id="L2561"><span class="lineNum">    2561</span>              : </span>
<span id="L2562"><span class="lineNum">    2562</span>              : // aten::flatten.using_names(Tensor(a) self, Dimname start_dim, Dimname end_dim, Dimname out_dim) -&gt; Tensor(a)</span>
<span id="L2563"><span class="lineNum">    2563</span>              : inline at::Tensor Tensor::flatten(at::Dimname start_dim, at::Dimname end_dim, at::Dimname out_dim) const {</span>
<span id="L2564"><span class="lineNum">    2564</span>              :     return at::_ops::flatten_using_names::call(const_cast&lt;Tensor&amp;&gt;(*this), start_dim, end_dim, out_dim);</span>
<span id="L2565"><span class="lineNum">    2565</span>              : }</span>
<span id="L2566"><span class="lineNum">    2566</span>              : </span>
<span id="L2567"><span class="lineNum">    2567</span>              : // aten::flatten.DimnameList(Tensor(a) self, Dimname[] dims, Dimname out_dim) -&gt; Tensor(a)</span>
<span id="L2568"><span class="lineNum">    2568</span>              : inline at::Tensor Tensor::flatten(at::DimnameList dims, at::Dimname out_dim) const {</span>
<span id="L2569"><span class="lineNum">    2569</span>              :     return at::_ops::flatten_DimnameList::call(const_cast&lt;Tensor&amp;&gt;(*this), dims, out_dim);</span>
<span id="L2570"><span class="lineNum">    2570</span>              : }</span>
<span id="L2571"><span class="lineNum">    2571</span>              : </span>
<span id="L2572"><span class="lineNum">    2572</span>              : // aten::unflatten.int(Tensor(a) self, int dim, SymInt[] sizes) -&gt; Tensor(a)</span>
<span id="L2573"><span class="lineNum">    2573</span>              : inline at::Tensor Tensor::unflatten(int64_t dim, at::IntArrayRef sizes) const {</span>
<span id="L2574"><span class="lineNum">    2574</span>              :     return at::_ops::unflatten_int::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, c10::fromIntArrayRefSlow(sizes));</span>
<span id="L2575"><span class="lineNum">    2575</span>              : }</span>
<span id="L2576"><span class="lineNum">    2576</span>              : </span>
<span id="L2577"><span class="lineNum">    2577</span>              : // aten::unflatten.int(Tensor(a) self, int dim, SymInt[] sizes) -&gt; Tensor(a)</span>
<span id="L2578"><span class="lineNum">    2578</span>              : inline at::Tensor Tensor::unflatten_symint(int64_t dim, c10::SymIntArrayRef sizes) const {</span>
<span id="L2579"><span class="lineNum">    2579</span>              :     return at::_ops::unflatten_int::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, sizes);</span>
<span id="L2580"><span class="lineNum">    2580</span>              : }</span>
<span id="L2581"><span class="lineNum">    2581</span>              : </span>
<span id="L2582"><span class="lineNum">    2582</span>              : // aten::unflatten.Dimname(Tensor(a) self, Dimname dim, SymInt[] sizes, Dimname[] names) -&gt; Tensor(a)</span>
<span id="L2583"><span class="lineNum">    2583</span>              : inline at::Tensor Tensor::unflatten(at::Dimname dim, at::IntArrayRef sizes, at::DimnameList names) const {</span>
<span id="L2584"><span class="lineNum">    2584</span>              :     return at::_ops::unflatten_Dimname::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, c10::fromIntArrayRefSlow(sizes), names);</span>
<span id="L2585"><span class="lineNum">    2585</span>              : }</span>
<span id="L2586"><span class="lineNum">    2586</span>              : </span>
<span id="L2587"><span class="lineNum">    2587</span>              : // aten::unflatten.Dimname(Tensor(a) self, Dimname dim, SymInt[] sizes, Dimname[] names) -&gt; Tensor(a)</span>
<span id="L2588"><span class="lineNum">    2588</span>              : inline at::Tensor Tensor::unflatten_symint(at::Dimname dim, c10::SymIntArrayRef sizes, at::DimnameList names) const {</span>
<span id="L2589"><span class="lineNum">    2589</span>              :     return at::_ops::unflatten_Dimname::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, sizes, names);</span>
<span id="L2590"><span class="lineNum">    2590</span>              : }</span>
<span id="L2591"><span class="lineNum">    2591</span>              : </span>
<span id="L2592"><span class="lineNum">    2592</span>              : // aten::fill_.Scalar(Tensor(a!) self, Scalar value) -&gt; Tensor(a!)</span>
<span id="L2593"><span class="lineNum">    2593</span>              : inline at::Tensor &amp; Tensor::fill_(const at::Scalar &amp; value) const {</span>
<span id="L2594"><span class="lineNum">    2594</span>              :     return at::_ops::fill__Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), value);</span>
<span id="L2595"><span class="lineNum">    2595</span>              : }</span>
<span id="L2596"><span class="lineNum">    2596</span>              : </span>
<span id="L2597"><span class="lineNum">    2597</span>              : // aten::fill_.Tensor(Tensor(a!) self, Tensor value) -&gt; Tensor(a!)</span>
<span id="L2598"><span class="lineNum">    2598</span>              : inline at::Tensor &amp; Tensor::fill_(const at::Tensor &amp; value) const {</span>
<span id="L2599"><span class="lineNum">    2599</span>              :     return at::_ops::fill__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), value);</span>
<span id="L2600"><span class="lineNum">    2600</span>              : }</span>
<span id="L2601"><span class="lineNum">    2601</span>              : </span>
<span id="L2602"><span class="lineNum">    2602</span>              : // aten::floor(Tensor self) -&gt; Tensor</span>
<span id="L2603"><span class="lineNum">    2603</span>              : inline at::Tensor Tensor::floor() const {</span>
<span id="L2604"><span class="lineNum">    2604</span>              :     return at::_ops::floor::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2605"><span class="lineNum">    2605</span>              : }</span>
<span id="L2606"><span class="lineNum">    2606</span>              : </span>
<span id="L2607"><span class="lineNum">    2607</span>              : // aten::floor_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L2608"><span class="lineNum">    2608</span>              : inline at::Tensor &amp; Tensor::floor_() const {</span>
<span id="L2609"><span class="lineNum">    2609</span>              :     return at::_ops::floor_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2610"><span class="lineNum">    2610</span>              : }</span>
<span id="L2611"><span class="lineNum">    2611</span>              : </span>
<span id="L2612"><span class="lineNum">    2612</span>              : // aten::floor_divide(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L2613"><span class="lineNum">    2613</span>              : inline at::Tensor Tensor::floor_divide(const at::Tensor &amp; other) const {</span>
<span id="L2614"><span class="lineNum">    2614</span>              :     return at::_ops::floor_divide::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L2615"><span class="lineNum">    2615</span>              : }</span>
<span id="L2616"><span class="lineNum">    2616</span>              : </span>
<span id="L2617"><span class="lineNum">    2617</span>              : // aten::floor_divide_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L2618"><span class="lineNum">    2618</span>              : inline at::Tensor &amp; Tensor::floor_divide_(const at::Tensor &amp; other) const {</span>
<span id="L2619"><span class="lineNum">    2619</span>              :     return at::_ops::floor_divide__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L2620"><span class="lineNum">    2620</span>              : }</span>
<span id="L2621"><span class="lineNum">    2621</span>              : </span>
<span id="L2622"><span class="lineNum">    2622</span>              : // aten::floor_divide.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span id="L2623"><span class="lineNum">    2623</span>              : inline at::Tensor Tensor::floor_divide(const at::Scalar &amp; other) const {</span>
<span id="L2624"><span class="lineNum">    2624</span>              :     return at::_ops::floor_divide_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L2625"><span class="lineNum">    2625</span>              : }</span>
<span id="L2626"><span class="lineNum">    2626</span>              : </span>
<span id="L2627"><span class="lineNum">    2627</span>              : // aten::floor_divide_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span id="L2628"><span class="lineNum">    2628</span>              : inline at::Tensor &amp; Tensor::floor_divide_(const at::Scalar &amp; other) const {</span>
<span id="L2629"><span class="lineNum">    2629</span>              :     return at::_ops::floor_divide__Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L2630"><span class="lineNum">    2630</span>              : }</span>
<span id="L2631"><span class="lineNum">    2631</span>              : </span>
<span id="L2632"><span class="lineNum">    2632</span>              : // aten::frac(Tensor self) -&gt; Tensor</span>
<span id="L2633"><span class="lineNum">    2633</span>              : inline at::Tensor Tensor::frac() const {</span>
<span id="L2634"><span class="lineNum">    2634</span>              :     return at::_ops::frac::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2635"><span class="lineNum">    2635</span>              : }</span>
<span id="L2636"><span class="lineNum">    2636</span>              : </span>
<span id="L2637"><span class="lineNum">    2637</span>              : // aten::frac_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L2638"><span class="lineNum">    2638</span>              : inline at::Tensor &amp; Tensor::frac_() const {</span>
<span id="L2639"><span class="lineNum">    2639</span>              :     return at::_ops::frac_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2640"><span class="lineNum">    2640</span>              : }</span>
<span id="L2641"><span class="lineNum">    2641</span>              : </span>
<span id="L2642"><span class="lineNum">    2642</span>              : // aten::gcd(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L2643"><span class="lineNum">    2643</span>              : inline at::Tensor Tensor::gcd(const at::Tensor &amp; other) const {</span>
<span id="L2644"><span class="lineNum">    2644</span>              :     return at::_ops::gcd::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L2645"><span class="lineNum">    2645</span>              : }</span>
<span id="L2646"><span class="lineNum">    2646</span>              : </span>
<span id="L2647"><span class="lineNum">    2647</span>              : // aten::gcd_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L2648"><span class="lineNum">    2648</span>              : inline at::Tensor &amp; Tensor::gcd_(const at::Tensor &amp; other) const {</span>
<span id="L2649"><span class="lineNum">    2649</span>              :     return at::_ops::gcd_::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L2650"><span class="lineNum">    2650</span>              : }</span>
<span id="L2651"><span class="lineNum">    2651</span>              : </span>
<span id="L2652"><span class="lineNum">    2652</span>              : // aten::lcm(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L2653"><span class="lineNum">    2653</span>              : inline at::Tensor Tensor::lcm(const at::Tensor &amp; other) const {</span>
<span id="L2654"><span class="lineNum">    2654</span>              :     return at::_ops::lcm::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L2655"><span class="lineNum">    2655</span>              : }</span>
<span id="L2656"><span class="lineNum">    2656</span>              : </span>
<span id="L2657"><span class="lineNum">    2657</span>              : // aten::lcm_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L2658"><span class="lineNum">    2658</span>              : inline at::Tensor &amp; Tensor::lcm_(const at::Tensor &amp; other) const {</span>
<span id="L2659"><span class="lineNum">    2659</span>              :     return at::_ops::lcm_::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L2660"><span class="lineNum">    2660</span>              : }</span>
<span id="L2661"><span class="lineNum">    2661</span>              : </span>
<span id="L2662"><span class="lineNum">    2662</span>              : // aten::index.Tensor(Tensor self, Tensor?[] indices) -&gt; Tensor</span>
<span id="L2663"><span class="lineNum">    2663</span>              : inline at::Tensor Tensor::index(const c10::List&lt;::std::optional&lt;at::Tensor&gt;&gt; &amp; indices) const {</span>
<span id="L2664"><span class="lineNum">    2664</span>              :     return at::_ops::index_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), indices);</span>
<span id="L2665"><span class="lineNum">    2665</span>              : }</span>
<span id="L2666"><span class="lineNum">    2666</span>              : </span>
<span id="L2667"><span class="lineNum">    2667</span>              : // aten::index_copy_(Tensor(a!) self, int dim, Tensor index, Tensor source) -&gt; Tensor(a!)</span>
<span id="L2668"><span class="lineNum">    2668</span>              : inline at::Tensor &amp; Tensor::index_copy_(int64_t dim, const at::Tensor &amp; index, const at::Tensor &amp; source) const {</span>
<span id="L2669"><span class="lineNum">    2669</span>              :     return at::_ops::index_copy_::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index, source);</span>
<span id="L2670"><span class="lineNum">    2670</span>              : }</span>
<span id="L2671"><span class="lineNum">    2671</span>              : </span>
<span id="L2672"><span class="lineNum">    2672</span>              : // aten::index_copy(Tensor self, int dim, Tensor index, Tensor source) -&gt; Tensor</span>
<span id="L2673"><span class="lineNum">    2673</span>              : inline at::Tensor Tensor::index_copy(int64_t dim, const at::Tensor &amp; index, const at::Tensor &amp; source) const {</span>
<span id="L2674"><span class="lineNum">    2674</span>              :     return at::_ops::index_copy::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index, source);</span>
<span id="L2675"><span class="lineNum">    2675</span>              : }</span>
<span id="L2676"><span class="lineNum">    2676</span>              : </span>
<span id="L2677"><span class="lineNum">    2677</span>              : // aten::index_copy_.dimname(Tensor(a!) self, Dimname dim, Tensor index, Tensor source) -&gt; Tensor(a!)</span>
<span id="L2678"><span class="lineNum">    2678</span>              : inline at::Tensor &amp; Tensor::index_copy_(at::Dimname dim, const at::Tensor &amp; index, const at::Tensor &amp; source) const {</span>
<span id="L2679"><span class="lineNum">    2679</span>              :     return at::_ops::index_copy__dimname::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index, source);</span>
<span id="L2680"><span class="lineNum">    2680</span>              : }</span>
<span id="L2681"><span class="lineNum">    2681</span>              : </span>
<span id="L2682"><span class="lineNum">    2682</span>              : // aten::index_copy.dimname(Tensor self, Dimname dim, Tensor index, Tensor source) -&gt; Tensor</span>
<span id="L2683"><span class="lineNum">    2683</span>              : inline at::Tensor Tensor::index_copy(at::Dimname dim, const at::Tensor &amp; index, const at::Tensor &amp; source) const {</span>
<span id="L2684"><span class="lineNum">    2684</span>              :     return at::_ops::index_copy_dimname::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index, source);</span>
<span id="L2685"><span class="lineNum">    2685</span>              : }</span>
<span id="L2686"><span class="lineNum">    2686</span>              : </span>
<span id="L2687"><span class="lineNum">    2687</span>              : // aten::index_put_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False) -&gt; Tensor(a!)</span>
<span id="L2688"><span class="lineNum">    2688</span>              : inline at::Tensor &amp; Tensor::index_put_(const c10::List&lt;::std::optional&lt;at::Tensor&gt;&gt; &amp; indices, const at::Tensor &amp; values, bool accumulate) const {</span>
<span id="L2689"><span class="lineNum">    2689</span>              :     return at::_ops::index_put_::call(const_cast&lt;Tensor&amp;&gt;(*this), indices, values, accumulate);</span>
<span id="L2690"><span class="lineNum">    2690</span>              : }</span>
<span id="L2691"><span class="lineNum">    2691</span>              : </span>
<span id="L2692"><span class="lineNum">    2692</span>              : // aten::index_put(Tensor self, Tensor?[] indices, Tensor values, bool accumulate=False) -&gt; Tensor</span>
<span id="L2693"><span class="lineNum">    2693</span>              : inline at::Tensor Tensor::index_put(const c10::List&lt;::std::optional&lt;at::Tensor&gt;&gt; &amp; indices, const at::Tensor &amp; values, bool accumulate) const {</span>
<span id="L2694"><span class="lineNum">    2694</span>              :     return at::_ops::index_put::call(const_cast&lt;Tensor&amp;&gt;(*this), indices, values, accumulate);</span>
<span id="L2695"><span class="lineNum">    2695</span>              : }</span>
<span id="L2696"><span class="lineNum">    2696</span>              : </span>
<span id="L2697"><span class="lineNum">    2697</span>              : // aten::isclose(Tensor self, Tensor other, float rtol=1e-05, float atol=1e-08, bool equal_nan=False) -&gt; Tensor</span>
<span id="L2698"><span class="lineNum">    2698</span>              : inline at::Tensor Tensor::isclose(const at::Tensor &amp; other, double rtol, double atol, bool equal_nan) const {</span>
<span id="L2699"><span class="lineNum">    2699</span>              :     return at::_ops::isclose::call(const_cast&lt;Tensor&amp;&gt;(*this), other, rtol, atol, equal_nan);</span>
<span id="L2700"><span class="lineNum">    2700</span>              : }</span>
<span id="L2701"><span class="lineNum">    2701</span>              : </span>
<span id="L2702"><span class="lineNum">    2702</span>              : // aten::isnan(Tensor self) -&gt; Tensor</span>
<span id="L2703"><span class="lineNum">    2703</span>              : inline at::Tensor Tensor::isnan() const {</span>
<span id="L2704"><span class="lineNum">    2704</span>              :     return at::_ops::isnan::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2705"><span class="lineNum">    2705</span>              : }</span>
<span id="L2706"><span class="lineNum">    2706</span>              : </span>
<span id="L2707"><span class="lineNum">    2707</span>              : // aten::is_distributed(Tensor self) -&gt; bool</span>
<span id="L2708"><span class="lineNum">    2708</span>              : inline bool Tensor::is_distributed() const {</span>
<span id="L2709"><span class="lineNum">    2709</span>              :     return at::_ops::is_distributed::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2710"><span class="lineNum">    2710</span>              : }</span>
<span id="L2711"><span class="lineNum">    2711</span>              : </span>
<span id="L2712"><span class="lineNum">    2712</span>              : // aten::is_floating_point(Tensor self) -&gt; bool</span>
<span id="L2713"><span class="lineNum">    2713</span>              : inline bool Tensor::__dispatch_is_floating_point() const {</span>
<span id="L2714"><span class="lineNum">    2714</span>              :     return at::_ops::is_floating_point::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2715"><span class="lineNum">    2715</span>              : }</span>
<span id="L2716"><span class="lineNum">    2716</span>              : </span>
<span id="L2717"><span class="lineNum">    2717</span>              : // aten::is_complex(Tensor self) -&gt; bool</span>
<span id="L2718"><span class="lineNum">    2718</span>              : inline bool Tensor::__dispatch_is_complex() const {</span>
<span id="L2719"><span class="lineNum">    2719</span>              :     return at::_ops::is_complex::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2720"><span class="lineNum">    2720</span>              : }</span>
<span id="L2721"><span class="lineNum">    2721</span>              : </span>
<span id="L2722"><span class="lineNum">    2722</span>              : // aten::is_conj(Tensor self) -&gt; bool</span>
<span id="L2723"><span class="lineNum">    2723</span>              : inline bool Tensor::__dispatch_is_conj() const {</span>
<span id="L2724"><span class="lineNum">    2724</span>              :     return at::_ops::is_conj::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2725"><span class="lineNum">    2725</span>              : }</span>
<span id="L2726"><span class="lineNum">    2726</span>              : </span>
<span id="L2727"><span class="lineNum">    2727</span>              : // aten::_is_zerotensor(Tensor self) -&gt; bool</span>
<span id="L2728"><span class="lineNum">    2728</span>              : inline bool Tensor::__dispatch__is_zerotensor() const {</span>
<span id="L2729"><span class="lineNum">    2729</span>              :     return at::_ops::_is_zerotensor::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2730"><span class="lineNum">    2730</span>              : }</span>
<span id="L2731"><span class="lineNum">    2731</span>              : </span>
<span id="L2732"><span class="lineNum">    2732</span>              : // aten::is_neg(Tensor self) -&gt; bool</span>
<span id="L2733"><span class="lineNum">    2733</span>              : inline bool Tensor::__dispatch_is_neg() const {</span>
<span id="L2734"><span class="lineNum">    2734</span>              :     return at::_ops::is_neg::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2735"><span class="lineNum">    2735</span>              : }</span>
<span id="L2736"><span class="lineNum">    2736</span>              : </span>
<span id="L2737"><span class="lineNum">    2737</span>              : // aten::isreal(Tensor self) -&gt; Tensor</span>
<span id="L2738"><span class="lineNum">    2738</span>              : inline at::Tensor Tensor::isreal() const {</span>
<span id="L2739"><span class="lineNum">    2739</span>              :     return at::_ops::isreal::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2740"><span class="lineNum">    2740</span>              : }</span>
<span id="L2741"><span class="lineNum">    2741</span>              : </span>
<span id="L2742"><span class="lineNum">    2742</span>              : // aten::is_nonzero(Tensor self) -&gt; bool</span>
<span id="L2743"><span class="lineNum">    2743</span>              : inline bool Tensor::is_nonzero() const {</span>
<span id="L2744"><span class="lineNum">    2744</span>              :     return at::_ops::is_nonzero::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2745"><span class="lineNum">    2745</span>              : }</span>
<span id="L2746"><span class="lineNum">    2746</span>              : </span>
<span id="L2747"><span class="lineNum">    2747</span>              : // aten::is_same_size(Tensor self, Tensor other) -&gt; bool</span>
<span id="L2748"><span class="lineNum">    2748</span>              : inline bool Tensor::is_same_size(const at::Tensor &amp; other) const {</span>
<span id="L2749"><span class="lineNum">    2749</span>              :     return at::_ops::is_same_size::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L2750"><span class="lineNum">    2750</span>              : }</span>
<span id="L2751"><span class="lineNum">    2751</span>              : </span>
<span id="L2752"><span class="lineNum">    2752</span>              : // aten::is_signed(Tensor self) -&gt; bool</span>
<span id="L2753"><span class="lineNum">    2753</span>              : inline bool Tensor::__dispatch_is_signed() const {</span>
<span id="L2754"><span class="lineNum">    2754</span>              :     return at::_ops::is_signed::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2755"><span class="lineNum">    2755</span>              : }</span>
<span id="L2756"><span class="lineNum">    2756</span>              : </span>
<span id="L2757"><span class="lineNum">    2757</span>              : // aten::is_inference(Tensor self) -&gt; bool</span>
<span id="L2758"><span class="lineNum">    2758</span>              : inline bool Tensor::__dispatch_is_inference() const {</span>
<span id="L2759"><span class="lineNum">    2759</span>              :     return at::_ops::is_inference::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2760"><span class="lineNum">    2760</span>              : }</span>
<span id="L2761"><span class="lineNum">    2761</span>              : </span>
<span id="L2762"><span class="lineNum">    2762</span>              : // aten::kron(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L2763"><span class="lineNum">    2763</span>              : inline at::Tensor Tensor::kron(const at::Tensor &amp; other) const {</span>
<span id="L2764"><span class="lineNum">    2764</span>              :     return at::_ops::kron::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L2765"><span class="lineNum">    2765</span>              : }</span>
<span id="L2766"><span class="lineNum">    2766</span>              : </span>
<span id="L2767"><span class="lineNum">    2767</span>              : // aten::kthvalue(Tensor self, int k, int dim=-1, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span id="L2768"><span class="lineNum">    2768</span>              : inline ::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::kthvalue(int64_t k, int64_t dim, bool keepdim) const {</span>
<span id="L2769"><span class="lineNum">    2769</span>              :     return at::_ops::kthvalue::call(const_cast&lt;Tensor&amp;&gt;(*this), k, dim, keepdim);</span>
<span id="L2770"><span class="lineNum">    2770</span>              : }</span>
<span id="L2771"><span class="lineNum">    2771</span>              : </span>
<span id="L2772"><span class="lineNum">    2772</span>              : // aten::kthvalue.dimname(Tensor self, int k, Dimname dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span id="L2773"><span class="lineNum">    2773</span>              : inline ::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::kthvalue(int64_t k, at::Dimname dim, bool keepdim) const {</span>
<span id="L2774"><span class="lineNum">    2774</span>              :     return at::_ops::kthvalue_dimname::call(const_cast&lt;Tensor&amp;&gt;(*this), k, dim, keepdim);</span>
<span id="L2775"><span class="lineNum">    2775</span>              : }</span>
<span id="L2776"><span class="lineNum">    2776</span>              : </span>
<span id="L2777"><span class="lineNum">    2777</span>              : // aten::nan_to_num(Tensor self, float? nan=None, float? posinf=None, float? neginf=None) -&gt; Tensor</span>
<span id="L2778"><span class="lineNum">    2778</span>              : inline at::Tensor Tensor::nan_to_num(::std::optional&lt;double&gt; nan, ::std::optional&lt;double&gt; posinf, ::std::optional&lt;double&gt; neginf) const {</span>
<span id="L2779"><span class="lineNum">    2779</span>              :     return at::_ops::nan_to_num::call(const_cast&lt;Tensor&amp;&gt;(*this), nan, posinf, neginf);</span>
<span id="L2780"><span class="lineNum">    2780</span>              : }</span>
<span id="L2781"><span class="lineNum">    2781</span>              : </span>
<span id="L2782"><span class="lineNum">    2782</span>              : // aten::nan_to_num_(Tensor(a!) self, float? nan=None, float? posinf=None, float? neginf=None) -&gt; Tensor(a!)</span>
<span id="L2783"><span class="lineNum">    2783</span>              : inline at::Tensor &amp; Tensor::nan_to_num_(::std::optional&lt;double&gt; nan, ::std::optional&lt;double&gt; posinf, ::std::optional&lt;double&gt; neginf) const {</span>
<span id="L2784"><span class="lineNum">    2784</span>              :     return at::_ops::nan_to_num_::call(const_cast&lt;Tensor&amp;&gt;(*this), nan, posinf, neginf);</span>
<span id="L2785"><span class="lineNum">    2785</span>              : }</span>
<span id="L2786"><span class="lineNum">    2786</span>              : </span>
<span id="L2787"><span class="lineNum">    2787</span>              : // aten::ldexp.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L2788"><span class="lineNum">    2788</span>              : inline at::Tensor Tensor::ldexp(const at::Tensor &amp; other) const {</span>
<span id="L2789"><span class="lineNum">    2789</span>              :     return at::_ops::ldexp_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L2790"><span class="lineNum">    2790</span>              : }</span>
<span id="L2791"><span class="lineNum">    2791</span>              : </span>
<span id="L2792"><span class="lineNum">    2792</span>              : // aten::ldexp_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L2793"><span class="lineNum">    2793</span>              : inline at::Tensor &amp; Tensor::ldexp_(const at::Tensor &amp; other) const {</span>
<span id="L2794"><span class="lineNum">    2794</span>              :     return at::_ops::ldexp_::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L2795"><span class="lineNum">    2795</span>              : }</span>
<span id="L2796"><span class="lineNum">    2796</span>              : </span>
<span id="L2797"><span class="lineNum">    2797</span>              : // aten::log(Tensor self) -&gt; Tensor</span>
<span id="L2798"><span class="lineNum">    2798</span>              : inline at::Tensor Tensor::log() const {</span>
<span id="L2799"><span class="lineNum">    2799</span>              :     return at::_ops::log::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2800"><span class="lineNum">    2800</span>              : }</span>
<span id="L2801"><span class="lineNum">    2801</span>              : </span>
<span id="L2802"><span class="lineNum">    2802</span>              : // aten::log_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L2803"><span class="lineNum">    2803</span>              : inline at::Tensor &amp; Tensor::log_() const {</span>
<span id="L2804"><span class="lineNum">    2804</span>              :     return at::_ops::log_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2805"><span class="lineNum">    2805</span>              : }</span>
<span id="L2806"><span class="lineNum">    2806</span>              : </span>
<span id="L2807"><span class="lineNum">    2807</span>              : // aten::log10(Tensor self) -&gt; Tensor</span>
<span id="L2808"><span class="lineNum">    2808</span>              : inline at::Tensor Tensor::log10() const {</span>
<span id="L2809"><span class="lineNum">    2809</span>              :     return at::_ops::log10::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2810"><span class="lineNum">    2810</span>              : }</span>
<span id="L2811"><span class="lineNum">    2811</span>              : </span>
<span id="L2812"><span class="lineNum">    2812</span>              : // aten::log10_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L2813"><span class="lineNum">    2813</span>              : inline at::Tensor &amp; Tensor::log10_() const {</span>
<span id="L2814"><span class="lineNum">    2814</span>              :     return at::_ops::log10_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2815"><span class="lineNum">    2815</span>              : }</span>
<span id="L2816"><span class="lineNum">    2816</span>              : </span>
<span id="L2817"><span class="lineNum">    2817</span>              : // aten::log1p(Tensor self) -&gt; Tensor</span>
<span id="L2818"><span class="lineNum">    2818</span>              : inline at::Tensor Tensor::log1p() const {</span>
<span id="L2819"><span class="lineNum">    2819</span>              :     return at::_ops::log1p::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2820"><span class="lineNum">    2820</span>              : }</span>
<span id="L2821"><span class="lineNum">    2821</span>              : </span>
<span id="L2822"><span class="lineNum">    2822</span>              : // aten::log1p_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L2823"><span class="lineNum">    2823</span>              : inline at::Tensor &amp; Tensor::log1p_() const {</span>
<span id="L2824"><span class="lineNum">    2824</span>              :     return at::_ops::log1p_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2825"><span class="lineNum">    2825</span>              : }</span>
<span id="L2826"><span class="lineNum">    2826</span>              : </span>
<span id="L2827"><span class="lineNum">    2827</span>              : // aten::log2(Tensor self) -&gt; Tensor</span>
<span id="L2828"><span class="lineNum">    2828</span>              : inline at::Tensor Tensor::log2() const {</span>
<span id="L2829"><span class="lineNum">    2829</span>              :     return at::_ops::log2::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2830"><span class="lineNum">    2830</span>              : }</span>
<span id="L2831"><span class="lineNum">    2831</span>              : </span>
<span id="L2832"><span class="lineNum">    2832</span>              : // aten::log2_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L2833"><span class="lineNum">    2833</span>              : inline at::Tensor &amp; Tensor::log2_() const {</span>
<span id="L2834"><span class="lineNum">    2834</span>              :     return at::_ops::log2_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2835"><span class="lineNum">    2835</span>              : }</span>
<span id="L2836"><span class="lineNum">    2836</span>              : </span>
<span id="L2837"><span class="lineNum">    2837</span>              : // aten::logaddexp(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L2838"><span class="lineNum">    2838</span>              : inline at::Tensor Tensor::logaddexp(const at::Tensor &amp; other) const {</span>
<span id="L2839"><span class="lineNum">    2839</span>              :     return at::_ops::logaddexp::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L2840"><span class="lineNum">    2840</span>              : }</span>
<span id="L2841"><span class="lineNum">    2841</span>              : </span>
<span id="L2842"><span class="lineNum">    2842</span>              : // aten::logaddexp2(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L2843"><span class="lineNum">    2843</span>              : inline at::Tensor Tensor::logaddexp2(const at::Tensor &amp; other) const {</span>
<span id="L2844"><span class="lineNum">    2844</span>              :     return at::_ops::logaddexp2::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L2845"><span class="lineNum">    2845</span>              : }</span>
<span id="L2846"><span class="lineNum">    2846</span>              : </span>
<span id="L2847"><span class="lineNum">    2847</span>              : // aten::xlogy.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L2848"><span class="lineNum">    2848</span>              : inline at::Tensor Tensor::xlogy(const at::Tensor &amp; other) const {</span>
<span id="L2849"><span class="lineNum">    2849</span>              :     return at::_ops::xlogy_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L2850"><span class="lineNum">    2850</span>              : }</span>
<span id="L2851"><span class="lineNum">    2851</span>              : </span>
<span id="L2852"><span class="lineNum">    2852</span>              : // aten::xlogy.Scalar_Other(Tensor self, Scalar other) -&gt; Tensor</span>
<span id="L2853"><span class="lineNum">    2853</span>              : inline at::Tensor Tensor::xlogy(const at::Scalar &amp; other) const {</span>
<span id="L2854"><span class="lineNum">    2854</span>              :     return at::_ops::xlogy_Scalar_Other::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L2855"><span class="lineNum">    2855</span>              : }</span>
<span id="L2856"><span class="lineNum">    2856</span>              : </span>
<span id="L2857"><span class="lineNum">    2857</span>              : // aten::xlogy_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L2858"><span class="lineNum">    2858</span>              : inline at::Tensor &amp; Tensor::xlogy_(const at::Tensor &amp; other) const {</span>
<span id="L2859"><span class="lineNum">    2859</span>              :     return at::_ops::xlogy__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L2860"><span class="lineNum">    2860</span>              : }</span>
<span id="L2861"><span class="lineNum">    2861</span>              : </span>
<span id="L2862"><span class="lineNum">    2862</span>              : // aten::xlogy_.Scalar_Other(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span id="L2863"><span class="lineNum">    2863</span>              : inline at::Tensor &amp; Tensor::xlogy_(const at::Scalar &amp; other) const {</span>
<span id="L2864"><span class="lineNum">    2864</span>              :     return at::_ops::xlogy__Scalar_Other::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L2865"><span class="lineNum">    2865</span>              : }</span>
<span id="L2866"><span class="lineNum">    2866</span>              : </span>
<span id="L2867"><span class="lineNum">    2867</span>              : // aten::log_softmax.int(Tensor self, int dim, ScalarType? dtype=None) -&gt; Tensor</span>
<span id="L2868"><span class="lineNum">    2868</span>              : inline at::Tensor Tensor::log_softmax(int64_t dim, ::std::optional&lt;at::ScalarType&gt; dtype) const {</span>
<span id="L2869"><span class="lineNum">    2869</span>              :     return at::_ops::log_softmax_int::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, dtype);</span>
<span id="L2870"><span class="lineNum">    2870</span>              : }</span>
<span id="L2871"><span class="lineNum">    2871</span>              : </span>
<span id="L2872"><span class="lineNum">    2872</span>              : // aten::log_softmax.Dimname(Tensor self, Dimname dim, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span id="L2873"><span class="lineNum">    2873</span>              : inline at::Tensor Tensor::log_softmax(at::Dimname dim, ::std::optional&lt;at::ScalarType&gt; dtype) const {</span>
<span id="L2874"><span class="lineNum">    2874</span>              :     return at::_ops::log_softmax_Dimname::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, dtype);</span>
<span id="L2875"><span class="lineNum">    2875</span>              : }</span>
<span id="L2876"><span class="lineNum">    2876</span>              : </span>
<span id="L2877"><span class="lineNum">    2877</span>              : // aten::logcumsumexp(Tensor self, int dim) -&gt; Tensor</span>
<span id="L2878"><span class="lineNum">    2878</span>              : inline at::Tensor Tensor::logcumsumexp(int64_t dim) const {</span>
<span id="L2879"><span class="lineNum">    2879</span>              :     return at::_ops::logcumsumexp::call(const_cast&lt;Tensor&amp;&gt;(*this), dim);</span>
<span id="L2880"><span class="lineNum">    2880</span>              : }</span>
<span id="L2881"><span class="lineNum">    2881</span>              : </span>
<span id="L2882"><span class="lineNum">    2882</span>              : // aten::logcumsumexp.dimname(Tensor self, Dimname dim) -&gt; Tensor</span>
<span id="L2883"><span class="lineNum">    2883</span>              : inline at::Tensor Tensor::logcumsumexp(at::Dimname dim) const {</span>
<span id="L2884"><span class="lineNum">    2884</span>              :     return at::_ops::logcumsumexp_dimname::call(const_cast&lt;Tensor&amp;&gt;(*this), dim);</span>
<span id="L2885"><span class="lineNum">    2885</span>              : }</span>
<span id="L2886"><span class="lineNum">    2886</span>              : </span>
<span id="L2887"><span class="lineNum">    2887</span>              : // aten::logsumexp(Tensor self, int[1] dim, bool keepdim=False) -&gt; Tensor</span>
<span id="L2888"><span class="lineNum">    2888</span>              : inline at::Tensor Tensor::logsumexp(at::IntArrayRef dim, bool keepdim) const {</span>
<span id="L2889"><span class="lineNum">    2889</span>              :     return at::_ops::logsumexp::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, keepdim);</span>
<span id="L2890"><span class="lineNum">    2890</span>              : }</span>
<span id="L2891"><span class="lineNum">    2891</span>              : </span>
<span id="L2892"><span class="lineNum">    2892</span>              : // aten::logsumexp.names(Tensor self, Dimname[1] dim, bool keepdim=False) -&gt; Tensor</span>
<span id="L2893"><span class="lineNum">    2893</span>              : inline at::Tensor Tensor::logsumexp(at::DimnameList dim, bool keepdim) const {</span>
<span id="L2894"><span class="lineNum">    2894</span>              :     return at::_ops::logsumexp_names::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, keepdim);</span>
<span id="L2895"><span class="lineNum">    2895</span>              : }</span>
<span id="L2896"><span class="lineNum">    2896</span>              : </span>
<span id="L2897"><span class="lineNum">    2897</span>              : // aten::matmul(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L2898"><span class="lineNum">    2898</span>              : inline at::Tensor Tensor::matmul(const at::Tensor &amp; other) const {</span>
<span id="L2899"><span class="lineNum">    2899</span>              :     return at::_ops::matmul::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L2900"><span class="lineNum">    2900</span>              : }</span>
<span id="L2901"><span class="lineNum">    2901</span>              : </span>
<span id="L2902"><span class="lineNum">    2902</span>              : // aten::matrix_power(Tensor self, int n) -&gt; Tensor</span>
<span id="L2903"><span class="lineNum">    2903</span>              : inline at::Tensor Tensor::matrix_power(int64_t n) const {</span>
<span id="L2904"><span class="lineNum">    2904</span>              :     return at::_ops::matrix_power::call(const_cast&lt;Tensor&amp;&gt;(*this), n);</span>
<span id="L2905"><span class="lineNum">    2905</span>              : }</span>
<span id="L2906"><span class="lineNum">    2906</span>              : </span>
<span id="L2907"><span class="lineNum">    2907</span>              : // aten::matrix_exp(Tensor self) -&gt; Tensor</span>
<span id="L2908"><span class="lineNum">    2908</span>              : inline at::Tensor Tensor::matrix_exp() const {</span>
<span id="L2909"><span class="lineNum">    2909</span>              :     return at::_ops::matrix_exp::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2910"><span class="lineNum">    2910</span>              : }</span>
<span id="L2911"><span class="lineNum">    2911</span>              : </span>
<span id="L2912"><span class="lineNum">    2912</span>              : // aten::aminmax(Tensor self, *, int? dim=None, bool keepdim=False) -&gt; (Tensor min, Tensor max)</span>
<span id="L2913"><span class="lineNum">    2913</span>              : inline ::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::aminmax(::std::optional&lt;int64_t&gt; dim, bool keepdim) const {</span>
<span id="L2914"><span class="lineNum">    2914</span>              :     return at::_ops::aminmax::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, keepdim);</span>
<span id="L2915"><span class="lineNum">    2915</span>              : }</span>
<span id="L2916"><span class="lineNum">    2916</span>              : </span>
<span id="L2917"><span class="lineNum">    2917</span>              : // aten::max.dim(Tensor self, int dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span id="L2918"><span class="lineNum">    2918</span>              : inline ::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::max(int64_t dim, bool keepdim) const {</span>
<span id="L2919"><span class="lineNum">    2919</span>              :     return at::_ops::max_dim::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, keepdim);</span>
<span id="L2920"><span class="lineNum">    2920</span>              : }</span>
<span id="L2921"><span class="lineNum">    2921</span>              : </span>
<span id="L2922"><span class="lineNum">    2922</span>              : // aten::max.names_dim(Tensor self, Dimname dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span id="L2923"><span class="lineNum">    2923</span>              : inline ::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::max(at::Dimname dim, bool keepdim) const {</span>
<span id="L2924"><span class="lineNum">    2924</span>              :     return at::_ops::max_names_dim::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, keepdim);</span>
<span id="L2925"><span class="lineNum">    2925</span>              : }</span>
<span id="L2926"><span class="lineNum">    2926</span>              : </span>
<span id="L2927"><span class="lineNum">    2927</span>              : // aten::amax(Tensor self, int[1] dim=[], bool keepdim=False) -&gt; Tensor</span>
<span id="L2928"><span class="lineNum">    2928</span>              : inline at::Tensor Tensor::amax(at::IntArrayRef dim, bool keepdim) const {</span>
<span id="L2929"><span class="lineNum">    2929</span>              :     return at::_ops::amax::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, keepdim);</span>
<span id="L2930"><span class="lineNum">    2930</span>              : }</span>
<span id="L2931"><span class="lineNum">    2931</span>              : </span>
<span id="L2932"><span class="lineNum">    2932</span>              : // aten::mean(Tensor self, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span id="L2933"><span class="lineNum">    2933</span>              : inline at::Tensor Tensor::mean(::std::optional&lt;at::ScalarType&gt; dtype) const {</span>
<span id="L2934"><span class="lineNum">    2934</span>              :     return at::_ops::mean::call(const_cast&lt;Tensor&amp;&gt;(*this), dtype);</span>
<span id="L2935"><span class="lineNum">    2935</span>              : }</span>
<span id="L2936"><span class="lineNum">    2936</span>              : </span>
<span id="L2937"><span class="lineNum">    2937</span>              : // aten::mean.dim(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span id="L2938"><span class="lineNum">    2938</span>              : inline at::Tensor Tensor::mean(at::OptionalIntArrayRef dim, bool keepdim, ::std::optional&lt;at::ScalarType&gt; dtype) const {</span>
<span id="L2939"><span class="lineNum">    2939</span>              :     return at::_ops::mean_dim::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, keepdim, dtype);</span>
<span id="L2940"><span class="lineNum">    2940</span>              : }</span>
<span id="L2941"><span class="lineNum">    2941</span>              : </span>
<span id="L2942"><span class="lineNum">    2942</span>              : // aten::mean.names_dim(Tensor self, Dimname[1] dim, bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span id="L2943"><span class="lineNum">    2943</span>              : inline at::Tensor Tensor::mean(at::DimnameList dim, bool keepdim, ::std::optional&lt;at::ScalarType&gt; dtype) const {</span>
<span id="L2944"><span class="lineNum">    2944</span>              :     return at::_ops::mean_names_dim::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, keepdim, dtype);</span>
<span id="L2945"><span class="lineNum">    2945</span>              : }</span>
<span id="L2946"><span class="lineNum">    2946</span>              : </span>
<span id="L2947"><span class="lineNum">    2947</span>              : // aten::nanmean(Tensor self, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span id="L2948"><span class="lineNum">    2948</span>              : inline at::Tensor Tensor::nanmean(at::OptionalIntArrayRef dim, bool keepdim, ::std::optional&lt;at::ScalarType&gt; dtype) const {</span>
<span id="L2949"><span class="lineNum">    2949</span>              :     return at::_ops::nanmean::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, keepdim, dtype);</span>
<span id="L2950"><span class="lineNum">    2950</span>              : }</span>
<span id="L2951"><span class="lineNum">    2951</span>              : </span>
<span id="L2952"><span class="lineNum">    2952</span>              : // aten::median(Tensor self) -&gt; Tensor</span>
<span id="L2953"><span class="lineNum">    2953</span>              : inline at::Tensor Tensor::median() const {</span>
<span id="L2954"><span class="lineNum">    2954</span>              :     return at::_ops::median::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2955"><span class="lineNum">    2955</span>              : }</span>
<span id="L2956"><span class="lineNum">    2956</span>              : </span>
<span id="L2957"><span class="lineNum">    2957</span>              : // aten::median.dim(Tensor self, int dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span id="L2958"><span class="lineNum">    2958</span>              : inline ::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::median(int64_t dim, bool keepdim) const {</span>
<span id="L2959"><span class="lineNum">    2959</span>              :     return at::_ops::median_dim::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, keepdim);</span>
<span id="L2960"><span class="lineNum">    2960</span>              : }</span>
<span id="L2961"><span class="lineNum">    2961</span>              : </span>
<span id="L2962"><span class="lineNum">    2962</span>              : // aten::median.names_dim(Tensor self, Dimname dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span id="L2963"><span class="lineNum">    2963</span>              : inline ::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::median(at::Dimname dim, bool keepdim) const {</span>
<span id="L2964"><span class="lineNum">    2964</span>              :     return at::_ops::median_names_dim::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, keepdim);</span>
<span id="L2965"><span class="lineNum">    2965</span>              : }</span>
<span id="L2966"><span class="lineNum">    2966</span>              : </span>
<span id="L2967"><span class="lineNum">    2967</span>              : // aten::nanmedian(Tensor self) -&gt; Tensor</span>
<span id="L2968"><span class="lineNum">    2968</span>              : inline at::Tensor Tensor::nanmedian() const {</span>
<span id="L2969"><span class="lineNum">    2969</span>              :     return at::_ops::nanmedian::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L2970"><span class="lineNum">    2970</span>              : }</span>
<span id="L2971"><span class="lineNum">    2971</span>              : </span>
<span id="L2972"><span class="lineNum">    2972</span>              : // aten::nanmedian.dim(Tensor self, int dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span id="L2973"><span class="lineNum">    2973</span>              : inline ::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::nanmedian(int64_t dim, bool keepdim) const {</span>
<span id="L2974"><span class="lineNum">    2974</span>              :     return at::_ops::nanmedian_dim::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, keepdim);</span>
<span id="L2975"><span class="lineNum">    2975</span>              : }</span>
<span id="L2976"><span class="lineNum">    2976</span>              : </span>
<span id="L2977"><span class="lineNum">    2977</span>              : // aten::nanmedian.names_dim(Tensor self, Dimname dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span id="L2978"><span class="lineNum">    2978</span>              : inline ::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::nanmedian(at::Dimname dim, bool keepdim) const {</span>
<span id="L2979"><span class="lineNum">    2979</span>              :     return at::_ops::nanmedian_names_dim::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, keepdim);</span>
<span id="L2980"><span class="lineNum">    2980</span>              : }</span>
<span id="L2981"><span class="lineNum">    2981</span>              : </span>
<span id="L2982"><span class="lineNum">    2982</span>              : // aten::min.dim(Tensor self, int dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span id="L2983"><span class="lineNum">    2983</span>              : inline ::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::min(int64_t dim, bool keepdim) const {</span>
<span id="L2984"><span class="lineNum">    2984</span>              :     return at::_ops::min_dim::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, keepdim);</span>
<span id="L2985"><span class="lineNum">    2985</span>              : }</span>
<span id="L2986"><span class="lineNum">    2986</span>              : </span>
<span id="L2987"><span class="lineNum">    2987</span>              : // aten::min.names_dim(Tensor self, Dimname dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span id="L2988"><span class="lineNum">    2988</span>              : inline ::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::min(at::Dimname dim, bool keepdim) const {</span>
<span id="L2989"><span class="lineNum">    2989</span>              :     return at::_ops::min_names_dim::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, keepdim);</span>
<span id="L2990"><span class="lineNum">    2990</span>              : }</span>
<span id="L2991"><span class="lineNum">    2991</span>              : </span>
<span id="L2992"><span class="lineNum">    2992</span>              : // aten::amin(Tensor self, int[1] dim=[], bool keepdim=False) -&gt; Tensor</span>
<span id="L2993"><span class="lineNum">    2993</span>              : inline at::Tensor Tensor::amin(at::IntArrayRef dim, bool keepdim) const {</span>
<span id="L2994"><span class="lineNum">    2994</span>              :     return at::_ops::amin::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, keepdim);</span>
<span id="L2995"><span class="lineNum">    2995</span>              : }</span>
<span id="L2996"><span class="lineNum">    2996</span>              : </span>
<span id="L2997"><span class="lineNum">    2997</span>              : // aten::mm(Tensor self, Tensor mat2) -&gt; Tensor</span>
<span id="L2998"><span class="lineNum">    2998</span>              : inline at::Tensor Tensor::mm(const at::Tensor &amp; mat2) const {</span>
<span id="L2999"><span class="lineNum">    2999</span>              :     return at::_ops::mm::call(const_cast&lt;Tensor&amp;&gt;(*this), mat2);</span>
<span id="L3000"><span class="lineNum">    3000</span>              : }</span>
<span id="L3001"><span class="lineNum">    3001</span>              : </span>
<span id="L3002"><span class="lineNum">    3002</span>              : // aten::mode(Tensor self, int dim=-1, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span id="L3003"><span class="lineNum">    3003</span>              : inline ::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::mode(int64_t dim, bool keepdim) const {</span>
<span id="L3004"><span class="lineNum">    3004</span>              :     return at::_ops::mode::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, keepdim);</span>
<span id="L3005"><span class="lineNum">    3005</span>              : }</span>
<span id="L3006"><span class="lineNum">    3006</span>              : </span>
<span id="L3007"><span class="lineNum">    3007</span>              : // aten::mode.dimname(Tensor self, Dimname dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span id="L3008"><span class="lineNum">    3008</span>              : inline ::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::mode(at::Dimname dim, bool keepdim) const {</span>
<span id="L3009"><span class="lineNum">    3009</span>              :     return at::_ops::mode_dimname::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, keepdim);</span>
<span id="L3010"><span class="lineNum">    3010</span>              : }</span>
<span id="L3011"><span class="lineNum">    3011</span>              : </span>
<span id="L3012"><span class="lineNum">    3012</span>              : // aten::mul.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L3013"><span class="lineNum">    3013</span>              : inline at::Tensor Tensor::mul(const at::Tensor &amp; other) const {</span>
<span id="L3014"><span class="lineNum">    3014</span>              :     return at::_ops::mul_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L3015"><span class="lineNum">    3015</span>              : }</span>
<span id="L3016"><span class="lineNum">    3016</span>              : </span>
<span id="L3017"><span class="lineNum">    3017</span>              : // aten::mul_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L3018"><span class="lineNum">    3018</span>              : inline at::Tensor &amp; Tensor::mul_(const at::Tensor &amp; other) const {</span>
<span id="L3019"><span class="lineNum">    3019</span>              :     return at::_ops::mul__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L3020"><span class="lineNum">    3020</span>              : }</span>
<span id="L3021"><span class="lineNum">    3021</span>              : </span>
<span id="L3022"><span class="lineNum">    3022</span>              : // aten::mul.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span id="L3023"><span class="lineNum">    3023</span>              : inline at::Tensor Tensor::mul(const at::Scalar &amp; other) const {</span>
<span id="L3024"><span class="lineNum">    3024</span>              :     return at::_ops::mul_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L3025"><span class="lineNum">    3025</span>              : }</span>
<span id="L3026"><span class="lineNum">    3026</span>              : </span>
<span id="L3027"><span class="lineNum">    3027</span>              : // aten::mul_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span id="L3028"><span class="lineNum">    3028</span>              : inline at::Tensor &amp; Tensor::mul_(const at::Scalar &amp; other) const {</span>
<span id="L3029"><span class="lineNum">    3029</span>              :     return at::_ops::mul__Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L3030"><span class="lineNum">    3030</span>              : }</span>
<span id="L3031"><span class="lineNum">    3031</span>              : </span>
<span id="L3032"><span class="lineNum">    3032</span>              : // aten::multiply.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L3033"><span class="lineNum">    3033</span>              : inline at::Tensor Tensor::multiply(const at::Tensor &amp; other) const {</span>
<span id="L3034"><span class="lineNum">    3034</span>              :     return at::_ops::multiply_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L3035"><span class="lineNum">    3035</span>              : }</span>
<span id="L3036"><span class="lineNum">    3036</span>              : </span>
<span id="L3037"><span class="lineNum">    3037</span>              : // aten::multiply_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L3038"><span class="lineNum">    3038</span>              : inline at::Tensor &amp; Tensor::multiply_(const at::Tensor &amp; other) const {</span>
<span id="L3039"><span class="lineNum">    3039</span>              :     return at::_ops::multiply__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L3040"><span class="lineNum">    3040</span>              : }</span>
<span id="L3041"><span class="lineNum">    3041</span>              : </span>
<span id="L3042"><span class="lineNum">    3042</span>              : // aten::multiply.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span id="L3043"><span class="lineNum">    3043</span>              : inline at::Tensor Tensor::multiply(const at::Scalar &amp; other) const {</span>
<span id="L3044"><span class="lineNum">    3044</span>              :     return at::_ops::multiply_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L3045"><span class="lineNum">    3045</span>              : }</span>
<span id="L3046"><span class="lineNum">    3046</span>              : </span>
<span id="L3047"><span class="lineNum">    3047</span>              : // aten::multiply_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span id="L3048"><span class="lineNum">    3048</span>              : inline at::Tensor &amp; Tensor::multiply_(const at::Scalar &amp; other) const {</span>
<span id="L3049"><span class="lineNum">    3049</span>              :     return at::_ops::multiply__Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L3050"><span class="lineNum">    3050</span>              : }</span>
<span id="L3051"><span class="lineNum">    3051</span>              : </span>
<span id="L3052"><span class="lineNum">    3052</span>              : // aten::mv(Tensor self, Tensor vec) -&gt; Tensor</span>
<span id="L3053"><span class="lineNum">    3053</span>              : inline at::Tensor Tensor::mv(const at::Tensor &amp; vec) const {</span>
<span id="L3054"><span class="lineNum">    3054</span>              :     return at::_ops::mv::call(const_cast&lt;Tensor&amp;&gt;(*this), vec);</span>
<span id="L3055"><span class="lineNum">    3055</span>              : }</span>
<span id="L3056"><span class="lineNum">    3056</span>              : </span>
<span id="L3057"><span class="lineNum">    3057</span>              : // aten::mvlgamma(Tensor self, int p) -&gt; Tensor</span>
<span id="L3058"><span class="lineNum">    3058</span>              : inline at::Tensor Tensor::mvlgamma(int64_t p) const {</span>
<span id="L3059"><span class="lineNum">    3059</span>              :     return at::_ops::mvlgamma::call(const_cast&lt;Tensor&amp;&gt;(*this), p);</span>
<span id="L3060"><span class="lineNum">    3060</span>              : }</span>
<span id="L3061"><span class="lineNum">    3061</span>              : </span>
<span id="L3062"><span class="lineNum">    3062</span>              : // aten::mvlgamma_(Tensor(a!) self, int p) -&gt; Tensor(a!)</span>
<span id="L3063"><span class="lineNum">    3063</span>              : inline at::Tensor &amp; Tensor::mvlgamma_(int64_t p) const {</span>
<span id="L3064"><span class="lineNum">    3064</span>              :     return at::_ops::mvlgamma_::call(const_cast&lt;Tensor&amp;&gt;(*this), p);</span>
<span id="L3065"><span class="lineNum">    3065</span>              : }</span>
<span id="L3066"><span class="lineNum">    3066</span>              : </span>
<span id="L3067"><span class="lineNum">    3067</span>              : // aten::narrow_copy(Tensor self, int dim, SymInt start, SymInt length) -&gt; Tensor</span>
<span id="L3068"><span class="lineNum">    3068</span>              : inline at::Tensor Tensor::narrow_copy(int64_t dim, int64_t start, int64_t length) const {</span>
<span id="L3069"><span class="lineNum">    3069</span>              :     return at::_ops::narrow_copy::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, start, length);</span>
<span id="L3070"><span class="lineNum">    3070</span>              : }</span>
<span id="L3071"><span class="lineNum">    3071</span>              : </span>
<span id="L3072"><span class="lineNum">    3072</span>              : // aten::narrow_copy(Tensor self, int dim, SymInt start, SymInt length) -&gt; Tensor</span>
<span id="L3073"><span class="lineNum">    3073</span>              : inline at::Tensor Tensor::narrow_copy_symint(int64_t dim, c10::SymInt start, c10::SymInt length) const {</span>
<span id="L3074"><span class="lineNum">    3074</span>              :     return at::_ops::narrow_copy::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, start, length);</span>
<span id="L3075"><span class="lineNum">    3075</span>              : }</span>
<span id="L3076"><span class="lineNum">    3076</span>              : </span>
<span id="L3077"><span class="lineNum">    3077</span>              : // aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -&gt; Tensor(a)</span>
<span id="L3078"><span class="lineNum">    3078</span>              : inline at::Tensor Tensor::narrow(int64_t dim, int64_t start, int64_t length) const {</span>
<span id="L3079"><span class="lineNum">    3079</span>              :     return at::_ops::narrow::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, start, length);</span>
<span id="L3080"><span class="lineNum">    3080</span>              : }</span>
<span id="L3081"><span class="lineNum">    3081</span>              : </span>
<span id="L3082"><span class="lineNum">    3082</span>              : // aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -&gt; Tensor(a)</span>
<span id="L3083"><span class="lineNum">    3083</span>              : inline at::Tensor Tensor::narrow_symint(int64_t dim, c10::SymInt start, c10::SymInt length) const {</span>
<span id="L3084"><span class="lineNum">    3084</span>              :     return at::_ops::narrow::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, start, length);</span>
<span id="L3085"><span class="lineNum">    3085</span>              : }</span>
<span id="L3086"><span class="lineNum">    3086</span>              : </span>
<span id="L3087"><span class="lineNum">    3087</span>              : // aten::narrow.Tensor(Tensor(a) self, int dim, Tensor start, SymInt length) -&gt; Tensor(a)</span>
<span id="L3088"><span class="lineNum">    3088</span>              : inline at::Tensor Tensor::narrow(int64_t dim, const at::Tensor &amp; start, int64_t length) const {</span>
<span id="L3089"><span class="lineNum">    3089</span>              :     return at::_ops::narrow_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, start, length);</span>
<span id="L3090"><span class="lineNum">    3090</span>              : }</span>
<span id="L3091"><span class="lineNum">    3091</span>              : </span>
<span id="L3092"><span class="lineNum">    3092</span>              : // aten::narrow.Tensor(Tensor(a) self, int dim, Tensor start, SymInt length) -&gt; Tensor(a)</span>
<span id="L3093"><span class="lineNum">    3093</span>              : inline at::Tensor Tensor::narrow_symint(int64_t dim, const at::Tensor &amp; start, c10::SymInt length) const {</span>
<span id="L3094"><span class="lineNum">    3094</span>              :     return at::_ops::narrow_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, start, length);</span>
<span id="L3095"><span class="lineNum">    3095</span>              : }</span>
<span id="L3096"><span class="lineNum">    3096</span>              : </span>
<span id="L3097"><span class="lineNum">    3097</span>              : // aten::permute(Tensor(a) self, int[] dims) -&gt; Tensor(a)</span>
<span id="L3098"><span class="lineNum">    3098</span>              : inline at::Tensor Tensor::permute(at::IntArrayRef dims) const {</span>
<span id="L3099"><span class="lineNum">    3099</span>              :     return at::_ops::permute::call(const_cast&lt;Tensor&amp;&gt;(*this), dims);</span>
<span id="L3100"><span class="lineNum">    3100</span>              : }</span>
<span id="L3101"><span class="lineNum">    3101</span>              : </span>
<span id="L3102"><span class="lineNum">    3102</span>              : // aten::movedim.intlist(Tensor(a) self, int[] source, int[] destination) -&gt; Tensor(a)</span>
<span id="L3103"><span class="lineNum">    3103</span>              : inline at::Tensor Tensor::movedim(at::IntArrayRef source, at::IntArrayRef destination) const {</span>
<span id="L3104"><span class="lineNum">    3104</span>              :     return at::_ops::movedim_intlist::call(const_cast&lt;Tensor&amp;&gt;(*this), source, destination);</span>
<span id="L3105"><span class="lineNum">    3105</span>              : }</span>
<span id="L3106"><span class="lineNum">    3106</span>              : </span>
<span id="L3107"><span class="lineNum">    3107</span>              : // aten::movedim.int(Tensor(a) self, int source, int destination) -&gt; Tensor(a)</span>
<span id="L3108"><span class="lineNum">    3108</span>              : inline at::Tensor Tensor::movedim(int64_t source, int64_t destination) const {</span>
<span id="L3109"><span class="lineNum">    3109</span>              :     return at::_ops::movedim_int::call(const_cast&lt;Tensor&amp;&gt;(*this), source, destination);</span>
<span id="L3110"><span class="lineNum">    3110</span>              : }</span>
<span id="L3111"><span class="lineNum">    3111</span>              : </span>
<span id="L3112"><span class="lineNum">    3112</span>              : // aten::moveaxis.intlist(Tensor(a) self, int[] source, int[] destination) -&gt; Tensor(a)</span>
<span id="L3113"><span class="lineNum">    3113</span>              : inline at::Tensor Tensor::moveaxis(at::IntArrayRef source, at::IntArrayRef destination) const {</span>
<span id="L3114"><span class="lineNum">    3114</span>              :     return at::_ops::moveaxis_intlist::call(const_cast&lt;Tensor&amp;&gt;(*this), source, destination);</span>
<span id="L3115"><span class="lineNum">    3115</span>              : }</span>
<span id="L3116"><span class="lineNum">    3116</span>              : </span>
<span id="L3117"><span class="lineNum">    3117</span>              : // aten::moveaxis.int(Tensor(a) self, int source, int destination) -&gt; Tensor(a)</span>
<span id="L3118"><span class="lineNum">    3118</span>              : inline at::Tensor Tensor::moveaxis(int64_t source, int64_t destination) const {</span>
<span id="L3119"><span class="lineNum">    3119</span>              :     return at::_ops::moveaxis_int::call(const_cast&lt;Tensor&amp;&gt;(*this), source, destination);</span>
<span id="L3120"><span class="lineNum">    3120</span>              : }</span>
<span id="L3121"><span class="lineNum">    3121</span>              : </span>
<span id="L3122"><span class="lineNum">    3122</span>              : // aten::numpy_T(Tensor(a) self) -&gt; Tensor(a)</span>
<span id="L3123"><span class="lineNum">    3123</span>              : inline at::Tensor Tensor::numpy_T() const {</span>
<span id="L3124"><span class="lineNum">    3124</span>              :     return at::_ops::numpy_T::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3125"><span class="lineNum">    3125</span>              : }</span>
<span id="L3126"><span class="lineNum">    3126</span>              : </span>
<span id="L3127"><span class="lineNum">    3127</span>              : // aten::matrix_H(Tensor(a) self) -&gt; Tensor(a)</span>
<span id="L3128"><span class="lineNum">    3128</span>              : inline at::Tensor Tensor::matrix_H() const {</span>
<span id="L3129"><span class="lineNum">    3129</span>              :     return at::_ops::matrix_H::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3130"><span class="lineNum">    3130</span>              : }</span>
<span id="L3131"><span class="lineNum">    3131</span>              : </span>
<span id="L3132"><span class="lineNum">    3132</span>              : // aten::mT(Tensor(a) self) -&gt; Tensor(a)</span>
<span id="L3133"><span class="lineNum">    3133</span>              : inline at::Tensor Tensor::mT() const {</span>
<span id="L3134"><span class="lineNum">    3134</span>              :     return at::_ops::mT::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3135"><span class="lineNum">    3135</span>              : }</span>
<span id="L3136"><span class="lineNum">    3136</span>              : </span>
<span id="L3137"><span class="lineNum">    3137</span>              : // aten::mH(Tensor(a) self) -&gt; Tensor(a)</span>
<span id="L3138"><span class="lineNum">    3138</span>              : inline at::Tensor Tensor::mH() const {</span>
<span id="L3139"><span class="lineNum">    3139</span>              :     return at::_ops::mH::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3140"><span class="lineNum">    3140</span>              : }</span>
<span id="L3141"><span class="lineNum">    3141</span>              : </span>
<span id="L3142"><span class="lineNum">    3142</span>              : // aten::adjoint(Tensor(a) self) -&gt; Tensor(a)</span>
<span id="L3143"><span class="lineNum">    3143</span>              : inline at::Tensor Tensor::adjoint() const {</span>
<span id="L3144"><span class="lineNum">    3144</span>              :     return at::_ops::adjoint::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3145"><span class="lineNum">    3145</span>              : }</span>
<span id="L3146"><span class="lineNum">    3146</span>              : </span>
<span id="L3147"><span class="lineNum">    3147</span>              : // aten::is_pinned(Tensor self, Device? device=None) -&gt; bool</span>
<span id="L3148"><span class="lineNum">    3148</span>              : inline bool Tensor::is_pinned(::std::optional&lt;at::Device&gt; device) const {</span>
<span id="L3149"><span class="lineNum">    3149</span>              :     return at::_ops::is_pinned::call(const_cast&lt;Tensor&amp;&gt;(*this), device);</span>
<span id="L3150"><span class="lineNum">    3150</span>              : }</span>
<span id="L3151"><span class="lineNum">    3151</span>              : </span>
<span id="L3152"><span class="lineNum">    3152</span>              : // aten::pin_memory(Tensor(a) self, Device? device=None) -&gt; Tensor(a)</span>
<span id="L3153"><span class="lineNum">    3153</span>              : inline at::Tensor Tensor::pin_memory(::std::optional&lt;at::Device&gt; device) const {</span>
<span id="L3154"><span class="lineNum">    3154</span>              :     return at::_ops::pin_memory::call(const_cast&lt;Tensor&amp;&gt;(*this), device);</span>
<span id="L3155"><span class="lineNum">    3155</span>              : }</span>
<span id="L3156"><span class="lineNum">    3156</span>              : </span>
<span id="L3157"><span class="lineNum">    3157</span>              : // aten::pinverse(Tensor self, float rcond=1e-15) -&gt; Tensor</span>
<span id="L3158"><span class="lineNum">    3158</span>              : inline at::Tensor Tensor::pinverse(double rcond) const {</span>
<span id="L3159"><span class="lineNum">    3159</span>              :     return at::_ops::pinverse::call(const_cast&lt;Tensor&amp;&gt;(*this), rcond);</span>
<span id="L3160"><span class="lineNum">    3160</span>              : }</span>
<span id="L3161"><span class="lineNum">    3161</span>              : </span>
<span id="L3162"><span class="lineNum">    3162</span>              : // aten::rad2deg(Tensor self) -&gt; Tensor</span>
<span id="L3163"><span class="lineNum">    3163</span>              : inline at::Tensor Tensor::rad2deg() const {</span>
<span id="L3164"><span class="lineNum">    3164</span>              :     return at::_ops::rad2deg::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3165"><span class="lineNum">    3165</span>              : }</span>
<span id="L3166"><span class="lineNum">    3166</span>              : </span>
<span id="L3167"><span class="lineNum">    3167</span>              : // aten::rad2deg_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L3168"><span class="lineNum">    3168</span>              : inline at::Tensor &amp; Tensor::rad2deg_() const {</span>
<span id="L3169"><span class="lineNum">    3169</span>              :     return at::_ops::rad2deg_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3170"><span class="lineNum">    3170</span>              : }</span>
<span id="L3171"><span class="lineNum">    3171</span>              : </span>
<span id="L3172"><span class="lineNum">    3172</span>              : // aten::deg2rad(Tensor self) -&gt; Tensor</span>
<span id="L3173"><span class="lineNum">    3173</span>              : inline at::Tensor Tensor::deg2rad() const {</span>
<span id="L3174"><span class="lineNum">    3174</span>              :     return at::_ops::deg2rad::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3175"><span class="lineNum">    3175</span>              : }</span>
<span id="L3176"><span class="lineNum">    3176</span>              : </span>
<span id="L3177"><span class="lineNum">    3177</span>              : // aten::deg2rad_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L3178"><span class="lineNum">    3178</span>              : inline at::Tensor &amp; Tensor::deg2rad_() const {</span>
<span id="L3179"><span class="lineNum">    3179</span>              :     return at::_ops::deg2rad_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3180"><span class="lineNum">    3180</span>              : }</span>
<span id="L3181"><span class="lineNum">    3181</span>              : </span>
<span id="L3182"><span class="lineNum">    3182</span>              : // aten::ravel(Tensor(a) self) -&gt; Tensor(a)</span>
<span id="L3183"><span class="lineNum">    3183</span>              : inline at::Tensor Tensor::ravel() const {</span>
<span id="L3184"><span class="lineNum">    3184</span>              :     return at::_ops::ravel::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3185"><span class="lineNum">    3185</span>              : }</span>
<span id="L3186"><span class="lineNum">    3186</span>              : </span>
<span id="L3187"><span class="lineNum">    3187</span>              : // aten::reciprocal(Tensor self) -&gt; Tensor</span>
<span id="L3188"><span class="lineNum">    3188</span>              : inline at::Tensor Tensor::reciprocal() const {</span>
<span id="L3189"><span class="lineNum">    3189</span>              :     return at::_ops::reciprocal::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3190"><span class="lineNum">    3190</span>              : }</span>
<span id="L3191"><span class="lineNum">    3191</span>              : </span>
<span id="L3192"><span class="lineNum">    3192</span>              : // aten::reciprocal_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L3193"><span class="lineNum">    3193</span>              : inline at::Tensor &amp; Tensor::reciprocal_() const {</span>
<span id="L3194"><span class="lineNum">    3194</span>              :     return at::_ops::reciprocal_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3195"><span class="lineNum">    3195</span>              : }</span>
<span id="L3196"><span class="lineNum">    3196</span>              : </span>
<span id="L3197"><span class="lineNum">    3197</span>              : // aten::neg(Tensor self) -&gt; Tensor</span>
<span id="L3198"><span class="lineNum">    3198</span>              : inline at::Tensor Tensor::neg() const {</span>
<span id="L3199"><span class="lineNum">    3199</span>              :     return at::_ops::neg::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3200"><span class="lineNum">    3200</span>              : }</span>
<span id="L3201"><span class="lineNum">    3201</span>              : </span>
<span id="L3202"><span class="lineNum">    3202</span>              : // aten::neg_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L3203"><span class="lineNum">    3203</span>              : inline at::Tensor &amp; Tensor::neg_() const {</span>
<span id="L3204"><span class="lineNum">    3204</span>              :     return at::_ops::neg_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3205"><span class="lineNum">    3205</span>              : }</span>
<span id="L3206"><span class="lineNum">    3206</span>              : </span>
<span id="L3207"><span class="lineNum">    3207</span>              : // aten::negative(Tensor self) -&gt; Tensor</span>
<span id="L3208"><span class="lineNum">    3208</span>              : inline at::Tensor Tensor::negative() const {</span>
<span id="L3209"><span class="lineNum">    3209</span>              :     return at::_ops::negative::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3210"><span class="lineNum">    3210</span>              : }</span>
<span id="L3211"><span class="lineNum">    3211</span>              : </span>
<span id="L3212"><span class="lineNum">    3212</span>              : // aten::negative_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L3213"><span class="lineNum">    3213</span>              : inline at::Tensor &amp; Tensor::negative_() const {</span>
<span id="L3214"><span class="lineNum">    3214</span>              :     return at::_ops::negative_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3215"><span class="lineNum">    3215</span>              : }</span>
<span id="L3216"><span class="lineNum">    3216</span>              : </span>
<span id="L3217"><span class="lineNum">    3217</span>              : // aten::repeat(Tensor self, SymInt[] repeats) -&gt; Tensor</span>
<span id="L3218"><span class="lineNum">    3218</span>              : inline at::Tensor Tensor::repeat(at::IntArrayRef repeats) const {</span>
<span id="L3219"><span class="lineNum">    3219</span>              :     return at::_ops::repeat::call(const_cast&lt;Tensor&amp;&gt;(*this), c10::fromIntArrayRefSlow(repeats));</span>
<span id="L3220"><span class="lineNum">    3220</span>              : }</span>
<span id="L3221"><span class="lineNum">    3221</span>              : </span>
<span id="L3222"><span class="lineNum">    3222</span>              : // aten::repeat(Tensor self, SymInt[] repeats) -&gt; Tensor</span>
<span id="L3223"><span class="lineNum">    3223</span>              : inline at::Tensor Tensor::repeat_symint(c10::SymIntArrayRef repeats) const {</span>
<span id="L3224"><span class="lineNum">    3224</span>              :     return at::_ops::repeat::call(const_cast&lt;Tensor&amp;&gt;(*this), repeats);</span>
<span id="L3225"><span class="lineNum">    3225</span>              : }</span>
<span id="L3226"><span class="lineNum">    3226</span>              : </span>
<span id="L3227"><span class="lineNum">    3227</span>              : // aten::repeat_interleave.self_Tensor(Tensor self, Tensor repeats, int? dim=None, *, SymInt? output_size=None) -&gt; Tensor</span>
<span id="L3228"><span class="lineNum">    3228</span>              : inline at::Tensor Tensor::repeat_interleave(const at::Tensor &amp; repeats, ::std::optional&lt;int64_t&gt; dim, ::std::optional&lt;int64_t&gt; output_size) const {</span>
<span id="L3229"><span class="lineNum">    3229</span>              :     return at::_ops::repeat_interleave_self_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), repeats, dim, output_size.has_value() ? ::std::make_optional(c10::SymInt(*output_size)) : ::std::nullopt);</span>
<span id="L3230"><span class="lineNum">    3230</span>              : }</span>
<span id="L3231"><span class="lineNum">    3231</span>              : </span>
<span id="L3232"><span class="lineNum">    3232</span>              : // aten::repeat_interleave.self_Tensor(Tensor self, Tensor repeats, int? dim=None, *, SymInt? output_size=None) -&gt; Tensor</span>
<span id="L3233"><span class="lineNum">    3233</span>              : inline at::Tensor Tensor::repeat_interleave_symint(const at::Tensor &amp; repeats, ::std::optional&lt;int64_t&gt; dim, ::std::optional&lt;c10::SymInt&gt; output_size) const {</span>
<span id="L3234"><span class="lineNum">    3234</span>              :     return at::_ops::repeat_interleave_self_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), repeats, dim, output_size);</span>
<span id="L3235"><span class="lineNum">    3235</span>              : }</span>
<span id="L3236"><span class="lineNum">    3236</span>              : </span>
<span id="L3237"><span class="lineNum">    3237</span>              : // aten::repeat_interleave.self_int(Tensor self, SymInt repeats, int? dim=None, *, SymInt? output_size=None) -&gt; Tensor</span>
<span id="L3238"><span class="lineNum">    3238</span>              : inline at::Tensor Tensor::repeat_interleave(int64_t repeats, ::std::optional&lt;int64_t&gt; dim, ::std::optional&lt;int64_t&gt; output_size) const {</span>
<span id="L3239"><span class="lineNum">    3239</span>              :     return at::_ops::repeat_interleave_self_int::call(const_cast&lt;Tensor&amp;&gt;(*this), repeats, dim, output_size.has_value() ? ::std::make_optional(c10::SymInt(*output_size)) : ::std::nullopt);</span>
<span id="L3240"><span class="lineNum">    3240</span>              : }</span>
<span id="L3241"><span class="lineNum">    3241</span>              : </span>
<span id="L3242"><span class="lineNum">    3242</span>              : // aten::repeat_interleave.self_int(Tensor self, SymInt repeats, int? dim=None, *, SymInt? output_size=None) -&gt; Tensor</span>
<span id="L3243"><span class="lineNum">    3243</span>              : inline at::Tensor Tensor::repeat_interleave_symint(c10::SymInt repeats, ::std::optional&lt;int64_t&gt; dim, ::std::optional&lt;c10::SymInt&gt; output_size) const {</span>
<span id="L3244"><span class="lineNum">    3244</span>              :     return at::_ops::repeat_interleave_self_int::call(const_cast&lt;Tensor&amp;&gt;(*this), repeats, dim, output_size);</span>
<span id="L3245"><span class="lineNum">    3245</span>              : }</span>
<span id="L3246"><span class="lineNum">    3246</span>              : </span>
<span id="L3247"><span class="lineNum">    3247</span>              : // aten::reshape(Tensor(a) self, SymInt[] shape) -&gt; Tensor(a)</span>
<span id="L3248"><span class="lineNum">    3248</span>              : inline at::Tensor Tensor::reshape(at::IntArrayRef shape) const {</span>
<span id="L3249"><span class="lineNum">    3249</span>              :     return at::_ops::reshape::call(const_cast&lt;Tensor&amp;&gt;(*this), c10::fromIntArrayRefSlow(shape));</span>
<span id="L3250"><span class="lineNum">    3250</span>              : }</span>
<span id="L3251"><span class="lineNum">    3251</span>              : </span>
<span id="L3252"><span class="lineNum">    3252</span>              : // aten::reshape(Tensor(a) self, SymInt[] shape) -&gt; Tensor(a)</span>
<span id="L3253"><span class="lineNum">    3253</span>              : inline at::Tensor Tensor::reshape_symint(c10::SymIntArrayRef shape) const {</span>
<span id="L3254"><span class="lineNum">    3254</span>              :     return at::_ops::reshape::call(const_cast&lt;Tensor&amp;&gt;(*this), shape);</span>
<span id="L3255"><span class="lineNum">    3255</span>              : }</span>
<span id="L3256"><span class="lineNum">    3256</span>              : </span>
<span id="L3257"><span class="lineNum">    3257</span>              : // aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -&gt; Tensor(a)</span>
<span id="L3258"><span class="lineNum">    3258</span>              : inline at::Tensor Tensor::_reshape_alias(at::IntArrayRef size, at::IntArrayRef stride) const {</span>
<span id="L3259"><span class="lineNum">    3259</span>              :     return at::_ops::_reshape_alias::call(const_cast&lt;Tensor&amp;&gt;(*this), c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride));</span>
<span id="L3260"><span class="lineNum">    3260</span>              : }</span>
<span id="L3261"><span class="lineNum">    3261</span>              : </span>
<span id="L3262"><span class="lineNum">    3262</span>              : // aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -&gt; Tensor(a)</span>
<span id="L3263"><span class="lineNum">    3263</span>              : inline at::Tensor Tensor::_reshape_alias_symint(c10::SymIntArrayRef size, c10::SymIntArrayRef stride) const {</span>
<span id="L3264"><span class="lineNum">    3264</span>              :     return at::_ops::_reshape_alias::call(const_cast&lt;Tensor&amp;&gt;(*this), size, stride);</span>
<span id="L3265"><span class="lineNum">    3265</span>              : }</span>
<span id="L3266"><span class="lineNum">    3266</span>              : </span>
<span id="L3267"><span class="lineNum">    3267</span>              : // aten::reshape_as(Tensor(a) self, Tensor other) -&gt; Tensor(a)</span>
<span id="L3268"><span class="lineNum">    3268</span>              : inline at::Tensor Tensor::reshape_as(const at::Tensor &amp; other) const {</span>
<span id="L3269"><span class="lineNum">    3269</span>              :     return at::_ops::reshape_as::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L3270"><span class="lineNum">    3270</span>              : }</span>
<span id="L3271"><span class="lineNum">    3271</span>              : </span>
<span id="L3272"><span class="lineNum">    3272</span>              : // aten::round(Tensor self) -&gt; Tensor</span>
<span id="L3273"><span class="lineNum">    3273</span>              : inline at::Tensor Tensor::round() const {</span>
<span id="L3274"><span class="lineNum">    3274</span>              :     return at::_ops::round::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3275"><span class="lineNum">    3275</span>              : }</span>
<span id="L3276"><span class="lineNum">    3276</span>              : </span>
<span id="L3277"><span class="lineNum">    3277</span>              : // aten::round_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L3278"><span class="lineNum">    3278</span>              : inline at::Tensor &amp; Tensor::round_() const {</span>
<span id="L3279"><span class="lineNum">    3279</span>              :     return at::_ops::round_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3280"><span class="lineNum">    3280</span>              : }</span>
<span id="L3281"><span class="lineNum">    3281</span>              : </span>
<span id="L3282"><span class="lineNum">    3282</span>              : // aten::round.decimals(Tensor self, *, int decimals) -&gt; Tensor</span>
<span id="L3283"><span class="lineNum">    3283</span>              : inline at::Tensor Tensor::round(int64_t decimals) const {</span>
<span id="L3284"><span class="lineNum">    3284</span>              :     return at::_ops::round_decimals::call(const_cast&lt;Tensor&amp;&gt;(*this), decimals);</span>
<span id="L3285"><span class="lineNum">    3285</span>              : }</span>
<span id="L3286"><span class="lineNum">    3286</span>              : </span>
<span id="L3287"><span class="lineNum">    3287</span>              : // aten::round_.decimals(Tensor(a!) self, *, int decimals) -&gt; Tensor(a!)</span>
<span id="L3288"><span class="lineNum">    3288</span>              : inline at::Tensor &amp; Tensor::round_(int64_t decimals) const {</span>
<span id="L3289"><span class="lineNum">    3289</span>              :     return at::_ops::round__decimals::call(const_cast&lt;Tensor&amp;&gt;(*this), decimals);</span>
<span id="L3290"><span class="lineNum">    3290</span>              : }</span>
<span id="L3291"><span class="lineNum">    3291</span>              : </span>
<span id="L3292"><span class="lineNum">    3292</span>              : // aten::relu(Tensor self) -&gt; Tensor</span>
<span id="L3293"><span class="lineNum">    3293</span>              : inline at::Tensor Tensor::relu() const {</span>
<span id="L3294"><span class="lineNum">    3294</span>              :     return at::_ops::relu::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3295"><span class="lineNum">    3295</span>              : }</span>
<span id="L3296"><span class="lineNum">    3296</span>              : </span>
<span id="L3297"><span class="lineNum">    3297</span>              : // aten::relu_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L3298"><span class="lineNum">    3298</span>              : inline at::Tensor &amp; Tensor::relu_() const {</span>
<span id="L3299"><span class="lineNum">    3299</span>              :     return at::_ops::relu_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3300"><span class="lineNum">    3300</span>              : }</span>
<span id="L3301"><span class="lineNum">    3301</span>              : </span>
<span id="L3302"><span class="lineNum">    3302</span>              : // aten::prelu(Tensor self, Tensor weight) -&gt; Tensor</span>
<span id="L3303"><span class="lineNum">    3303</span>              : inline at::Tensor Tensor::prelu(const at::Tensor &amp; weight) const {</span>
<span id="L3304"><span class="lineNum">    3304</span>              :     return at::_ops::prelu::call(const_cast&lt;Tensor&amp;&gt;(*this), weight);</span>
<span id="L3305"><span class="lineNum">    3305</span>              : }</span>
<span id="L3306"><span class="lineNum">    3306</span>              : </span>
<span id="L3307"><span class="lineNum">    3307</span>              : // aten::hardshrink(Tensor self, Scalar lambd=0.5) -&gt; Tensor</span>
<span id="L3308"><span class="lineNum">    3308</span>              : inline at::Tensor Tensor::hardshrink(const at::Scalar &amp; lambd) const {</span>
<span id="L3309"><span class="lineNum">    3309</span>              :     return at::_ops::hardshrink::call(const_cast&lt;Tensor&amp;&gt;(*this), lambd);</span>
<span id="L3310"><span class="lineNum">    3310</span>              : }</span>
<span id="L3311"><span class="lineNum">    3311</span>              : </span>
<span id="L3312"><span class="lineNum">    3312</span>              : // aten::hardshrink_backward(Tensor grad_out, Tensor self, Scalar lambd) -&gt; Tensor</span>
<span id="L3313"><span class="lineNum">    3313</span>              : inline at::Tensor Tensor::hardshrink_backward(const at::Tensor &amp; grad_out, const at::Scalar &amp; lambd) const {</span>
<span id="L3314"><span class="lineNum">    3314</span>              :     return at::_ops::hardshrink_backward::call(grad_out, const_cast&lt;Tensor&amp;&gt;(*this), lambd);</span>
<span id="L3315"><span class="lineNum">    3315</span>              : }</span>
<span id="L3316"><span class="lineNum">    3316</span>              : </span>
<span id="L3317"><span class="lineNum">    3317</span>              : // aten::rsqrt(Tensor self) -&gt; Tensor</span>
<span id="L3318"><span class="lineNum">    3318</span>              : inline at::Tensor Tensor::rsqrt() const {</span>
<span id="L3319"><span class="lineNum">    3319</span>              :     return at::_ops::rsqrt::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3320"><span class="lineNum">    3320</span>              : }</span>
<span id="L3321"><span class="lineNum">    3321</span>              : </span>
<span id="L3322"><span class="lineNum">    3322</span>              : // aten::rsqrt_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L3323"><span class="lineNum">    3323</span>              : inline at::Tensor &amp; Tensor::rsqrt_() const {</span>
<span id="L3324"><span class="lineNum">    3324</span>              :     return at::_ops::rsqrt_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3325"><span class="lineNum">    3325</span>              : }</span>
<span id="L3326"><span class="lineNum">    3326</span>              : </span>
<span id="L3327"><span class="lineNum">    3327</span>              : // aten::select.Dimname(Tensor(a) self, Dimname dim, int index) -&gt; Tensor(a)</span>
<span id="L3328"><span class="lineNum">    3328</span>              : inline at::Tensor Tensor::select(at::Dimname dim, int64_t index) const {</span>
<span id="L3329"><span class="lineNum">    3329</span>              :     return at::_ops::select_Dimname::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index);</span>
<span id="L3330"><span class="lineNum">    3330</span>              : }</span>
<span id="L3331"><span class="lineNum">    3331</span>              : </span>
<span id="L3332"><span class="lineNum">    3332</span>              : // aten::select.int(Tensor(a) self, int dim, SymInt index) -&gt; Tensor(a)</span>
<span id="L3333"><span class="lineNum">    3333</span>              : inline at::Tensor Tensor::select(int64_t dim, int64_t index) const {</span>
<span id="L3334"><span class="lineNum">    3334</span>              :     return at::_ops::select_int::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index);</span>
<span id="L3335"><span class="lineNum">    3335</span>              : }</span>
<span id="L3336"><span class="lineNum">    3336</span>              : </span>
<span id="L3337"><span class="lineNum">    3337</span>              : // aten::select.int(Tensor(a) self, int dim, SymInt index) -&gt; Tensor(a)</span>
<span id="L3338"><span class="lineNum">    3338</span>              : inline at::Tensor Tensor::select_symint(int64_t dim, c10::SymInt index) const {</span>
<span id="L3339"><span class="lineNum">    3339</span>              :     return at::_ops::select_int::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index);</span>
<span id="L3340"><span class="lineNum">    3340</span>              : }</span>
<span id="L3341"><span class="lineNum">    3341</span>              : </span>
<span id="L3342"><span class="lineNum">    3342</span>              : // aten::sigmoid(Tensor self) -&gt; Tensor</span>
<span id="L3343"><span class="lineNum">    3343</span>              : inline at::Tensor Tensor::sigmoid() const {</span>
<span id="L3344"><span class="lineNum">    3344</span>              :     return at::_ops::sigmoid::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3345"><span class="lineNum">    3345</span>              : }</span>
<span id="L3346"><span class="lineNum">    3346</span>              : </span>
<span id="L3347"><span class="lineNum">    3347</span>              : // aten::sigmoid_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L3348"><span class="lineNum">    3348</span>              : inline at::Tensor &amp; Tensor::sigmoid_() const {</span>
<span id="L3349"><span class="lineNum">    3349</span>              :     return at::_ops::sigmoid_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3350"><span class="lineNum">    3350</span>              : }</span>
<span id="L3351"><span class="lineNum">    3351</span>              : </span>
<span id="L3352"><span class="lineNum">    3352</span>              : // aten::logit(Tensor self, float? eps=None) -&gt; Tensor</span>
<span id="L3353"><span class="lineNum">    3353</span>              : inline at::Tensor Tensor::logit(::std::optional&lt;double&gt; eps) const {</span>
<span id="L3354"><span class="lineNum">    3354</span>              :     return at::_ops::logit::call(const_cast&lt;Tensor&amp;&gt;(*this), eps);</span>
<span id="L3355"><span class="lineNum">    3355</span>              : }</span>
<span id="L3356"><span class="lineNum">    3356</span>              : </span>
<span id="L3357"><span class="lineNum">    3357</span>              : // aten::logit_(Tensor(a!) self, float? eps=None) -&gt; Tensor(a!)</span>
<span id="L3358"><span class="lineNum">    3358</span>              : inline at::Tensor &amp; Tensor::logit_(::std::optional&lt;double&gt; eps) const {</span>
<span id="L3359"><span class="lineNum">    3359</span>              :     return at::_ops::logit_::call(const_cast&lt;Tensor&amp;&gt;(*this), eps);</span>
<span id="L3360"><span class="lineNum">    3360</span>              : }</span>
<span id="L3361"><span class="lineNum">    3361</span>              : </span>
<span id="L3362"><span class="lineNum">    3362</span>              : // aten::sin(Tensor self) -&gt; Tensor</span>
<span id="L3363"><span class="lineNum">    3363</span>              : inline at::Tensor Tensor::sin() const {</span>
<span id="L3364"><span class="lineNum">    3364</span>              :     return at::_ops::sin::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3365"><span class="lineNum">    3365</span>              : }</span>
<span id="L3366"><span class="lineNum">    3366</span>              : </span>
<span id="L3367"><span class="lineNum">    3367</span>              : // aten::sin_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L3368"><span class="lineNum">    3368</span>              : inline at::Tensor &amp; Tensor::sin_() const {</span>
<span id="L3369"><span class="lineNum">    3369</span>              :     return at::_ops::sin_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3370"><span class="lineNum">    3370</span>              : }</span>
<span id="L3371"><span class="lineNum">    3371</span>              : </span>
<span id="L3372"><span class="lineNum">    3372</span>              : // aten::sinc(Tensor self) -&gt; Tensor</span>
<span id="L3373"><span class="lineNum">    3373</span>              : inline at::Tensor Tensor::sinc() const {</span>
<span id="L3374"><span class="lineNum">    3374</span>              :     return at::_ops::sinc::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3375"><span class="lineNum">    3375</span>              : }</span>
<span id="L3376"><span class="lineNum">    3376</span>              : </span>
<span id="L3377"><span class="lineNum">    3377</span>              : // aten::sinc_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L3378"><span class="lineNum">    3378</span>              : inline at::Tensor &amp; Tensor::sinc_() const {</span>
<span id="L3379"><span class="lineNum">    3379</span>              :     return at::_ops::sinc_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3380"><span class="lineNum">    3380</span>              : }</span>
<span id="L3381"><span class="lineNum">    3381</span>              : </span>
<span id="L3382"><span class="lineNum">    3382</span>              : // aten::sinh(Tensor self) -&gt; Tensor</span>
<span id="L3383"><span class="lineNum">    3383</span>              : inline at::Tensor Tensor::sinh() const {</span>
<span id="L3384"><span class="lineNum">    3384</span>              :     return at::_ops::sinh::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3385"><span class="lineNum">    3385</span>              : }</span>
<span id="L3386"><span class="lineNum">    3386</span>              : </span>
<span id="L3387"><span class="lineNum">    3387</span>              : // aten::sinh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L3388"><span class="lineNum">    3388</span>              : inline at::Tensor &amp; Tensor::sinh_() const {</span>
<span id="L3389"><span class="lineNum">    3389</span>              :     return at::_ops::sinh_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3390"><span class="lineNum">    3390</span>              : }</span>
<span id="L3391"><span class="lineNum">    3391</span>              : </span>
<span id="L3392"><span class="lineNum">    3392</span>              : // aten::detach(Tensor(a) self) -&gt; Tensor(a)</span>
<span id="L3393"><span class="lineNum">    3393</span>              : inline at::Tensor Tensor::detach() const {</span>
<span id="L3394"><span class="lineNum">    3394</span>              :     return at::_ops::detach::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3395"><span class="lineNum">    3395</span>              : }</span>
<span id="L3396"><span class="lineNum">    3396</span>              : </span>
<span id="L3397"><span class="lineNum">    3397</span>              : // aten::detach_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L3398"><span class="lineNum">    3398</span>              : inline at::Tensor &amp; Tensor::detach_() const {</span>
<span id="L3399"><span class="lineNum">    3399</span>              :     return at::_ops::detach_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3400"><span class="lineNum">    3400</span>              : }</span>
<span id="L3401"><span class="lineNum">    3401</span>              : </span>
<span id="L3402"><span class="lineNum">    3402</span>              : // aten::size.Dimname(Tensor self, Dimname dim) -&gt; int</span>
<span id="L3403"><span class="lineNum">    3403</span>              : inline int64_t Tensor::size(at::Dimname dim) const {</span>
<span id="L3404"><span class="lineNum">    3404</span>              :     return at::_ops::size_Dimname::call(const_cast&lt;Tensor&amp;&gt;(*this), dim);</span>
<span id="L3405"><span class="lineNum">    3405</span>              : }</span>
<span id="L3406"><span class="lineNum">    3406</span>              : </span>
<span id="L3407"><span class="lineNum">    3407</span>              : // aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -&gt; Tensor(a)</span>
<span id="L3408"><span class="lineNum">    3408</span>              : inline at::Tensor Tensor::slice(int64_t dim, ::std::optional&lt;int64_t&gt; start, ::std::optional&lt;int64_t&gt; end, int64_t step) const {</span>
<span id="L3409"><span class="lineNum">    3409</span>              :     return at::_ops::slice_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, start.has_value() ? ::std::make_optional(c10::SymInt(*start)) : ::std::nullopt, end.has_value() ? ::std::make_optional(c10::SymInt(*end)) : ::std::nullopt, step);</span>
<span id="L3410"><span class="lineNum">    3410</span>              : }</span>
<span id="L3411"><span class="lineNum">    3411</span>              : </span>
<span id="L3412"><span class="lineNum">    3412</span>              : // aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -&gt; Tensor(a)</span>
<span id="L3413"><span class="lineNum">    3413</span>              : inline at::Tensor Tensor::slice_symint(int64_t dim, ::std::optional&lt;c10::SymInt&gt; start, ::std::optional&lt;c10::SymInt&gt; end, c10::SymInt step) const {</span>
<span id="L3414"><span class="lineNum">    3414</span>              :     return at::_ops::slice_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, start, end, step);</span>
<span id="L3415"><span class="lineNum">    3415</span>              : }</span>
<span id="L3416"><span class="lineNum">    3416</span>              : </span>
<span id="L3417"><span class="lineNum">    3417</span>              : // aten::slice_inverse(Tensor(a) self, Tensor src, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -&gt; Tensor(a)</span>
<span id="L3418"><span class="lineNum">    3418</span>              : inline at::Tensor Tensor::slice_inverse(const at::Tensor &amp; src, int64_t dim, ::std::optional&lt;int64_t&gt; start, ::std::optional&lt;int64_t&gt; end, int64_t step) const {</span>
<span id="L3419"><span class="lineNum">    3419</span>              :     return at::_ops::slice_inverse::call(const_cast&lt;Tensor&amp;&gt;(*this), src, dim, start.has_value() ? ::std::make_optional(c10::SymInt(*start)) : ::std::nullopt, end.has_value() ? ::std::make_optional(c10::SymInt(*end)) : ::std::nullopt, step);</span>
<span id="L3420"><span class="lineNum">    3420</span>              : }</span>
<span id="L3421"><span class="lineNum">    3421</span>              : </span>
<span id="L3422"><span class="lineNum">    3422</span>              : // aten::slice_inverse(Tensor(a) self, Tensor src, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -&gt; Tensor(a)</span>
<span id="L3423"><span class="lineNum">    3423</span>              : inline at::Tensor Tensor::slice_inverse_symint(const at::Tensor &amp; src, int64_t dim, ::std::optional&lt;c10::SymInt&gt; start, ::std::optional&lt;c10::SymInt&gt; end, c10::SymInt step) const {</span>
<span id="L3424"><span class="lineNum">    3424</span>              :     return at::_ops::slice_inverse::call(const_cast&lt;Tensor&amp;&gt;(*this), src, dim, start, end, step);</span>
<span id="L3425"><span class="lineNum">    3425</span>              : }</span>
<span id="L3426"><span class="lineNum">    3426</span>              : </span>
<span id="L3427"><span class="lineNum">    3427</span>              : // aten::slice_scatter(Tensor self, Tensor src, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -&gt; Tensor</span>
<span id="L3428"><span class="lineNum">    3428</span>              : inline at::Tensor Tensor::slice_scatter(const at::Tensor &amp; src, int64_t dim, ::std::optional&lt;int64_t&gt; start, ::std::optional&lt;int64_t&gt; end, int64_t step) const {</span>
<span id="L3429"><span class="lineNum">    3429</span>              :     return at::_ops::slice_scatter::call(const_cast&lt;Tensor&amp;&gt;(*this), src, dim, start.has_value() ? ::std::make_optional(c10::SymInt(*start)) : ::std::nullopt, end.has_value() ? ::std::make_optional(c10::SymInt(*end)) : ::std::nullopt, step);</span>
<span id="L3430"><span class="lineNum">    3430</span>              : }</span>
<span id="L3431"><span class="lineNum">    3431</span>              : </span>
<span id="L3432"><span class="lineNum">    3432</span>              : // aten::slice_scatter(Tensor self, Tensor src, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -&gt; Tensor</span>
<span id="L3433"><span class="lineNum">    3433</span>              : inline at::Tensor Tensor::slice_scatter_symint(const at::Tensor &amp; src, int64_t dim, ::std::optional&lt;c10::SymInt&gt; start, ::std::optional&lt;c10::SymInt&gt; end, c10::SymInt step) const {</span>
<span id="L3434"><span class="lineNum">    3434</span>              :     return at::_ops::slice_scatter::call(const_cast&lt;Tensor&amp;&gt;(*this), src, dim, start, end, step);</span>
<span id="L3435"><span class="lineNum">    3435</span>              : }</span>
<span id="L3436"><span class="lineNum">    3436</span>              : </span>
<span id="L3437"><span class="lineNum">    3437</span>              : // aten::select_scatter(Tensor self, Tensor src, int dim, SymInt index) -&gt; Tensor</span>
<span id="L3438"><span class="lineNum">    3438</span>              : inline at::Tensor Tensor::select_scatter(const at::Tensor &amp; src, int64_t dim, int64_t index) const {</span>
<span id="L3439"><span class="lineNum">    3439</span>              :     return at::_ops::select_scatter::call(const_cast&lt;Tensor&amp;&gt;(*this), src, dim, index);</span>
<span id="L3440"><span class="lineNum">    3440</span>              : }</span>
<span id="L3441"><span class="lineNum">    3441</span>              : </span>
<span id="L3442"><span class="lineNum">    3442</span>              : // aten::select_scatter(Tensor self, Tensor src, int dim, SymInt index) -&gt; Tensor</span>
<span id="L3443"><span class="lineNum">    3443</span>              : inline at::Tensor Tensor::select_scatter_symint(const at::Tensor &amp; src, int64_t dim, c10::SymInt index) const {</span>
<span id="L3444"><span class="lineNum">    3444</span>              :     return at::_ops::select_scatter::call(const_cast&lt;Tensor&amp;&gt;(*this), src, dim, index);</span>
<span id="L3445"><span class="lineNum">    3445</span>              : }</span>
<span id="L3446"><span class="lineNum">    3446</span>              : </span>
<span id="L3447"><span class="lineNum">    3447</span>              : // aten::diagonal_scatter(Tensor self, Tensor src, int offset=0, int dim1=0, int dim2=1) -&gt; Tensor</span>
<span id="L3448"><span class="lineNum">    3448</span>              : inline at::Tensor Tensor::diagonal_scatter(const at::Tensor &amp; src, int64_t offset, int64_t dim1, int64_t dim2) const {</span>
<span id="L3449"><span class="lineNum">    3449</span>              :     return at::_ops::diagonal_scatter::call(const_cast&lt;Tensor&amp;&gt;(*this), src, offset, dim1, dim2);</span>
<span id="L3450"><span class="lineNum">    3450</span>              : }</span>
<span id="L3451"><span class="lineNum">    3451</span>              : </span>
<span id="L3452"><span class="lineNum">    3452</span>              : // aten::as_strided_scatter(Tensor self, Tensor src, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -&gt; Tensor</span>
<span id="L3453"><span class="lineNum">    3453</span>              : inline at::Tensor Tensor::as_strided_scatter(const at::Tensor &amp; src, at::IntArrayRef size, at::IntArrayRef stride, ::std::optional&lt;int64_t&gt; storage_offset) const {</span>
<span id="L3454"><span class="lineNum">    3454</span>              :     return at::_ops::as_strided_scatter::call(const_cast&lt;Tensor&amp;&gt;(*this), src, c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride), storage_offset.has_value() ? ::std::make_optional(c10::SymInt(*storage_offset)) : ::std::nullopt);</span>
<span id="L3455"><span class="lineNum">    3455</span>              : }</span>
<span id="L3456"><span class="lineNum">    3456</span>              : </span>
<span id="L3457"><span class="lineNum">    3457</span>              : // aten::as_strided_scatter(Tensor self, Tensor src, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -&gt; Tensor</span>
<span id="L3458"><span class="lineNum">    3458</span>              : inline at::Tensor Tensor::as_strided_scatter_symint(const at::Tensor &amp; src, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, ::std::optional&lt;c10::SymInt&gt; storage_offset) const {</span>
<span id="L3459"><span class="lineNum">    3459</span>              :     return at::_ops::as_strided_scatter::call(const_cast&lt;Tensor&amp;&gt;(*this), src, size, stride, storage_offset);</span>
<span id="L3460"><span class="lineNum">    3460</span>              : }</span>
<span id="L3461"><span class="lineNum">    3461</span>              : </span>
<span id="L3462"><span class="lineNum">    3462</span>              : // aten::smm(Tensor self, Tensor mat2) -&gt; Tensor</span>
<span id="L3463"><span class="lineNum">    3463</span>              : inline at::Tensor Tensor::smm(const at::Tensor &amp; mat2) const {</span>
<span id="L3464"><span class="lineNum">    3464</span>              :     return at::_ops::smm::call(const_cast&lt;Tensor&amp;&gt;(*this), mat2);</span>
<span id="L3465"><span class="lineNum">    3465</span>              : }</span>
<span id="L3466"><span class="lineNum">    3466</span>              : </span>
<span id="L3467"><span class="lineNum">    3467</span>              : // aten::softmax.int(Tensor self, int dim, ScalarType? dtype=None) -&gt; Tensor</span>
<span id="L3468"><span class="lineNum">    3468</span>              : inline at::Tensor Tensor::softmax(int64_t dim, ::std::optional&lt;at::ScalarType&gt; dtype) const {</span>
<span id="L3469"><span class="lineNum">    3469</span>              :     return at::_ops::softmax_int::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, dtype);</span>
<span id="L3470"><span class="lineNum">    3470</span>              : }</span>
<span id="L3471"><span class="lineNum">    3471</span>              : </span>
<span id="L3472"><span class="lineNum">    3472</span>              : // aten::softmax.Dimname(Tensor self, Dimname dim, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span id="L3473"><span class="lineNum">    3473</span>              : inline at::Tensor Tensor::softmax(at::Dimname dim, ::std::optional&lt;at::ScalarType&gt; dtype) const {</span>
<span id="L3474"><span class="lineNum">    3474</span>              :     return at::_ops::softmax_Dimname::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, dtype);</span>
<span id="L3475"><span class="lineNum">    3475</span>              : }</span>
<span id="L3476"><span class="lineNum">    3476</span>              : </span>
<span id="L3477"><span class="lineNum">    3477</span>              : // aten::unsafe_split.Tensor(Tensor self, SymInt split_size, int dim=0) -&gt; Tensor[]</span>
<span id="L3478"><span class="lineNum">    3478</span>              : inline ::std::vector&lt;at::Tensor&gt; Tensor::unsafe_split(int64_t split_size, int64_t dim) const {</span>
<span id="L3479"><span class="lineNum">    3479</span>              :     return at::_ops::unsafe_split_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), split_size, dim);</span>
<span id="L3480"><span class="lineNum">    3480</span>              : }</span>
<span id="L3481"><span class="lineNum">    3481</span>              : </span>
<span id="L3482"><span class="lineNum">    3482</span>              : // aten::unsafe_split.Tensor(Tensor self, SymInt split_size, int dim=0) -&gt; Tensor[]</span>
<span id="L3483"><span class="lineNum">    3483</span>              : inline ::std::vector&lt;at::Tensor&gt; Tensor::unsafe_split_symint(c10::SymInt split_size, int64_t dim) const {</span>
<span id="L3484"><span class="lineNum">    3484</span>              :     return at::_ops::unsafe_split_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), split_size, dim);</span>
<span id="L3485"><span class="lineNum">    3485</span>              : }</span>
<span id="L3486"><span class="lineNum">    3486</span>              : </span>
<span id="L3487"><span class="lineNum">    3487</span>              : // aten::split.Tensor(Tensor(a -&gt; *) self, SymInt split_size, int dim=0) -&gt; Tensor(a)[]</span>
<span id="L3488"><span class="lineNum">    3488</span>              : inline ::std::vector&lt;at::Tensor&gt; Tensor::split(int64_t split_size, int64_t dim) const {</span>
<span id="L3489"><span class="lineNum">    3489</span>              :     return at::_ops::split_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), split_size, dim);</span>
<span id="L3490"><span class="lineNum">    3490</span>              : }</span>
<span id="L3491"><span class="lineNum">    3491</span>              : </span>
<span id="L3492"><span class="lineNum">    3492</span>              : // aten::split.Tensor(Tensor(a -&gt; *) self, SymInt split_size, int dim=0) -&gt; Tensor(a)[]</span>
<span id="L3493"><span class="lineNum">    3493</span>              : inline ::std::vector&lt;at::Tensor&gt; Tensor::split_symint(c10::SymInt split_size, int64_t dim) const {</span>
<span id="L3494"><span class="lineNum">    3494</span>              :     return at::_ops::split_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), split_size, dim);</span>
<span id="L3495"><span class="lineNum">    3495</span>              : }</span>
<span id="L3496"><span class="lineNum">    3496</span>              : </span>
<span id="L3497"><span class="lineNum">    3497</span>              : // aten::split.sizes(Tensor(a -&gt; *) self, SymInt[] split_size, int dim=0) -&gt; Tensor(a)[]</span>
<span id="L3498"><span class="lineNum">    3498</span>              : inline ::std::vector&lt;at::Tensor&gt; Tensor::split(at::IntArrayRef split_size, int64_t dim) const {</span>
<span id="L3499"><span class="lineNum">    3499</span>              :     return at::_ops::split_sizes::call(const_cast&lt;Tensor&amp;&gt;(*this), c10::fromIntArrayRefSlow(split_size), dim);</span>
<span id="L3500"><span class="lineNum">    3500</span>              : }</span>
<span id="L3501"><span class="lineNum">    3501</span>              : </span>
<span id="L3502"><span class="lineNum">    3502</span>              : // aten::split.sizes(Tensor(a -&gt; *) self, SymInt[] split_size, int dim=0) -&gt; Tensor(a)[]</span>
<span id="L3503"><span class="lineNum">    3503</span>              : inline ::std::vector&lt;at::Tensor&gt; Tensor::split_symint(c10::SymIntArrayRef split_size, int64_t dim) const {</span>
<span id="L3504"><span class="lineNum">    3504</span>              :     return at::_ops::split_sizes::call(const_cast&lt;Tensor&amp;&gt;(*this), split_size, dim);</span>
<span id="L3505"><span class="lineNum">    3505</span>              : }</span>
<span id="L3506"><span class="lineNum">    3506</span>              : </span>
<span id="L3507"><span class="lineNum">    3507</span>              : // aten::unsafe_split_with_sizes(Tensor self, SymInt[] split_sizes, int dim=0) -&gt; Tensor[]</span>
<span id="L3508"><span class="lineNum">    3508</span>              : inline ::std::vector&lt;at::Tensor&gt; Tensor::unsafe_split_with_sizes(at::IntArrayRef split_sizes, int64_t dim) const {</span>
<span id="L3509"><span class="lineNum">    3509</span>              :     return at::_ops::unsafe_split_with_sizes::call(const_cast&lt;Tensor&amp;&gt;(*this), c10::fromIntArrayRefSlow(split_sizes), dim);</span>
<span id="L3510"><span class="lineNum">    3510</span>              : }</span>
<span id="L3511"><span class="lineNum">    3511</span>              : </span>
<span id="L3512"><span class="lineNum">    3512</span>              : // aten::unsafe_split_with_sizes(Tensor self, SymInt[] split_sizes, int dim=0) -&gt; Tensor[]</span>
<span id="L3513"><span class="lineNum">    3513</span>              : inline ::std::vector&lt;at::Tensor&gt; Tensor::unsafe_split_with_sizes_symint(c10::SymIntArrayRef split_sizes, int64_t dim) const {</span>
<span id="L3514"><span class="lineNum">    3514</span>              :     return at::_ops::unsafe_split_with_sizes::call(const_cast&lt;Tensor&amp;&gt;(*this), split_sizes, dim);</span>
<span id="L3515"><span class="lineNum">    3515</span>              : }</span>
<span id="L3516"><span class="lineNum">    3516</span>              : </span>
<span id="L3517"><span class="lineNum">    3517</span>              : // aten::split_with_sizes(Tensor(a -&gt; *) self, SymInt[] split_sizes, int dim=0) -&gt; Tensor(a)[]</span>
<span id="L3518"><span class="lineNum">    3518</span>              : inline ::std::vector&lt;at::Tensor&gt; Tensor::split_with_sizes(at::IntArrayRef split_sizes, int64_t dim) const {</span>
<span id="L3519"><span class="lineNum">    3519</span>              :     return at::_ops::split_with_sizes::call(const_cast&lt;Tensor&amp;&gt;(*this), c10::fromIntArrayRefSlow(split_sizes), dim);</span>
<span id="L3520"><span class="lineNum">    3520</span>              : }</span>
<span id="L3521"><span class="lineNum">    3521</span>              : </span>
<span id="L3522"><span class="lineNum">    3522</span>              : // aten::split_with_sizes(Tensor(a -&gt; *) self, SymInt[] split_sizes, int dim=0) -&gt; Tensor(a)[]</span>
<span id="L3523"><span class="lineNum">    3523</span>              : inline ::std::vector&lt;at::Tensor&gt; Tensor::split_with_sizes_symint(c10::SymIntArrayRef split_sizes, int64_t dim) const {</span>
<span id="L3524"><span class="lineNum">    3524</span>              :     return at::_ops::split_with_sizes::call(const_cast&lt;Tensor&amp;&gt;(*this), split_sizes, dim);</span>
<span id="L3525"><span class="lineNum">    3525</span>              : }</span>
<span id="L3526"><span class="lineNum">    3526</span>              : </span>
<span id="L3527"><span class="lineNum">    3527</span>              : // aten::hsplit.int(Tensor(a -&gt; *) self, int sections) -&gt; Tensor(a)[]</span>
<span id="L3528"><span class="lineNum">    3528</span>              : inline ::std::vector&lt;at::Tensor&gt; Tensor::hsplit(int64_t sections) const {</span>
<span id="L3529"><span class="lineNum">    3529</span>              :     return at::_ops::hsplit_int::call(const_cast&lt;Tensor&amp;&gt;(*this), sections);</span>
<span id="L3530"><span class="lineNum">    3530</span>              : }</span>
<span id="L3531"><span class="lineNum">    3531</span>              : </span>
<span id="L3532"><span class="lineNum">    3532</span>              : // aten::hsplit.array(Tensor(a -&gt; *) self, int[] indices) -&gt; Tensor(a)[]</span>
<span id="L3533"><span class="lineNum">    3533</span>              : inline ::std::vector&lt;at::Tensor&gt; Tensor::hsplit(at::IntArrayRef indices) const {</span>
<span id="L3534"><span class="lineNum">    3534</span>              :     return at::_ops::hsplit_array::call(const_cast&lt;Tensor&amp;&gt;(*this), indices);</span>
<span id="L3535"><span class="lineNum">    3535</span>              : }</span>
<span id="L3536"><span class="lineNum">    3536</span>              : </span>
<span id="L3537"><span class="lineNum">    3537</span>              : // aten::vsplit.int(Tensor(a -&gt; *) self, int sections) -&gt; Tensor(a)[]</span>
<span id="L3538"><span class="lineNum">    3538</span>              : inline ::std::vector&lt;at::Tensor&gt; Tensor::vsplit(int64_t sections) const {</span>
<span id="L3539"><span class="lineNum">    3539</span>              :     return at::_ops::vsplit_int::call(const_cast&lt;Tensor&amp;&gt;(*this), sections);</span>
<span id="L3540"><span class="lineNum">    3540</span>              : }</span>
<span id="L3541"><span class="lineNum">    3541</span>              : </span>
<span id="L3542"><span class="lineNum">    3542</span>              : // aten::vsplit.array(Tensor(a -&gt; *) self, int[] indices) -&gt; Tensor(a)[]</span>
<span id="L3543"><span class="lineNum">    3543</span>              : inline ::std::vector&lt;at::Tensor&gt; Tensor::vsplit(at::IntArrayRef indices) const {</span>
<span id="L3544"><span class="lineNum">    3544</span>              :     return at::_ops::vsplit_array::call(const_cast&lt;Tensor&amp;&gt;(*this), indices);</span>
<span id="L3545"><span class="lineNum">    3545</span>              : }</span>
<span id="L3546"><span class="lineNum">    3546</span>              : </span>
<span id="L3547"><span class="lineNum">    3547</span>              : // aten::dsplit.int(Tensor(a -&gt; *) self, int sections) -&gt; Tensor(a)[]</span>
<span id="L3548"><span class="lineNum">    3548</span>              : inline ::std::vector&lt;at::Tensor&gt; Tensor::dsplit(int64_t sections) const {</span>
<span id="L3549"><span class="lineNum">    3549</span>              :     return at::_ops::dsplit_int::call(const_cast&lt;Tensor&amp;&gt;(*this), sections);</span>
<span id="L3550"><span class="lineNum">    3550</span>              : }</span>
<span id="L3551"><span class="lineNum">    3551</span>              : </span>
<span id="L3552"><span class="lineNum">    3552</span>              : // aten::dsplit.array(Tensor(a -&gt; *) self, int[] indices) -&gt; Tensor(a)[]</span>
<span id="L3553"><span class="lineNum">    3553</span>              : inline ::std::vector&lt;at::Tensor&gt; Tensor::dsplit(at::IntArrayRef indices) const {</span>
<span id="L3554"><span class="lineNum">    3554</span>              :     return at::_ops::dsplit_array::call(const_cast&lt;Tensor&amp;&gt;(*this), indices);</span>
<span id="L3555"><span class="lineNum">    3555</span>              : }</span>
<span id="L3556"><span class="lineNum">    3556</span>              : </span>
<span id="L3557"><span class="lineNum">    3557</span>              : // aten::squeeze(Tensor(a) self) -&gt; Tensor(a)</span>
<span id="L3558"><span class="lineNum">    3558</span>              : inline at::Tensor Tensor::squeeze() const {</span>
<span id="L3559"><span class="lineNum">    3559</span>              :     return at::_ops::squeeze::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3560"><span class="lineNum">    3560</span>              : }</span>
<span id="L3561"><span class="lineNum">    3561</span>              : </span>
<span id="L3562"><span class="lineNum">    3562</span>              : // aten::squeeze.dim(Tensor(a) self, int dim) -&gt; Tensor(a)</span>
<span id="L3563"><span class="lineNum">    3563</span>              : inline at::Tensor Tensor::squeeze(int64_t dim) const {</span>
<span id="L3564"><span class="lineNum">    3564</span>              :     return at::_ops::squeeze_dim::call(const_cast&lt;Tensor&amp;&gt;(*this), dim);</span>
<span id="L3565"><span class="lineNum">    3565</span>              : }</span>
<span id="L3566"><span class="lineNum">    3566</span>              : </span>
<span id="L3567"><span class="lineNum">    3567</span>              : // aten::squeeze.dimname(Tensor(a) self, Dimname dim) -&gt; Tensor(a)</span>
<span id="L3568"><span class="lineNum">    3568</span>              : inline at::Tensor Tensor::squeeze(at::Dimname dim) const {</span>
<span id="L3569"><span class="lineNum">    3569</span>              :     return at::_ops::squeeze_dimname::call(const_cast&lt;Tensor&amp;&gt;(*this), dim);</span>
<span id="L3570"><span class="lineNum">    3570</span>              : }</span>
<span id="L3571"><span class="lineNum">    3571</span>              : </span>
<span id="L3572"><span class="lineNum">    3572</span>              : // aten::squeeze.dims(Tensor(a) self, int[] dim) -&gt; Tensor(a)</span>
<span id="L3573"><span class="lineNum">    3573</span>              : inline at::Tensor Tensor::squeeze(at::IntArrayRef dim) const {</span>
<span id="L3574"><span class="lineNum">    3574</span>              :     return at::_ops::squeeze_dims::call(const_cast&lt;Tensor&amp;&gt;(*this), dim);</span>
<span id="L3575"><span class="lineNum">    3575</span>              : }</span>
<span id="L3576"><span class="lineNum">    3576</span>              : </span>
<span id="L3577"><span class="lineNum">    3577</span>              : // aten::squeeze_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L3578"><span class="lineNum">    3578</span>              : inline at::Tensor &amp; Tensor::squeeze_() const {</span>
<span id="L3579"><span class="lineNum">    3579</span>              :     return at::_ops::squeeze_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3580"><span class="lineNum">    3580</span>              : }</span>
<span id="L3581"><span class="lineNum">    3581</span>              : </span>
<span id="L3582"><span class="lineNum">    3582</span>              : // aten::squeeze_.dim(Tensor(a!) self, int dim) -&gt; Tensor(a!)</span>
<span id="L3583"><span class="lineNum">    3583</span>              : inline at::Tensor &amp; Tensor::squeeze_(int64_t dim) const {</span>
<span id="L3584"><span class="lineNum">    3584</span>              :     return at::_ops::squeeze__dim::call(const_cast&lt;Tensor&amp;&gt;(*this), dim);</span>
<span id="L3585"><span class="lineNum">    3585</span>              : }</span>
<span id="L3586"><span class="lineNum">    3586</span>              : </span>
<span id="L3587"><span class="lineNum">    3587</span>              : // aten::squeeze_.dims(Tensor(a!) self, int[] dim) -&gt; Tensor(a!)</span>
<span id="L3588"><span class="lineNum">    3588</span>              : inline at::Tensor &amp; Tensor::squeeze_(at::IntArrayRef dim) const {</span>
<span id="L3589"><span class="lineNum">    3589</span>              :     return at::_ops::squeeze__dims::call(const_cast&lt;Tensor&amp;&gt;(*this), dim);</span>
<span id="L3590"><span class="lineNum">    3590</span>              : }</span>
<span id="L3591"><span class="lineNum">    3591</span>              : </span>
<span id="L3592"><span class="lineNum">    3592</span>              : // aten::squeeze_.dimname(Tensor(a!) self, Dimname dim) -&gt; Tensor(a!)</span>
<span id="L3593"><span class="lineNum">    3593</span>              : inline at::Tensor &amp; Tensor::squeeze_(at::Dimname dim) const {</span>
<span id="L3594"><span class="lineNum">    3594</span>              :     return at::_ops::squeeze__dimname::call(const_cast&lt;Tensor&amp;&gt;(*this), dim);</span>
<span id="L3595"><span class="lineNum">    3595</span>              : }</span>
<span id="L3596"><span class="lineNum">    3596</span>              : </span>
<span id="L3597"><span class="lineNum">    3597</span>              : // aten::sspaddmm(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor</span>
<span id="L3598"><span class="lineNum">    3598</span>              : inline at::Tensor Tensor::sspaddmm(const at::Tensor &amp; mat1, const at::Tensor &amp; mat2, const at::Scalar &amp; beta, const at::Scalar &amp; alpha) const {</span>
<span id="L3599"><span class="lineNum">    3599</span>              :     return at::_ops::sspaddmm::call(const_cast&lt;Tensor&amp;&gt;(*this), mat1, mat2, beta, alpha);</span>
<span id="L3600"><span class="lineNum">    3600</span>              : }</span>
<span id="L3601"><span class="lineNum">    3601</span>              : </span>
<span id="L3602"><span class="lineNum">    3602</span>              : // aten::stft(Tensor self, int n_fft, int? hop_length=None, int? win_length=None, Tensor? window=None, bool normalized=False, bool? onesided=None, bool? return_complex=None) -&gt; Tensor</span>
<span id="L3603"><span class="lineNum">    3603</span>              : inline at::Tensor Tensor::stft(int64_t n_fft, ::std::optional&lt;int64_t&gt; hop_length, ::std::optional&lt;int64_t&gt; win_length, const ::std::optional&lt;at::Tensor&gt; &amp; window, bool normalized, ::std::optional&lt;bool&gt; onesided, ::std::optional&lt;bool&gt; return_complex) const {</span>
<span id="L3604"><span class="lineNum">    3604</span>              :     return at::_ops::stft::call(const_cast&lt;Tensor&amp;&gt;(*this), n_fft, hop_length, win_length, window, normalized, onesided, return_complex);</span>
<span id="L3605"><span class="lineNum">    3605</span>              : }</span>
<span id="L3606"><span class="lineNum">    3606</span>              : </span>
<span id="L3607"><span class="lineNum">    3607</span>              : // aten::stft.center(Tensor self, int n_fft, int? hop_length=None, int? win_length=None, Tensor? window=None, bool center=True, str pad_mode=&quot;reflect&quot;, bool normalized=False, bool? onesided=None, bool? return_complex=None) -&gt; Tensor</span>
<span id="L3608"><span class="lineNum">    3608</span>              : inline at::Tensor Tensor::stft(int64_t n_fft, ::std::optional&lt;int64_t&gt; hop_length, ::std::optional&lt;int64_t&gt; win_length, const ::std::optional&lt;at::Tensor&gt; &amp; window, bool center, c10::string_view pad_mode, bool normalized, ::std::optional&lt;bool&gt; onesided, ::std::optional&lt;bool&gt; return_complex) const {</span>
<span id="L3609"><span class="lineNum">    3609</span>              :     return at::_ops::stft_center::call(const_cast&lt;Tensor&amp;&gt;(*this), n_fft, hop_length, win_length, window, center, pad_mode, normalized, onesided, return_complex);</span>
<span id="L3610"><span class="lineNum">    3610</span>              : }</span>
<span id="L3611"><span class="lineNum">    3611</span>              : </span>
<span id="L3612"><span class="lineNum">    3612</span>              : // aten::istft(Tensor self, int n_fft, int? hop_length=None, int? win_length=None, Tensor? window=None, bool center=True, bool normalized=False, bool? onesided=None, int? length=None, bool return_complex=False) -&gt; Tensor</span>
<span id="L3613"><span class="lineNum">    3613</span>              : inline at::Tensor Tensor::istft(int64_t n_fft, ::std::optional&lt;int64_t&gt; hop_length, ::std::optional&lt;int64_t&gt; win_length, const ::std::optional&lt;at::Tensor&gt; &amp; window, bool center, bool normalized, ::std::optional&lt;bool&gt; onesided, ::std::optional&lt;int64_t&gt; length, bool return_complex) const {</span>
<span id="L3614"><span class="lineNum">    3614</span>              :     return at::_ops::istft::call(const_cast&lt;Tensor&amp;&gt;(*this), n_fft, hop_length, win_length, window, center, normalized, onesided, length, return_complex);</span>
<span id="L3615"><span class="lineNum">    3615</span>              : }</span>
<span id="L3616"><span class="lineNum">    3616</span>              : </span>
<span id="L3617"><span class="lineNum">    3617</span>              : // aten::stride.Dimname(Tensor self, Dimname dim) -&gt; int</span>
<span id="L3618"><span class="lineNum">    3618</span>              : inline int64_t Tensor::stride(at::Dimname dim) const {</span>
<span id="L3619"><span class="lineNum">    3619</span>              :     return at::_ops::stride_Dimname::call(const_cast&lt;Tensor&amp;&gt;(*this), dim);</span>
<span id="L3620"><span class="lineNum">    3620</span>              : }</span>
<span id="L3621"><span class="lineNum">    3621</span>              : </span>
<span id="L3622"><span class="lineNum">    3622</span>              : // aten::sum(Tensor self, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span id="L3623"><span class="lineNum">    3623</span>              : inline at::Tensor Tensor::sum(::std::optional&lt;at::ScalarType&gt; dtype) const {</span>
<span id="L3624"><span class="lineNum">    3624</span>              :     return at::_ops::sum::call(const_cast&lt;Tensor&amp;&gt;(*this), dtype);</span>
<span id="L3625"><span class="lineNum">    3625</span>              : }</span>
<span id="L3626"><span class="lineNum">    3626</span>              : </span>
<span id="L3627"><span class="lineNum">    3627</span>              : // aten::sum.dim_IntList(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span id="L3628"><span class="lineNum">    3628</span>              : inline at::Tensor Tensor::sum(at::OptionalIntArrayRef dim, bool keepdim, ::std::optional&lt;at::ScalarType&gt; dtype) const {</span>
<span id="L3629"><span class="lineNum">    3629</span>              :     return at::_ops::sum_dim_IntList::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, keepdim, dtype);</span>
<span id="L3630"><span class="lineNum">    3630</span>              : }</span>
<span id="L3631"><span class="lineNum">    3631</span>              : </span>
<span id="L3632"><span class="lineNum">    3632</span>              : // aten::sum.dim_DimnameList(Tensor self, Dimname[1] dim, bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span id="L3633"><span class="lineNum">    3633</span>              : inline at::Tensor Tensor::sum(at::DimnameList dim, bool keepdim, ::std::optional&lt;at::ScalarType&gt; dtype) const {</span>
<span id="L3634"><span class="lineNum">    3634</span>              :     return at::_ops::sum_dim_DimnameList::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, keepdim, dtype);</span>
<span id="L3635"><span class="lineNum">    3635</span>              : }</span>
<span id="L3636"><span class="lineNum">    3636</span>              : </span>
<span id="L3637"><span class="lineNum">    3637</span>              : // aten::nansum(Tensor self, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span id="L3638"><span class="lineNum">    3638</span>              : inline at::Tensor Tensor::nansum(at::OptionalIntArrayRef dim, bool keepdim, ::std::optional&lt;at::ScalarType&gt; dtype) const {</span>
<span id="L3639"><span class="lineNum">    3639</span>              :     return at::_ops::nansum::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, keepdim, dtype);</span>
<span id="L3640"><span class="lineNum">    3640</span>              : }</span>
<span id="L3641"><span class="lineNum">    3641</span>              : </span>
<span id="L3642"><span class="lineNum">    3642</span>              : // aten::sum_to_size(Tensor self, SymInt[] size) -&gt; Tensor</span>
<span id="L3643"><span class="lineNum">    3643</span>              : inline at::Tensor Tensor::sum_to_size(at::IntArrayRef size) const {</span>
<span id="L3644"><span class="lineNum">    3644</span>              :     return at::_ops::sum_to_size::call(const_cast&lt;Tensor&amp;&gt;(*this), c10::fromIntArrayRefSlow(size));</span>
<span id="L3645"><span class="lineNum">    3645</span>              : }</span>
<span id="L3646"><span class="lineNum">    3646</span>              : </span>
<span id="L3647"><span class="lineNum">    3647</span>              : // aten::sum_to_size(Tensor self, SymInt[] size) -&gt; Tensor</span>
<span id="L3648"><span class="lineNum">    3648</span>              : inline at::Tensor Tensor::sum_to_size_symint(c10::SymIntArrayRef size) const {</span>
<span id="L3649"><span class="lineNum">    3649</span>              :     return at::_ops::sum_to_size::call(const_cast&lt;Tensor&amp;&gt;(*this), size);</span>
<span id="L3650"><span class="lineNum">    3650</span>              : }</span>
<span id="L3651"><span class="lineNum">    3651</span>              : </span>
<span id="L3652"><span class="lineNum">    3652</span>              : // aten::sqrt(Tensor self) -&gt; Tensor</span>
<span id="L3653"><span class="lineNum">    3653</span>              : inline at::Tensor Tensor::sqrt() const {</span>
<span id="L3654"><span class="lineNum">    3654</span>              :     return at::_ops::sqrt::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3655"><span class="lineNum">    3655</span>              : }</span>
<span id="L3656"><span class="lineNum">    3656</span>              : </span>
<span id="L3657"><span class="lineNum">    3657</span>              : // aten::sqrt_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L3658"><span class="lineNum">    3658</span>              : inline at::Tensor &amp; Tensor::sqrt_() const {</span>
<span id="L3659"><span class="lineNum">    3659</span>              :     return at::_ops::sqrt_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3660"><span class="lineNum">    3660</span>              : }</span>
<span id="L3661"><span class="lineNum">    3661</span>              : </span>
<span id="L3662"><span class="lineNum">    3662</span>              : // aten::square(Tensor self) -&gt; Tensor</span>
<span id="L3663"><span class="lineNum">    3663</span>              : inline at::Tensor Tensor::square() const {</span>
<span id="L3664"><span class="lineNum">    3664</span>              :     return at::_ops::square::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3665"><span class="lineNum">    3665</span>              : }</span>
<span id="L3666"><span class="lineNum">    3666</span>              : </span>
<span id="L3667"><span class="lineNum">    3667</span>              : // aten::square_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L3668"><span class="lineNum">    3668</span>              : inline at::Tensor &amp; Tensor::square_() const {</span>
<span id="L3669"><span class="lineNum">    3669</span>              :     return at::_ops::square_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3670"><span class="lineNum">    3670</span>              : }</span>
<span id="L3671"><span class="lineNum">    3671</span>              : </span>
<span id="L3672"><span class="lineNum">    3672</span>              : // aten::std(Tensor self, bool unbiased=True) -&gt; Tensor</span>
<span id="L3673"><span class="lineNum">    3673</span>              : inline at::Tensor Tensor::std(bool unbiased) const {</span>
<span id="L3674"><span class="lineNum">    3674</span>              :     return at::_ops::std::call(const_cast&lt;Tensor&amp;&gt;(*this), unbiased);</span>
<span id="L3675"><span class="lineNum">    3675</span>              : }</span>
<span id="L3676"><span class="lineNum">    3676</span>              : </span>
<span id="L3677"><span class="lineNum">    3677</span>              : // aten::std.dim(Tensor self, int[1]? dim, bool unbiased=True, bool keepdim=False) -&gt; Tensor</span>
<span id="L3678"><span class="lineNum">    3678</span>              : inline at::Tensor Tensor::std(at::OptionalIntArrayRef dim, bool unbiased, bool keepdim) const {</span>
<span id="L3679"><span class="lineNum">    3679</span>              :     return at::_ops::std_dim::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, unbiased, keepdim);</span>
<span id="L3680"><span class="lineNum">    3680</span>              : }</span>
<span id="L3681"><span class="lineNum">    3681</span>              : </span>
<span id="L3682"><span class="lineNum">    3682</span>              : // aten::std.correction(Tensor self, int[1]? dim=None, *, Scalar? correction=None, bool keepdim=False) -&gt; Tensor</span>
<span id="L3683"><span class="lineNum">    3683</span>              : inline at::Tensor Tensor::std(at::OptionalIntArrayRef dim, const ::std::optional&lt;at::Scalar&gt; &amp; correction, bool keepdim) const {</span>
<span id="L3684"><span class="lineNum">    3684</span>              :     return at::_ops::std_correction::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, correction, keepdim);</span>
<span id="L3685"><span class="lineNum">    3685</span>              : }</span>
<span id="L3686"><span class="lineNum">    3686</span>              : </span>
<span id="L3687"><span class="lineNum">    3687</span>              : // aten::std.names_dim(Tensor self, Dimname[1] dim, bool unbiased=True, bool keepdim=False) -&gt; Tensor</span>
<span id="L3688"><span class="lineNum">    3688</span>              : inline at::Tensor Tensor::std(at::DimnameList dim, bool unbiased, bool keepdim) const {</span>
<span id="L3689"><span class="lineNum">    3689</span>              :     return at::_ops::std_names_dim::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, unbiased, keepdim);</span>
<span id="L3690"><span class="lineNum">    3690</span>              : }</span>
<span id="L3691"><span class="lineNum">    3691</span>              : </span>
<span id="L3692"><span class="lineNum">    3692</span>              : // aten::std.correction_names(Tensor self, Dimname[1] dim, *, Scalar? correction=None, bool keepdim=False) -&gt; Tensor</span>
<span id="L3693"><span class="lineNum">    3693</span>              : inline at::Tensor Tensor::std(at::DimnameList dim, const ::std::optional&lt;at::Scalar&gt; &amp; correction, bool keepdim) const {</span>
<span id="L3694"><span class="lineNum">    3694</span>              :     return at::_ops::std_correction_names::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, correction, keepdim);</span>
<span id="L3695"><span class="lineNum">    3695</span>              : }</span>
<span id="L3696"><span class="lineNum">    3696</span>              : </span>
<span id="L3697"><span class="lineNum">    3697</span>              : // aten::prod(Tensor self, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span id="L3698"><span class="lineNum">    3698</span>              : inline at::Tensor Tensor::prod(::std::optional&lt;at::ScalarType&gt; dtype) const {</span>
<span id="L3699"><span class="lineNum">    3699</span>              :     return at::_ops::prod::call(const_cast&lt;Tensor&amp;&gt;(*this), dtype);</span>
<span id="L3700"><span class="lineNum">    3700</span>              : }</span>
<span id="L3701"><span class="lineNum">    3701</span>              : </span>
<span id="L3702"><span class="lineNum">    3702</span>              : // aten::prod.dim_int(Tensor self, int dim, bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span id="L3703"><span class="lineNum">    3703</span>              : inline at::Tensor Tensor::prod(int64_t dim, bool keepdim, ::std::optional&lt;at::ScalarType&gt; dtype) const {</span>
<span id="L3704"><span class="lineNum">    3704</span>              :     return at::_ops::prod_dim_int::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, keepdim, dtype);</span>
<span id="L3705"><span class="lineNum">    3705</span>              : }</span>
<span id="L3706"><span class="lineNum">    3706</span>              : </span>
<span id="L3707"><span class="lineNum">    3707</span>              : // aten::prod.dim_Dimname(Tensor self, Dimname dim, bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span id="L3708"><span class="lineNum">    3708</span>              : inline at::Tensor Tensor::prod(at::Dimname dim, bool keepdim, ::std::optional&lt;at::ScalarType&gt; dtype) const {</span>
<span id="L3709"><span class="lineNum">    3709</span>              :     return at::_ops::prod_dim_Dimname::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, keepdim, dtype);</span>
<span id="L3710"><span class="lineNum">    3710</span>              : }</span>
<span id="L3711"><span class="lineNum">    3711</span>              : </span>
<span id="L3712"><span class="lineNum">    3712</span>              : // aten::t(Tensor(a) self) -&gt; Tensor(a)</span>
<span id="L3713"><span class="lineNum">    3713</span>              : inline at::Tensor Tensor::t() const {</span>
<span id="L3714"><span class="lineNum">    3714</span>              :     return at::_ops::t::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3715"><span class="lineNum">    3715</span>              : }</span>
<span id="L3716"><span class="lineNum">    3716</span>              : </span>
<span id="L3717"><span class="lineNum">    3717</span>              : // aten::t_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L3718"><span class="lineNum">    3718</span>              : inline at::Tensor &amp; Tensor::t_() const {</span>
<span id="L3719"><span class="lineNum">    3719</span>              :     return at::_ops::t_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3720"><span class="lineNum">    3720</span>              : }</span>
<span id="L3721"><span class="lineNum">    3721</span>              : </span>
<span id="L3722"><span class="lineNum">    3722</span>              : // aten::tan(Tensor self) -&gt; Tensor</span>
<span id="L3723"><span class="lineNum">    3723</span>              : inline at::Tensor Tensor::tan() const {</span>
<span id="L3724"><span class="lineNum">    3724</span>              :     return at::_ops::tan::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3725"><span class="lineNum">    3725</span>              : }</span>
<span id="L3726"><span class="lineNum">    3726</span>              : </span>
<span id="L3727"><span class="lineNum">    3727</span>              : // aten::tan_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L3728"><span class="lineNum">    3728</span>              : inline at::Tensor &amp; Tensor::tan_() const {</span>
<span id="L3729"><span class="lineNum">    3729</span>              :     return at::_ops::tan_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3730"><span class="lineNum">    3730</span>              : }</span>
<span id="L3731"><span class="lineNum">    3731</span>              : </span>
<span id="L3732"><span class="lineNum">    3732</span>              : // aten::tanh(Tensor self) -&gt; Tensor</span>
<span id="L3733"><span class="lineNum">    3733</span>              : inline at::Tensor Tensor::tanh() const {</span>
<span id="L3734"><span class="lineNum">    3734</span>              :     return at::_ops::tanh::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3735"><span class="lineNum">    3735</span>              : }</span>
<span id="L3736"><span class="lineNum">    3736</span>              : </span>
<span id="L3737"><span class="lineNum">    3737</span>              : // aten::tanh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L3738"><span class="lineNum">    3738</span>              : inline at::Tensor &amp; Tensor::tanh_() const {</span>
<span id="L3739"><span class="lineNum">    3739</span>              :     return at::_ops::tanh_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3740"><span class="lineNum">    3740</span>              : }</span>
<span id="L3741"><span class="lineNum">    3741</span>              : </span>
<span id="L3742"><span class="lineNum">    3742</span>              : // aten::tile(Tensor self, SymInt[] dims) -&gt; Tensor</span>
<span id="L3743"><span class="lineNum">    3743</span>              : inline at::Tensor Tensor::tile(at::IntArrayRef dims) const {</span>
<span id="L3744"><span class="lineNum">    3744</span>              :     return at::_ops::tile::call(const_cast&lt;Tensor&amp;&gt;(*this), c10::fromIntArrayRefSlow(dims));</span>
<span id="L3745"><span class="lineNum">    3745</span>              : }</span>
<span id="L3746"><span class="lineNum">    3746</span>              : </span>
<span id="L3747"><span class="lineNum">    3747</span>              : // aten::tile(Tensor self, SymInt[] dims) -&gt; Tensor</span>
<span id="L3748"><span class="lineNum">    3748</span>              : inline at::Tensor Tensor::tile_symint(c10::SymIntArrayRef dims) const {</span>
<span id="L3749"><span class="lineNum">    3749</span>              :     return at::_ops::tile::call(const_cast&lt;Tensor&amp;&gt;(*this), dims);</span>
<span id="L3750"><span class="lineNum">    3750</span>              : }</span>
<span id="L3751"><span class="lineNum">    3751</span>              : </span>
<span id="L3752"><span class="lineNum">    3752</span>              : // aten::transpose.int(Tensor(a) self, int dim0, int dim1) -&gt; Tensor(a)</span>
<span id="L3753"><span class="lineNum">    3753</span>              : inline at::Tensor Tensor::transpose(int64_t dim0, int64_t dim1) const {</span>
<span id="L3754"><span class="lineNum">    3754</span>              :     return at::_ops::transpose_int::call(const_cast&lt;Tensor&amp;&gt;(*this), dim0, dim1);</span>
<span id="L3755"><span class="lineNum">    3755</span>              : }</span>
<span id="L3756"><span class="lineNum">    3756</span>              : </span>
<span id="L3757"><span class="lineNum">    3757</span>              : // aten::transpose.Dimname(Tensor(a) self, Dimname dim0, Dimname dim1) -&gt; Tensor(a)</span>
<span id="L3758"><span class="lineNum">    3758</span>              : inline at::Tensor Tensor::transpose(at::Dimname dim0, at::Dimname dim1) const {</span>
<span id="L3759"><span class="lineNum">    3759</span>              :     return at::_ops::transpose_Dimname::call(const_cast&lt;Tensor&amp;&gt;(*this), dim0, dim1);</span>
<span id="L3760"><span class="lineNum">    3760</span>              : }</span>
<span id="L3761"><span class="lineNum">    3761</span>              : </span>
<span id="L3762"><span class="lineNum">    3762</span>              : // aten::transpose_(Tensor(a!) self, int dim0, int dim1) -&gt; Tensor(a!)</span>
<span id="L3763"><span class="lineNum">    3763</span>              : inline at::Tensor &amp; Tensor::transpose_(int64_t dim0, int64_t dim1) const {</span>
<span id="L3764"><span class="lineNum">    3764</span>              :     return at::_ops::transpose_::call(const_cast&lt;Tensor&amp;&gt;(*this), dim0, dim1);</span>
<span id="L3765"><span class="lineNum">    3765</span>              : }</span>
<span id="L3766"><span class="lineNum">    3766</span>              : </span>
<span id="L3767"><span class="lineNum">    3767</span>              : // aten::flip(Tensor self, int[] dims) -&gt; Tensor</span>
<span id="L3768"><span class="lineNum">    3768</span>              : inline at::Tensor Tensor::flip(at::IntArrayRef dims) const {</span>
<span id="L3769"><span class="lineNum">    3769</span>              :     return at::_ops::flip::call(const_cast&lt;Tensor&amp;&gt;(*this), dims);</span>
<span id="L3770"><span class="lineNum">    3770</span>              : }</span>
<span id="L3771"><span class="lineNum">    3771</span>              : </span>
<span id="L3772"><span class="lineNum">    3772</span>              : // aten::fliplr(Tensor self) -&gt; Tensor</span>
<span id="L3773"><span class="lineNum">    3773</span>              : inline at::Tensor Tensor::fliplr() const {</span>
<span id="L3774"><span class="lineNum">    3774</span>              :     return at::_ops::fliplr::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3775"><span class="lineNum">    3775</span>              : }</span>
<span id="L3776"><span class="lineNum">    3776</span>              : </span>
<span id="L3777"><span class="lineNum">    3777</span>              : // aten::flipud(Tensor self) -&gt; Tensor</span>
<span id="L3778"><span class="lineNum">    3778</span>              : inline at::Tensor Tensor::flipud() const {</span>
<span id="L3779"><span class="lineNum">    3779</span>              :     return at::_ops::flipud::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3780"><span class="lineNum">    3780</span>              : }</span>
<span id="L3781"><span class="lineNum">    3781</span>              : </span>
<span id="L3782"><span class="lineNum">    3782</span>              : // aten::roll(Tensor self, SymInt[1] shifts, int[1] dims=[]) -&gt; Tensor</span>
<span id="L3783"><span class="lineNum">    3783</span>              : inline at::Tensor Tensor::roll(at::IntArrayRef shifts, at::IntArrayRef dims) const {</span>
<span id="L3784"><span class="lineNum">    3784</span>              :     return at::_ops::roll::call(const_cast&lt;Tensor&amp;&gt;(*this), c10::fromIntArrayRefSlow(shifts), dims);</span>
<span id="L3785"><span class="lineNum">    3785</span>              : }</span>
<span id="L3786"><span class="lineNum">    3786</span>              : </span>
<span id="L3787"><span class="lineNum">    3787</span>              : // aten::roll(Tensor self, SymInt[1] shifts, int[1] dims=[]) -&gt; Tensor</span>
<span id="L3788"><span class="lineNum">    3788</span>              : inline at::Tensor Tensor::roll_symint(c10::SymIntArrayRef shifts, at::IntArrayRef dims) const {</span>
<span id="L3789"><span class="lineNum">    3789</span>              :     return at::_ops::roll::call(const_cast&lt;Tensor&amp;&gt;(*this), shifts, dims);</span>
<span id="L3790"><span class="lineNum">    3790</span>              : }</span>
<span id="L3791"><span class="lineNum">    3791</span>              : </span>
<span id="L3792"><span class="lineNum">    3792</span>              : // aten::rot90(Tensor self, int k=1, int[] dims=[0,1]) -&gt; Tensor</span>
<span id="L3793"><span class="lineNum">    3793</span>              : inline at::Tensor Tensor::rot90(int64_t k, at::IntArrayRef dims) const {</span>
<span id="L3794"><span class="lineNum">    3794</span>              :     return at::_ops::rot90::call(const_cast&lt;Tensor&amp;&gt;(*this), k, dims);</span>
<span id="L3795"><span class="lineNum">    3795</span>              : }</span>
<span id="L3796"><span class="lineNum">    3796</span>              : </span>
<span id="L3797"><span class="lineNum">    3797</span>              : // aten::_nested_tensor_size(Tensor self) -&gt; Tensor</span>
<span id="L3798"><span class="lineNum">    3798</span>              : inline at::Tensor Tensor::_nested_tensor_size() const {</span>
<span id="L3799"><span class="lineNum">    3799</span>              :     return at::_ops::_nested_tensor_size::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3800"><span class="lineNum">    3800</span>              : }</span>
<span id="L3801"><span class="lineNum">    3801</span>              : </span>
<span id="L3802"><span class="lineNum">    3802</span>              : // aten::_nested_tensor_strides(Tensor self) -&gt; Tensor</span>
<span id="L3803"><span class="lineNum">    3803</span>              : inline at::Tensor Tensor::_nested_tensor_strides() const {</span>
<span id="L3804"><span class="lineNum">    3804</span>              :     return at::_ops::_nested_tensor_strides::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3805"><span class="lineNum">    3805</span>              : }</span>
<span id="L3806"><span class="lineNum">    3806</span>              : </span>
<span id="L3807"><span class="lineNum">    3807</span>              : // aten::_nested_tensor_storage_offsets(Tensor self) -&gt; Tensor</span>
<span id="L3808"><span class="lineNum">    3808</span>              : inline at::Tensor Tensor::_nested_tensor_storage_offsets() const {</span>
<span id="L3809"><span class="lineNum">    3809</span>              :     return at::_ops::_nested_tensor_storage_offsets::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3810"><span class="lineNum">    3810</span>              : }</span>
<span id="L3811"><span class="lineNum">    3811</span>              : </span>
<span id="L3812"><span class="lineNum">    3812</span>              : // aten::trunc(Tensor self) -&gt; Tensor</span>
<span id="L3813"><span class="lineNum">    3813</span>              : inline at::Tensor Tensor::trunc() const {</span>
<span id="L3814"><span class="lineNum">    3814</span>              :     return at::_ops::trunc::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3815"><span class="lineNum">    3815</span>              : }</span>
<span id="L3816"><span class="lineNum">    3816</span>              : </span>
<span id="L3817"><span class="lineNum">    3817</span>              : // aten::trunc_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L3818"><span class="lineNum">    3818</span>              : inline at::Tensor &amp; Tensor::trunc_() const {</span>
<span id="L3819"><span class="lineNum">    3819</span>              :     return at::_ops::trunc_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3820"><span class="lineNum">    3820</span>              : }</span>
<span id="L3821"><span class="lineNum">    3821</span>              : </span>
<span id="L3822"><span class="lineNum">    3822</span>              : // aten::fix(Tensor self) -&gt; Tensor</span>
<span id="L3823"><span class="lineNum">    3823</span>              : inline at::Tensor Tensor::fix() const {</span>
<span id="L3824"><span class="lineNum">    3824</span>              :     return at::_ops::fix::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3825"><span class="lineNum">    3825</span>              : }</span>
<span id="L3826"><span class="lineNum">    3826</span>              : </span>
<span id="L3827"><span class="lineNum">    3827</span>              : // aten::fix_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L3828"><span class="lineNum">    3828</span>              : inline at::Tensor &amp; Tensor::fix_() const {</span>
<span id="L3829"><span class="lineNum">    3829</span>              :     return at::_ops::fix_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3830"><span class="lineNum">    3830</span>              : }</span>
<span id="L3831"><span class="lineNum">    3831</span>              : </span>
<span id="L3832"><span class="lineNum">    3832</span>              : // aten::type_as(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L3833"><span class="lineNum">    3833</span>              : inline at::Tensor Tensor::type_as(const at::Tensor &amp; other) const {</span>
<span id="L3834"><span class="lineNum">    3834</span>              :     return at::_ops::type_as::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L3835"><span class="lineNum">    3835</span>              : }</span>
<span id="L3836"><span class="lineNum">    3836</span>              : </span>
<span id="L3837"><span class="lineNum">    3837</span>              : // aten::unsqueeze(Tensor(a) self, int dim) -&gt; Tensor(a)</span>
<span id="L3838"><span class="lineNum">    3838</span>              : inline at::Tensor Tensor::unsqueeze(int64_t dim) const {</span>
<span id="L3839"><span class="lineNum">    3839</span>              :     return at::_ops::unsqueeze::call(const_cast&lt;Tensor&amp;&gt;(*this), dim);</span>
<span id="L3840"><span class="lineNum">    3840</span>              : }</span>
<span id="L3841"><span class="lineNum">    3841</span>              : </span>
<span id="L3842"><span class="lineNum">    3842</span>              : // aten::unsqueeze_(Tensor(a!) self, int dim) -&gt; Tensor(a!)</span>
<span id="L3843"><span class="lineNum">    3843</span>              : inline at::Tensor &amp; Tensor::unsqueeze_(int64_t dim) const {</span>
<span id="L3844"><span class="lineNum">    3844</span>              :     return at::_ops::unsqueeze_::call(const_cast&lt;Tensor&amp;&gt;(*this), dim);</span>
<span id="L3845"><span class="lineNum">    3845</span>              : }</span>
<span id="L3846"><span class="lineNum">    3846</span>              : </span>
<span id="L3847"><span class="lineNum">    3847</span>              : // aten::var(Tensor self, bool unbiased=True) -&gt; Tensor</span>
<span id="L3848"><span class="lineNum">    3848</span>              : inline at::Tensor Tensor::var(bool unbiased) const {</span>
<span id="L3849"><span class="lineNum">    3849</span>              :     return at::_ops::var::call(const_cast&lt;Tensor&amp;&gt;(*this), unbiased);</span>
<span id="L3850"><span class="lineNum">    3850</span>              : }</span>
<span id="L3851"><span class="lineNum">    3851</span>              : </span>
<span id="L3852"><span class="lineNum">    3852</span>              : // aten::var.dim(Tensor self, int[1]? dim, bool unbiased=True, bool keepdim=False) -&gt; Tensor</span>
<span id="L3853"><span class="lineNum">    3853</span>              : inline at::Tensor Tensor::var(at::OptionalIntArrayRef dim, bool unbiased, bool keepdim) const {</span>
<span id="L3854"><span class="lineNum">    3854</span>              :     return at::_ops::var_dim::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, unbiased, keepdim);</span>
<span id="L3855"><span class="lineNum">    3855</span>              : }</span>
<span id="L3856"><span class="lineNum">    3856</span>              : </span>
<span id="L3857"><span class="lineNum">    3857</span>              : // aten::var.correction(Tensor self, int[1]? dim=None, *, Scalar? correction=None, bool keepdim=False) -&gt; Tensor</span>
<span id="L3858"><span class="lineNum">    3858</span>              : inline at::Tensor Tensor::var(at::OptionalIntArrayRef dim, const ::std::optional&lt;at::Scalar&gt; &amp; correction, bool keepdim) const {</span>
<span id="L3859"><span class="lineNum">    3859</span>              :     return at::_ops::var_correction::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, correction, keepdim);</span>
<span id="L3860"><span class="lineNum">    3860</span>              : }</span>
<span id="L3861"><span class="lineNum">    3861</span>              : </span>
<span id="L3862"><span class="lineNum">    3862</span>              : // aten::var.names_dim(Tensor self, Dimname[1] dim, bool unbiased=True, bool keepdim=False) -&gt; Tensor</span>
<span id="L3863"><span class="lineNum">    3863</span>              : inline at::Tensor Tensor::var(at::DimnameList dim, bool unbiased, bool keepdim) const {</span>
<span id="L3864"><span class="lineNum">    3864</span>              :     return at::_ops::var_names_dim::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, unbiased, keepdim);</span>
<span id="L3865"><span class="lineNum">    3865</span>              : }</span>
<span id="L3866"><span class="lineNum">    3866</span>              : </span>
<span id="L3867"><span class="lineNum">    3867</span>              : // aten::var.correction_names(Tensor self, Dimname[1] dim, *, Scalar? correction=None, bool keepdim=False) -&gt; Tensor</span>
<span id="L3868"><span class="lineNum">    3868</span>              : inline at::Tensor Tensor::var(at::DimnameList dim, const ::std::optional&lt;at::Scalar&gt; &amp; correction, bool keepdim) const {</span>
<span id="L3869"><span class="lineNum">    3869</span>              :     return at::_ops::var_correction_names::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, correction, keepdim);</span>
<span id="L3870"><span class="lineNum">    3870</span>              : }</span>
<span id="L3871"><span class="lineNum">    3871</span>              : </span>
<span id="L3872"><span class="lineNum">    3872</span>              : // aten::view_as(Tensor(a) self, Tensor other) -&gt; Tensor(a)</span>
<span id="L3873"><span class="lineNum">    3873</span>              : inline at::Tensor Tensor::view_as(const at::Tensor &amp; other) const {</span>
<span id="L3874"><span class="lineNum">    3874</span>              :     return at::_ops::view_as::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L3875"><span class="lineNum">    3875</span>              : }</span>
<span id="L3876"><span class="lineNum">    3876</span>              : </span>
<span id="L3877"><span class="lineNum">    3877</span>              : // aten::where.self(Tensor condition, Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L3878"><span class="lineNum">    3878</span>              : inline at::Tensor Tensor::where(const at::Tensor &amp; condition, const at::Tensor &amp; other) const {</span>
<span id="L3879"><span class="lineNum">    3879</span>              :     return at::_ops::where_self::call(condition, const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L3880"><span class="lineNum">    3880</span>              : }</span>
<span id="L3881"><span class="lineNum">    3881</span>              : </span>
<span id="L3882"><span class="lineNum">    3882</span>              : // aten::where.ScalarOther(Tensor condition, Tensor self, Scalar other) -&gt; Tensor</span>
<span id="L3883"><span class="lineNum">    3883</span>              : inline at::Tensor Tensor::where(const at::Tensor &amp; condition, const at::Scalar &amp; other) const {</span>
<span id="L3884"><span class="lineNum">    3884</span>              :     return at::_ops::where_ScalarOther::call(condition, const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L3885"><span class="lineNum">    3885</span>              : }</span>
<span id="L3886"><span class="lineNum">    3886</span>              : </span>
<span id="L3887"><span class="lineNum">    3887</span>              : // aten::norm.ScalarOpt_dtype(Tensor self, Scalar? p, *, ScalarType dtype) -&gt; Tensor</span>
<span id="L3888"><span class="lineNum">    3888</span>              : inline at::Tensor Tensor::norm(const ::std::optional&lt;at::Scalar&gt; &amp; p, at::ScalarType dtype) const {</span>
<span id="L3889"><span class="lineNum">    3889</span>              :     return at::_ops::norm_ScalarOpt_dtype::call(const_cast&lt;Tensor&amp;&gt;(*this), p, dtype);</span>
<span id="L3890"><span class="lineNum">    3890</span>              : }</span>
<span id="L3891"><span class="lineNum">    3891</span>              : </span>
<span id="L3892"><span class="lineNum">    3892</span>              : // aten::norm.Scalar(Tensor self, Scalar p=2) -&gt; Tensor</span>
<span id="L3893"><span class="lineNum">    3893</span>              : inline at::Tensor Tensor::norm(const at::Scalar &amp; p) const {</span>
<span id="L3894"><span class="lineNum">    3894</span>              :     return at::_ops::norm_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), p);</span>
<span id="L3895"><span class="lineNum">    3895</span>              : }</span>
<span id="L3896"><span class="lineNum">    3896</span>              : </span>
<span id="L3897"><span class="lineNum">    3897</span>              : // aten::norm.ScalarOpt_dim_dtype(Tensor self, Scalar? p, int[1] dim, bool keepdim, *, ScalarType dtype) -&gt; Tensor</span>
<span id="L3898"><span class="lineNum">    3898</span>              : inline at::Tensor Tensor::norm(const ::std::optional&lt;at::Scalar&gt; &amp; p, at::IntArrayRef dim, bool keepdim, at::ScalarType dtype) const {</span>
<span id="L3899"><span class="lineNum">    3899</span>              :     return at::_ops::norm_ScalarOpt_dim_dtype::call(const_cast&lt;Tensor&amp;&gt;(*this), p, dim, keepdim, dtype);</span>
<span id="L3900"><span class="lineNum">    3900</span>              : }</span>
<span id="L3901"><span class="lineNum">    3901</span>              : </span>
<span id="L3902"><span class="lineNum">    3902</span>              : // aten::norm.ScalarOpt_dim(Tensor self, Scalar? p, int[1] dim, bool keepdim=False) -&gt; Tensor</span>
<span id="L3903"><span class="lineNum">    3903</span>              : inline at::Tensor Tensor::norm(const ::std::optional&lt;at::Scalar&gt; &amp; p, at::IntArrayRef dim, bool keepdim) const {</span>
<span id="L3904"><span class="lineNum">    3904</span>              :     return at::_ops::norm_ScalarOpt_dim::call(const_cast&lt;Tensor&amp;&gt;(*this), p, dim, keepdim);</span>
<span id="L3905"><span class="lineNum">    3905</span>              : }</span>
<span id="L3906"><span class="lineNum">    3906</span>              : </span>
<span id="L3907"><span class="lineNum">    3907</span>              : // aten::norm.names_ScalarOpt_dim_dtype(Tensor self, Scalar? p, Dimname[1] dim, bool keepdim, *, ScalarType dtype) -&gt; Tensor</span>
<span id="L3908"><span class="lineNum">    3908</span>              : inline at::Tensor Tensor::norm(const ::std::optional&lt;at::Scalar&gt; &amp; p, at::DimnameList dim, bool keepdim, at::ScalarType dtype) const {</span>
<span id="L3909"><span class="lineNum">    3909</span>              :     return at::_ops::norm_names_ScalarOpt_dim_dtype::call(const_cast&lt;Tensor&amp;&gt;(*this), p, dim, keepdim, dtype);</span>
<span id="L3910"><span class="lineNum">    3910</span>              : }</span>
<span id="L3911"><span class="lineNum">    3911</span>              : </span>
<span id="L3912"><span class="lineNum">    3912</span>              : // aten::norm.names_ScalarOpt_dim(Tensor self, Scalar? p, Dimname[1] dim, bool keepdim=False) -&gt; Tensor</span>
<span id="L3913"><span class="lineNum">    3913</span>              : inline at::Tensor Tensor::norm(const ::std::optional&lt;at::Scalar&gt; &amp; p, at::DimnameList dim, bool keepdim) const {</span>
<span id="L3914"><span class="lineNum">    3914</span>              :     return at::_ops::norm_names_ScalarOpt_dim::call(const_cast&lt;Tensor&amp;&gt;(*this), p, dim, keepdim);</span>
<span id="L3915"><span class="lineNum">    3915</span>              : }</span>
<span id="L3916"><span class="lineNum">    3916</span>              : </span>
<span id="L3917"><span class="lineNum">    3917</span>              : // aten::frexp.Tensor(Tensor self) -&gt; (Tensor mantissa, Tensor exponent)</span>
<span id="L3918"><span class="lineNum">    3918</span>              : inline ::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::frexp() const {</span>
<span id="L3919"><span class="lineNum">    3919</span>              :     return at::_ops::frexp_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3920"><span class="lineNum">    3920</span>              : }</span>
<span id="L3921"><span class="lineNum">    3921</span>              : </span>
<span id="L3922"><span class="lineNum">    3922</span>              : // aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -&gt; Tensor</span>
<span id="L3923"><span class="lineNum">    3923</span>              : inline at::Tensor Tensor::clone(::std::optional&lt;at::MemoryFormat&gt; memory_format) const {</span>
<span id="L3924"><span class="lineNum">    3924</span>              :     return at::_ops::clone::call(const_cast&lt;Tensor&amp;&gt;(*this), memory_format);</span>
<span id="L3925"><span class="lineNum">    3925</span>              : }</span>
<span id="L3926"><span class="lineNum">    3926</span>              : </span>
<span id="L3927"><span class="lineNum">    3927</span>              : // aten::positive(Tensor(a) self) -&gt; Tensor(a)</span>
<span id="L3928"><span class="lineNum">    3928</span>              : inline at::Tensor Tensor::positive() const {</span>
<span id="L3929"><span class="lineNum">    3929</span>              :     return at::_ops::positive::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3930"><span class="lineNum">    3930</span>              : }</span>
<span id="L3931"><span class="lineNum">    3931</span>              : </span>
<span id="L3932"><span class="lineNum">    3932</span>              : // aten::resize_as_(Tensor(a!) self, Tensor the_template, *, MemoryFormat? memory_format=None) -&gt; Tensor(a!)</span>
<span id="L3933"><span class="lineNum">    3933</span>              : inline const at::Tensor &amp; Tensor::resize_as_(const at::Tensor &amp; the_template, ::std::optional&lt;at::MemoryFormat&gt; memory_format) const {</span>
<span id="L3934"><span class="lineNum">    3934</span>              :     return at::_ops::resize_as_::call(const_cast&lt;Tensor&amp;&gt;(*this), the_template, memory_format);</span>
<span id="L3935"><span class="lineNum">    3935</span>              : }</span>
<span id="L3936"><span class="lineNum">    3936</span>              : </span>
<span id="L3937"><span class="lineNum">    3937</span>              : // aten::resize_as_sparse_(Tensor(a!) self, Tensor the_template) -&gt; Tensor(a!)</span>
<span id="L3938"><span class="lineNum">    3938</span>              : inline const at::Tensor &amp; Tensor::resize_as_sparse_(const at::Tensor &amp; the_template) const {</span>
<span id="L3939"><span class="lineNum">    3939</span>              :     return at::_ops::resize_as_sparse_::call(const_cast&lt;Tensor&amp;&gt;(*this), the_template);</span>
<span id="L3940"><span class="lineNum">    3940</span>              : }</span>
<span id="L3941"><span class="lineNum">    3941</span>              : </span>
<span id="L3942"><span class="lineNum">    3942</span>              : // aten::zero_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L3943"><span class="lineNum">    3943</span>              : inline at::Tensor &amp; Tensor::zero_() const {</span>
<span id="L3944"><span class="lineNum">    3944</span>              :     return at::_ops::zero_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L3945"><span class="lineNum">    3945</span>              : }</span>
<span id="L3946"><span class="lineNum">    3946</span>              : </span>
<span id="L3947"><span class="lineNum">    3947</span>              : // aten::sub.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -&gt; Tensor</span>
<span id="L3948"><span class="lineNum">    3948</span>              : inline at::Tensor Tensor::sub(const at::Tensor &amp; other, const at::Scalar &amp; alpha) const {</span>
<span id="L3949"><span class="lineNum">    3949</span>              :     return at::_ops::sub_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other, alpha);</span>
<span id="L3950"><span class="lineNum">    3950</span>              : }</span>
<span id="L3951"><span class="lineNum">    3951</span>              : </span>
<span id="L3952"><span class="lineNum">    3952</span>              : // aten::sub_.Tensor(Tensor(a!) self, Tensor other, *, Scalar alpha=1) -&gt; Tensor(a!)</span>
<span id="L3953"><span class="lineNum">    3953</span>              : inline at::Tensor &amp; Tensor::sub_(const at::Tensor &amp; other, const at::Scalar &amp; alpha) const {</span>
<span id="L3954"><span class="lineNum">    3954</span>              :     return at::_ops::sub__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other, alpha);</span>
<span id="L3955"><span class="lineNum">    3955</span>              : }</span>
<span id="L3956"><span class="lineNum">    3956</span>              : </span>
<span id="L3957"><span class="lineNum">    3957</span>              : // aten::sub.Scalar(Tensor self, Scalar other, Scalar alpha=1) -&gt; Tensor</span>
<span id="L3958"><span class="lineNum">    3958</span>              : inline at::Tensor Tensor::sub(const at::Scalar &amp; other, const at::Scalar &amp; alpha) const {</span>
<span id="L3959"><span class="lineNum">    3959</span>              :     return at::_ops::sub_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other, alpha);</span>
<span id="L3960"><span class="lineNum">    3960</span>              : }</span>
<span id="L3961"><span class="lineNum">    3961</span>              : </span>
<span id="L3962"><span class="lineNum">    3962</span>              : // aten::sub_.Scalar(Tensor(a!) self, Scalar other, Scalar alpha=1) -&gt; Tensor(a!)</span>
<span id="L3963"><span class="lineNum">    3963</span>              : inline at::Tensor &amp; Tensor::sub_(const at::Scalar &amp; other, const at::Scalar &amp; alpha) const {</span>
<span id="L3964"><span class="lineNum">    3964</span>              :     return at::_ops::sub__Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other, alpha);</span>
<span id="L3965"><span class="lineNum">    3965</span>              : }</span>
<span id="L3966"><span class="lineNum">    3966</span>              : </span>
<span id="L3967"><span class="lineNum">    3967</span>              : // aten::subtract.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -&gt; Tensor</span>
<span id="L3968"><span class="lineNum">    3968</span>              : inline at::Tensor Tensor::subtract(const at::Tensor &amp; other, const at::Scalar &amp; alpha) const {</span>
<span id="L3969"><span class="lineNum">    3969</span>              :     return at::_ops::subtract_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other, alpha);</span>
<span id="L3970"><span class="lineNum">    3970</span>              : }</span>
<span id="L3971"><span class="lineNum">    3971</span>              : </span>
<span id="L3972"><span class="lineNum">    3972</span>              : // aten::subtract_.Tensor(Tensor(a!) self, Tensor other, *, Scalar alpha=1) -&gt; Tensor(a!)</span>
<span id="L3973"><span class="lineNum">    3973</span>              : inline at::Tensor &amp; Tensor::subtract_(const at::Tensor &amp; other, const at::Scalar &amp; alpha) const {</span>
<span id="L3974"><span class="lineNum">    3974</span>              :     return at::_ops::subtract__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other, alpha);</span>
<span id="L3975"><span class="lineNum">    3975</span>              : }</span>
<span id="L3976"><span class="lineNum">    3976</span>              : </span>
<span id="L3977"><span class="lineNum">    3977</span>              : // aten::subtract.Scalar(Tensor self, Scalar other, Scalar alpha=1) -&gt; Tensor</span>
<span id="L3978"><span class="lineNum">    3978</span>              : inline at::Tensor Tensor::subtract(const at::Scalar &amp; other, const at::Scalar &amp; alpha) const {</span>
<span id="L3979"><span class="lineNum">    3979</span>              :     return at::_ops::subtract_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other, alpha);</span>
<span id="L3980"><span class="lineNum">    3980</span>              : }</span>
<span id="L3981"><span class="lineNum">    3981</span>              : </span>
<span id="L3982"><span class="lineNum">    3982</span>              : // aten::subtract_.Scalar(Tensor(a!) self, Scalar other, Scalar alpha=1) -&gt; Tensor(a!)</span>
<span id="L3983"><span class="lineNum">    3983</span>              : inline at::Tensor &amp; Tensor::subtract_(const at::Scalar &amp; other, const at::Scalar &amp; alpha) const {</span>
<span id="L3984"><span class="lineNum">    3984</span>              :     return at::_ops::subtract__Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other, alpha);</span>
<span id="L3985"><span class="lineNum">    3985</span>              : }</span>
<span id="L3986"><span class="lineNum">    3986</span>              : </span>
<span id="L3987"><span class="lineNum">    3987</span>              : // aten::heaviside(Tensor self, Tensor values) -&gt; Tensor</span>
<span id="L3988"><span class="lineNum">    3988</span>              : inline at::Tensor Tensor::heaviside(const at::Tensor &amp; values) const {</span>
<span id="L3989"><span class="lineNum">    3989</span>              :     return at::_ops::heaviside::call(const_cast&lt;Tensor&amp;&gt;(*this), values);</span>
<span id="L3990"><span class="lineNum">    3990</span>              : }</span>
<span id="L3991"><span class="lineNum">    3991</span>              : </span>
<span id="L3992"><span class="lineNum">    3992</span>              : // aten::heaviside_(Tensor(a!) self, Tensor values) -&gt; Tensor(a!)</span>
<span id="L3993"><span class="lineNum">    3993</span>              : inline at::Tensor &amp; Tensor::heaviside_(const at::Tensor &amp; values) const {</span>
<span id="L3994"><span class="lineNum">    3994</span>              :     return at::_ops::heaviside_::call(const_cast&lt;Tensor&amp;&gt;(*this), values);</span>
<span id="L3995"><span class="lineNum">    3995</span>              : }</span>
<span id="L3996"><span class="lineNum">    3996</span>              : </span>
<span id="L3997"><span class="lineNum">    3997</span>              : // aten::addmm(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor</span>
<span id="L3998"><span class="lineNum">    3998</span>              : inline at::Tensor Tensor::addmm(const at::Tensor &amp; mat1, const at::Tensor &amp; mat2, const at::Scalar &amp; beta, const at::Scalar &amp; alpha) const {</span>
<span id="L3999"><span class="lineNum">    3999</span>              :     return at::_ops::addmm::call(const_cast&lt;Tensor&amp;&gt;(*this), mat1, mat2, beta, alpha);</span>
<span id="L4000"><span class="lineNum">    4000</span>              : }</span>
<span id="L4001"><span class="lineNum">    4001</span>              : </span>
<span id="L4002"><span class="lineNum">    4002</span>              : // aten::addmm_(Tensor(a!) self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor(a!)</span>
<span id="L4003"><span class="lineNum">    4003</span>              : inline at::Tensor &amp; Tensor::addmm_(const at::Tensor &amp; mat1, const at::Tensor &amp; mat2, const at::Scalar &amp; beta, const at::Scalar &amp; alpha) const {</span>
<span id="L4004"><span class="lineNum">    4004</span>              :     return at::_ops::addmm_::call(const_cast&lt;Tensor&amp;&gt;(*this), mat1, mat2, beta, alpha);</span>
<span id="L4005"><span class="lineNum">    4005</span>              : }</span>
<span id="L4006"><span class="lineNum">    4006</span>              : </span>
<span id="L4007"><span class="lineNum">    4007</span>              : // aten::_addmm_activation(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1, bool use_gelu=False) -&gt; Tensor</span>
<span id="L4008"><span class="lineNum">    4008</span>              : inline at::Tensor Tensor::_addmm_activation(const at::Tensor &amp; mat1, const at::Tensor &amp; mat2, const at::Scalar &amp; beta, const at::Scalar &amp; alpha, bool use_gelu) const {</span>
<span id="L4009"><span class="lineNum">    4009</span>              :     return at::_ops::_addmm_activation::call(const_cast&lt;Tensor&amp;&gt;(*this), mat1, mat2, beta, alpha, use_gelu);</span>
<span id="L4010"><span class="lineNum">    4010</span>              : }</span>
<span id="L4011"><span class="lineNum">    4011</span>              : </span>
<span id="L4012"><span class="lineNum">    4012</span>              : // aten::sparse_resize_(Tensor(a!) self, int[] size, int sparse_dim, int dense_dim) -&gt; Tensor(a!)</span>
<span id="L4013"><span class="lineNum">    4013</span>              : inline const at::Tensor &amp; Tensor::sparse_resize_(at::IntArrayRef size, int64_t sparse_dim, int64_t dense_dim) const {</span>
<span id="L4014"><span class="lineNum">    4014</span>              :     return at::_ops::sparse_resize_::call(const_cast&lt;Tensor&amp;&gt;(*this), size, sparse_dim, dense_dim);</span>
<span id="L4015"><span class="lineNum">    4015</span>              : }</span>
<span id="L4016"><span class="lineNum">    4016</span>              : </span>
<span id="L4017"><span class="lineNum">    4017</span>              : // aten::sparse_resize_and_clear_(Tensor(a!) self, int[] size, int sparse_dim, int dense_dim) -&gt; Tensor(a!)</span>
<span id="L4018"><span class="lineNum">    4018</span>              : inline const at::Tensor &amp; Tensor::sparse_resize_and_clear_(at::IntArrayRef size, int64_t sparse_dim, int64_t dense_dim) const {</span>
<span id="L4019"><span class="lineNum">    4019</span>              :     return at::_ops::sparse_resize_and_clear_::call(const_cast&lt;Tensor&amp;&gt;(*this), size, sparse_dim, dense_dim);</span>
<span id="L4020"><span class="lineNum">    4020</span>              : }</span>
<span id="L4021"><span class="lineNum">    4021</span>              : </span>
<span id="L4022"><span class="lineNum">    4022</span>              : // aten::sparse_mask(Tensor self, Tensor mask) -&gt; Tensor</span>
<span id="L4023"><span class="lineNum">    4023</span>              : inline at::Tensor Tensor::sparse_mask(const at::Tensor &amp; mask) const {</span>
<span id="L4024"><span class="lineNum">    4024</span>              :     return at::_ops::sparse_mask::call(const_cast&lt;Tensor&amp;&gt;(*this), mask);</span>
<span id="L4025"><span class="lineNum">    4025</span>              : }</span>
<span id="L4026"><span class="lineNum">    4026</span>              : </span>
<span id="L4027"><span class="lineNum">    4027</span>              : // aten::_sparse_mask_projection(Tensor self, Tensor mask, bool accumulate_matches=False) -&gt; Tensor</span>
<span id="L4028"><span class="lineNum">    4028</span>              : inline at::Tensor Tensor::_sparse_mask_projection(const at::Tensor &amp; mask, bool accumulate_matches) const {</span>
<span id="L4029"><span class="lineNum">    4029</span>              :     return at::_ops::_sparse_mask_projection::call(const_cast&lt;Tensor&amp;&gt;(*this), mask, accumulate_matches);</span>
<span id="L4030"><span class="lineNum">    4030</span>              : }</span>
<span id="L4031"><span class="lineNum">    4031</span>              : </span>
<span id="L4032"><span class="lineNum">    4032</span>              : // aten::to_dense(Tensor self, ScalarType? dtype=None, *, bool? masked_grad=None) -&gt; Tensor</span>
<span id="L4033"><span class="lineNum">    4033</span>              : inline at::Tensor Tensor::to_dense(::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;bool&gt; masked_grad) const {</span>
<span id="L4034"><span class="lineNum">    4034</span>              :     return at::_ops::to_dense::call(const_cast&lt;Tensor&amp;&gt;(*this), dtype, masked_grad);</span>
<span id="L4035"><span class="lineNum">    4035</span>              : }</span>
<span id="L4036"><span class="lineNum">    4036</span>              : </span>
<span id="L4037"><span class="lineNum">    4037</span>              : // aten::_to_dense(Tensor self, ScalarType? dtype=None, bool? masked_grad=None) -&gt; Tensor</span>
<span id="L4038"><span class="lineNum">    4038</span>              : inline at::Tensor Tensor::_to_dense(::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;bool&gt; masked_grad) const {</span>
<span id="L4039"><span class="lineNum">    4039</span>              :     return at::_ops::_to_dense::call(const_cast&lt;Tensor&amp;&gt;(*this), dtype, masked_grad);</span>
<span id="L4040"><span class="lineNum">    4040</span>              : }</span>
<span id="L4041"><span class="lineNum">    4041</span>              : </span>
<span id="L4042"><span class="lineNum">    4042</span>              : // aten::sparse_dim(Tensor self) -&gt; int</span>
<span id="L4043"><span class="lineNum">    4043</span>              : inline int64_t Tensor::sparse_dim() const {</span>
<span id="L4044"><span class="lineNum">    4044</span>              :     return at::_ops::sparse_dim::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L4045"><span class="lineNum">    4045</span>              : }</span>
<span id="L4046"><span class="lineNum">    4046</span>              : </span>
<span id="L4047"><span class="lineNum">    4047</span>              : // aten::_dimI(Tensor self) -&gt; int</span>
<span id="L4048"><span class="lineNum">    4048</span>              : inline int64_t Tensor::_dimI() const {</span>
<span id="L4049"><span class="lineNum">    4049</span>              :     return at::_ops::_dimI::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L4050"><span class="lineNum">    4050</span>              : }</span>
<span id="L4051"><span class="lineNum">    4051</span>              : </span>
<span id="L4052"><span class="lineNum">    4052</span>              : // aten::dense_dim(Tensor self) -&gt; int</span>
<span id="L4053"><span class="lineNum">    4053</span>              : inline int64_t Tensor::dense_dim() const {</span>
<span id="L4054"><span class="lineNum">    4054</span>              :     return at::_ops::dense_dim::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L4055"><span class="lineNum">    4055</span>              : }</span>
<span id="L4056"><span class="lineNum">    4056</span>              : </span>
<span id="L4057"><span class="lineNum">    4057</span>              : // aten::_dimV(Tensor self) -&gt; int</span>
<span id="L4058"><span class="lineNum">    4058</span>              : inline int64_t Tensor::_dimV() const {</span>
<span id="L4059"><span class="lineNum">    4059</span>              :     return at::_ops::_dimV::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L4060"><span class="lineNum">    4060</span>              : }</span>
<span id="L4061"><span class="lineNum">    4061</span>              : </span>
<span id="L4062"><span class="lineNum">    4062</span>              : // aten::_nnz(Tensor self) -&gt; int</span>
<span id="L4063"><span class="lineNum">    4063</span>              : inline int64_t Tensor::_nnz() const {</span>
<span id="L4064"><span class="lineNum">    4064</span>              :     return at::_ops::_nnz::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L4065"><span class="lineNum">    4065</span>              : }</span>
<span id="L4066"><span class="lineNum">    4066</span>              : </span>
<span id="L4067"><span class="lineNum">    4067</span>              : // aten::coalesce(Tensor(a) self) -&gt; Tensor(a)</span>
<span id="L4068"><span class="lineNum">    4068</span>              : inline at::Tensor Tensor::coalesce() const {</span>
<span id="L4069"><span class="lineNum">    4069</span>              :     return at::_ops::coalesce::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L4070"><span class="lineNum">    4070</span>              : }</span>
<span id="L4071"><span class="lineNum">    4071</span>              : </span>
<span id="L4072"><span class="lineNum">    4072</span>              : // aten::is_coalesced(Tensor self) -&gt; bool</span>
<span id="L4073"><span class="lineNum">    4073</span>              : inline bool Tensor::is_coalesced() const {</span>
<span id="L4074"><span class="lineNum">    4074</span>              :     return at::_ops::is_coalesced::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L4075"><span class="lineNum">    4075</span>              : }</span>
<span id="L4076"><span class="lineNum">    4076</span>              : </span>
<span id="L4077"><span class="lineNum">    4077</span>              : // aten::_indices(Tensor(a) self) -&gt; Tensor(a)</span>
<span id="L4078"><span class="lineNum">    4078</span>              : inline at::Tensor Tensor::_indices() const {</span>
<span id="L4079"><span class="lineNum">    4079</span>              :     return at::_ops::_indices::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L4080"><span class="lineNum">    4080</span>              : }</span>
<span id="L4081"><span class="lineNum">    4081</span>              : </span>
<span id="L4082"><span class="lineNum">    4082</span>              : // aten::_values(Tensor(a) self) -&gt; Tensor(a)</span>
<span id="L4083"><span class="lineNum">    4083</span>              : inline at::Tensor Tensor::_values() const {</span>
<span id="L4084"><span class="lineNum">    4084</span>              :     return at::_ops::_values::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L4085"><span class="lineNum">    4085</span>              : }</span>
<span id="L4086"><span class="lineNum">    4086</span>              : </span>
<span id="L4087"><span class="lineNum">    4087</span>              : // aten::_coalesced_(Tensor(a!) self, bool coalesced) -&gt; Tensor(a!)</span>
<span id="L4088"><span class="lineNum">    4088</span>              : inline at::Tensor &amp; Tensor::_coalesced_(bool coalesced) const {</span>
<span id="L4089"><span class="lineNum">    4089</span>              :     return at::_ops::_coalesced_::call(const_cast&lt;Tensor&amp;&gt;(*this), coalesced);</span>
<span id="L4090"><span class="lineNum">    4090</span>              : }</span>
<span id="L4091"><span class="lineNum">    4091</span>              : </span>
<span id="L4092"><span class="lineNum">    4092</span>              : // aten::indices(Tensor(a) self) -&gt; Tensor(a)</span>
<span id="L4093"><span class="lineNum">    4093</span>              : inline at::Tensor Tensor::indices() const {</span>
<span id="L4094"><span class="lineNum">    4094</span>              :     return at::_ops::indices::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L4095"><span class="lineNum">    4095</span>              : }</span>
<span id="L4096"><span class="lineNum">    4096</span>              : </span>
<span id="L4097"><span class="lineNum">    4097</span>              : // aten::values(Tensor(a) self) -&gt; Tensor(a)</span>
<span id="L4098"><span class="lineNum">    4098</span>              : inline at::Tensor Tensor::values() const {</span>
<span id="L4099"><span class="lineNum">    4099</span>              :     return at::_ops::values::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L4100"><span class="lineNum">    4100</span>              : }</span>
<span id="L4101"><span class="lineNum">    4101</span>              : </span>
<span id="L4102"><span class="lineNum">    4102</span>              : // aten::crow_indices(Tensor(a) self) -&gt; Tensor(a)</span>
<span id="L4103"><span class="lineNum">    4103</span>              : inline at::Tensor Tensor::crow_indices() const {</span>
<span id="L4104"><span class="lineNum">    4104</span>              :     return at::_ops::crow_indices::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L4105"><span class="lineNum">    4105</span>              : }</span>
<span id="L4106"><span class="lineNum">    4106</span>              : </span>
<span id="L4107"><span class="lineNum">    4107</span>              : // aten::col_indices(Tensor(a) self) -&gt; Tensor(a)</span>
<span id="L4108"><span class="lineNum">    4108</span>              : inline at::Tensor Tensor::col_indices() const {</span>
<span id="L4109"><span class="lineNum">    4109</span>              :     return at::_ops::col_indices::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L4110"><span class="lineNum">    4110</span>              : }</span>
<span id="L4111"><span class="lineNum">    4111</span>              : </span>
<span id="L4112"><span class="lineNum">    4112</span>              : // aten::ccol_indices(Tensor(a) self) -&gt; Tensor(a)</span>
<span id="L4113"><span class="lineNum">    4113</span>              : inline at::Tensor Tensor::ccol_indices() const {</span>
<span id="L4114"><span class="lineNum">    4114</span>              :     return at::_ops::ccol_indices::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L4115"><span class="lineNum">    4115</span>              : }</span>
<span id="L4116"><span class="lineNum">    4116</span>              : </span>
<span id="L4117"><span class="lineNum">    4117</span>              : // aten::row_indices(Tensor(a) self) -&gt; Tensor(a)</span>
<span id="L4118"><span class="lineNum">    4118</span>              : inline at::Tensor Tensor::row_indices() const {</span>
<span id="L4119"><span class="lineNum">    4119</span>              :     return at::_ops::row_indices::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L4120"><span class="lineNum">    4120</span>              : }</span>
<span id="L4121"><span class="lineNum">    4121</span>              : </span>
<span id="L4122"><span class="lineNum">    4122</span>              : // aten::unbind.int(Tensor(a -&gt; *) self, int dim=0) -&gt; Tensor(a)[]</span>
<span id="L4123"><span class="lineNum">    4123</span>              : inline ::std::vector&lt;at::Tensor&gt; Tensor::unbind(int64_t dim) const {</span>
<span id="L4124"><span class="lineNum">    4124</span>              :     return at::_ops::unbind_int::call(const_cast&lt;Tensor&amp;&gt;(*this), dim);</span>
<span id="L4125"><span class="lineNum">    4125</span>              : }</span>
<span id="L4126"><span class="lineNum">    4126</span>              : </span>
<span id="L4127"><span class="lineNum">    4127</span>              : // aten::unbind.Dimname(Tensor(a -&gt; *) self, Dimname dim) -&gt; Tensor(a)[]</span>
<span id="L4128"><span class="lineNum">    4128</span>              : inline ::std::vector&lt;at::Tensor&gt; Tensor::unbind(at::Dimname dim) const {</span>
<span id="L4129"><span class="lineNum">    4129</span>              :     return at::_ops::unbind_Dimname::call(const_cast&lt;Tensor&amp;&gt;(*this), dim);</span>
<span id="L4130"><span class="lineNum">    4130</span>              : }</span>
<span id="L4131"><span class="lineNum">    4131</span>              : </span>
<span id="L4132"><span class="lineNum">    4132</span>              : // aten::to_sparse.sparse_dim(Tensor self, int sparse_dim) -&gt; Tensor</span>
<span id="L4133"><span class="lineNum">    4133</span>              : inline at::Tensor Tensor::to_sparse(int64_t sparse_dim) const {</span>
<span id="L4134"><span class="lineNum">    4134</span>              :     return at::_ops::to_sparse_sparse_dim::call(const_cast&lt;Tensor&amp;&gt;(*this), sparse_dim);</span>
<span id="L4135"><span class="lineNum">    4135</span>              : }</span>
<span id="L4136"><span class="lineNum">    4136</span>              : </span>
<span id="L4137"><span class="lineNum">    4137</span>              : // aten::_to_sparse.sparse_dim(Tensor self, int sparse_dim) -&gt; Tensor</span>
<span id="L4138"><span class="lineNum">    4138</span>              : inline at::Tensor Tensor::_to_sparse(int64_t sparse_dim) const {</span>
<span id="L4139"><span class="lineNum">    4139</span>              :     return at::_ops::_to_sparse_sparse_dim::call(const_cast&lt;Tensor&amp;&gt;(*this), sparse_dim);</span>
<span id="L4140"><span class="lineNum">    4140</span>              : }</span>
<span id="L4141"><span class="lineNum">    4141</span>              : </span>
<span id="L4142"><span class="lineNum">    4142</span>              : // aten::to_sparse(Tensor self, *, Layout? layout=None, int[2]? blocksize=None, int? dense_dim=None) -&gt; Tensor</span>
<span id="L4143"><span class="lineNum">    4143</span>              : inline at::Tensor Tensor::to_sparse(::std::optional&lt;at::Layout&gt; layout, at::OptionalIntArrayRef blocksize, ::std::optional&lt;int64_t&gt; dense_dim) const {</span>
<span id="L4144"><span class="lineNum">    4144</span>              :     return at::_ops::to_sparse::call(const_cast&lt;Tensor&amp;&gt;(*this), layout, blocksize, dense_dim);</span>
<span id="L4145"><span class="lineNum">    4145</span>              : }</span>
<span id="L4146"><span class="lineNum">    4146</span>              : </span>
<span id="L4147"><span class="lineNum">    4147</span>              : // aten::_to_sparse(Tensor self, *, Layout? layout=None, int[2]? blocksize=None, int? dense_dim=None) -&gt; Tensor</span>
<span id="L4148"><span class="lineNum">    4148</span>              : inline at::Tensor Tensor::_to_sparse(::std::optional&lt;at::Layout&gt; layout, at::OptionalIntArrayRef blocksize, ::std::optional&lt;int64_t&gt; dense_dim) const {</span>
<span id="L4149"><span class="lineNum">    4149</span>              :     return at::_ops::_to_sparse::call(const_cast&lt;Tensor&amp;&gt;(*this), layout, blocksize, dense_dim);</span>
<span id="L4150"><span class="lineNum">    4150</span>              : }</span>
<span id="L4151"><span class="lineNum">    4151</span>              : </span>
<span id="L4152"><span class="lineNum">    4152</span>              : // aten::to_sparse_csr(Tensor self, int? dense_dim=None) -&gt; Tensor</span>
<span id="L4153"><span class="lineNum">    4153</span>              : inline at::Tensor Tensor::to_sparse_csr(::std::optional&lt;int64_t&gt; dense_dim) const {</span>
<span id="L4154"><span class="lineNum">    4154</span>              :     return at::_ops::to_sparse_csr::call(const_cast&lt;Tensor&amp;&gt;(*this), dense_dim);</span>
<span id="L4155"><span class="lineNum">    4155</span>              : }</span>
<span id="L4156"><span class="lineNum">    4156</span>              : </span>
<span id="L4157"><span class="lineNum">    4157</span>              : // aten::_to_sparse_csr(Tensor self, int? dense_dim=None) -&gt; Tensor</span>
<span id="L4158"><span class="lineNum">    4158</span>              : inline at::Tensor Tensor::_to_sparse_csr(::std::optional&lt;int64_t&gt; dense_dim) const {</span>
<span id="L4159"><span class="lineNum">    4159</span>              :     return at::_ops::_to_sparse_csr::call(const_cast&lt;Tensor&amp;&gt;(*this), dense_dim);</span>
<span id="L4160"><span class="lineNum">    4160</span>              : }</span>
<span id="L4161"><span class="lineNum">    4161</span>              : </span>
<span id="L4162"><span class="lineNum">    4162</span>              : // aten::to_sparse_csc(Tensor self, int? dense_dim=None) -&gt; Tensor</span>
<span id="L4163"><span class="lineNum">    4163</span>              : inline at::Tensor Tensor::to_sparse_csc(::std::optional&lt;int64_t&gt; dense_dim) const {</span>
<span id="L4164"><span class="lineNum">    4164</span>              :     return at::_ops::to_sparse_csc::call(const_cast&lt;Tensor&amp;&gt;(*this), dense_dim);</span>
<span id="L4165"><span class="lineNum">    4165</span>              : }</span>
<span id="L4166"><span class="lineNum">    4166</span>              : </span>
<span id="L4167"><span class="lineNum">    4167</span>              : // aten::_to_sparse_csc(Tensor self, int? dense_dim=None) -&gt; Tensor</span>
<span id="L4168"><span class="lineNum">    4168</span>              : inline at::Tensor Tensor::_to_sparse_csc(::std::optional&lt;int64_t&gt; dense_dim) const {</span>
<span id="L4169"><span class="lineNum">    4169</span>              :     return at::_ops::_to_sparse_csc::call(const_cast&lt;Tensor&amp;&gt;(*this), dense_dim);</span>
<span id="L4170"><span class="lineNum">    4170</span>              : }</span>
<span id="L4171"><span class="lineNum">    4171</span>              : </span>
<span id="L4172"><span class="lineNum">    4172</span>              : // aten::to_sparse_bsr(Tensor self, int[2] blocksize, int? dense_dim=None) -&gt; Tensor</span>
<span id="L4173"><span class="lineNum">    4173</span>              : inline at::Tensor Tensor::to_sparse_bsr(at::IntArrayRef blocksize, ::std::optional&lt;int64_t&gt; dense_dim) const {</span>
<span id="L4174"><span class="lineNum">    4174</span>              :     return at::_ops::to_sparse_bsr::call(const_cast&lt;Tensor&amp;&gt;(*this), blocksize, dense_dim);</span>
<span id="L4175"><span class="lineNum">    4175</span>              : }</span>
<span id="L4176"><span class="lineNum">    4176</span>              : </span>
<span id="L4177"><span class="lineNum">    4177</span>              : // aten::_to_sparse_bsr(Tensor self, int[2] blocksize, int? dense_dim=None) -&gt; Tensor</span>
<span id="L4178"><span class="lineNum">    4178</span>              : inline at::Tensor Tensor::_to_sparse_bsr(at::IntArrayRef blocksize, ::std::optional&lt;int64_t&gt; dense_dim) const {</span>
<span id="L4179"><span class="lineNum">    4179</span>              :     return at::_ops::_to_sparse_bsr::call(const_cast&lt;Tensor&amp;&gt;(*this), blocksize, dense_dim);</span>
<span id="L4180"><span class="lineNum">    4180</span>              : }</span>
<span id="L4181"><span class="lineNum">    4181</span>              : </span>
<span id="L4182"><span class="lineNum">    4182</span>              : // aten::to_sparse_bsc(Tensor self, int[2] blocksize, int? dense_dim=None) -&gt; Tensor</span>
<span id="L4183"><span class="lineNum">    4183</span>              : inline at::Tensor Tensor::to_sparse_bsc(at::IntArrayRef blocksize, ::std::optional&lt;int64_t&gt; dense_dim) const {</span>
<span id="L4184"><span class="lineNum">    4184</span>              :     return at::_ops::to_sparse_bsc::call(const_cast&lt;Tensor&amp;&gt;(*this), blocksize, dense_dim);</span>
<span id="L4185"><span class="lineNum">    4185</span>              : }</span>
<span id="L4186"><span class="lineNum">    4186</span>              : </span>
<span id="L4187"><span class="lineNum">    4187</span>              : // aten::_to_sparse_bsc(Tensor self, int[2] blocksize, int? dense_dim=None) -&gt; Tensor</span>
<span id="L4188"><span class="lineNum">    4188</span>              : inline at::Tensor Tensor::_to_sparse_bsc(at::IntArrayRef blocksize, ::std::optional&lt;int64_t&gt; dense_dim) const {</span>
<span id="L4189"><span class="lineNum">    4189</span>              :     return at::_ops::_to_sparse_bsc::call(const_cast&lt;Tensor&amp;&gt;(*this), blocksize, dense_dim);</span>
<span id="L4190"><span class="lineNum">    4190</span>              : }</span>
<span id="L4191"><span class="lineNum">    4191</span>              : </span>
<span id="L4192"><span class="lineNum">    4192</span>              : // aten::to_mkldnn(Tensor self, ScalarType? dtype=None) -&gt; Tensor</span>
<span id="L4193"><span class="lineNum">    4193</span>              : inline at::Tensor Tensor::to_mkldnn(::std::optional&lt;at::ScalarType&gt; dtype) const {</span>
<span id="L4194"><span class="lineNum">    4194</span>              :     return at::_ops::to_mkldnn::call(const_cast&lt;Tensor&amp;&gt;(*this), dtype);</span>
<span id="L4195"><span class="lineNum">    4195</span>              : }</span>
<span id="L4196"><span class="lineNum">    4196</span>              : </span>
<span id="L4197"><span class="lineNum">    4197</span>              : // aten::dequantize.self(Tensor self) -&gt; Tensor</span>
<span id="L4198"><span class="lineNum">    4198</span>              : inline at::Tensor Tensor::dequantize() const {</span>
<span id="L4199"><span class="lineNum">    4199</span>              :     return at::_ops::dequantize_self::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L4200"><span class="lineNum">    4200</span>              : }</span>
<span id="L4201"><span class="lineNum">    4201</span>              : </span>
<span id="L4202"><span class="lineNum">    4202</span>              : // aten::q_scale(Tensor self) -&gt; float</span>
<span id="L4203"><span class="lineNum">    4203</span>              : inline double Tensor::q_scale() const {</span>
<span id="L4204"><span class="lineNum">    4204</span>              :     return at::_ops::q_scale::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L4205"><span class="lineNum">    4205</span>              : }</span>
<span id="L4206"><span class="lineNum">    4206</span>              : </span>
<span id="L4207"><span class="lineNum">    4207</span>              : // aten::q_zero_point(Tensor self) -&gt; int</span>
<span id="L4208"><span class="lineNum">    4208</span>              : inline int64_t Tensor::q_zero_point() const {</span>
<span id="L4209"><span class="lineNum">    4209</span>              :     return at::_ops::q_zero_point::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L4210"><span class="lineNum">    4210</span>              : }</span>
<span id="L4211"><span class="lineNum">    4211</span>              : </span>
<span id="L4212"><span class="lineNum">    4212</span>              : // aten::q_per_channel_scales(Tensor self) -&gt; Tensor</span>
<span id="L4213"><span class="lineNum">    4213</span>              : inline at::Tensor Tensor::q_per_channel_scales() const {</span>
<span id="L4214"><span class="lineNum">    4214</span>              :     return at::_ops::q_per_channel_scales::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L4215"><span class="lineNum">    4215</span>              : }</span>
<span id="L4216"><span class="lineNum">    4216</span>              : </span>
<span id="L4217"><span class="lineNum">    4217</span>              : // aten::q_per_channel_zero_points(Tensor self) -&gt; Tensor</span>
<span id="L4218"><span class="lineNum">    4218</span>              : inline at::Tensor Tensor::q_per_channel_zero_points() const {</span>
<span id="L4219"><span class="lineNum">    4219</span>              :     return at::_ops::q_per_channel_zero_points::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L4220"><span class="lineNum">    4220</span>              : }</span>
<span id="L4221"><span class="lineNum">    4221</span>              : </span>
<span id="L4222"><span class="lineNum">    4222</span>              : // aten::q_per_channel_axis(Tensor self) -&gt; int</span>
<span id="L4223"><span class="lineNum">    4223</span>              : inline int64_t Tensor::q_per_channel_axis() const {</span>
<span id="L4224"><span class="lineNum">    4224</span>              :     return at::_ops::q_per_channel_axis::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L4225"><span class="lineNum">    4225</span>              : }</span>
<span id="L4226"><span class="lineNum">    4226</span>              : </span>
<span id="L4227"><span class="lineNum">    4227</span>              : // aten::int_repr(Tensor self) -&gt; Tensor</span>
<span id="L4228"><span class="lineNum">    4228</span>              : inline at::Tensor Tensor::int_repr() const {</span>
<span id="L4229"><span class="lineNum">    4229</span>              :     return at::_ops::int_repr::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L4230"><span class="lineNum">    4230</span>              : }</span>
<span id="L4231"><span class="lineNum">    4231</span>              : </span>
<span id="L4232"><span class="lineNum">    4232</span>              : // aten::qscheme(Tensor self) -&gt; QScheme</span>
<span id="L4233"><span class="lineNum">    4233</span>              : inline at::QScheme Tensor::qscheme() const {</span>
<span id="L4234"><span class="lineNum">    4234</span>              :     return at::_ops::qscheme::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L4235"><span class="lineNum">    4235</span>              : }</span>
<span id="L4236"><span class="lineNum">    4236</span>              : </span>
<span id="L4237"><span class="lineNum">    4237</span>              : // aten::_autocast_to_reduced_precision(Tensor(a) self, bool cuda_enabled, bool cpu_enabled, ScalarType cuda_dtype, ScalarType cpu_dtype) -&gt; Tensor(a)</span>
<span id="L4238"><span class="lineNum">    4238</span>              : inline at::Tensor Tensor::_autocast_to_reduced_precision(bool cuda_enabled, bool cpu_enabled, at::ScalarType cuda_dtype, at::ScalarType cpu_dtype) const {</span>
<span id="L4239"><span class="lineNum">    4239</span>              :     return at::_ops::_autocast_to_reduced_precision::call(const_cast&lt;Tensor&amp;&gt;(*this), cuda_enabled, cpu_enabled, cuda_dtype, cpu_dtype);</span>
<span id="L4240"><span class="lineNum">    4240</span>              : }</span>
<span id="L4241"><span class="lineNum">    4241</span>              : </span>
<span id="L4242"><span class="lineNum">    4242</span>              : // aten::_autocast_to_full_precision(Tensor(a) self, bool cuda_enabled, bool cpu_enabled) -&gt; Tensor(a)</span>
<span id="L4243"><span class="lineNum">    4243</span>              : inline at::Tensor Tensor::_autocast_to_full_precision(bool cuda_enabled, bool cpu_enabled) const {</span>
<span id="L4244"><span class="lineNum">    4244</span>              :     return at::_ops::_autocast_to_full_precision::call(const_cast&lt;Tensor&amp;&gt;(*this), cuda_enabled, cpu_enabled);</span>
<span id="L4245"><span class="lineNum">    4245</span>              : }</span>
<span id="L4246"><span class="lineNum">    4246</span>              : </span>
<span id="L4247"><span class="lineNum">    4247</span>              : // aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -&gt; Tensor(a)</span>
<span id="L4248"><span class="lineNum">    4248</span>              : inline at::Tensor Tensor::to(at::TensorOptions options, bool non_blocking, bool copy, ::std::optional&lt;at::MemoryFormat&gt; memory_format) const {</span>
<span id="L4249"><span class="lineNum">    4249</span>              :     return at::_ops::to_dtype_layout::call(const_cast&lt;Tensor&amp;&gt;(*this), c10::optTypeMetaToScalarType(options.dtype_opt()), options.layout_opt(), options.device_opt(), options.pinned_memory_opt(), non_blocking, copy, c10::impl::check_tensor_options_and_extract_memory_format(options, memory_format));</span>
<span id="L4250"><span class="lineNum">    4250</span>              : }</span>
<span id="L4251"><span class="lineNum">    4251</span>              : </span>
<span id="L4252"><span class="lineNum">    4252</span>              : // aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -&gt; Tensor(a)</span>
<span id="L4253"><span class="lineNum">    4253</span>              : inline at::Tensor Tensor::to(::std::optional&lt;at::ScalarType&gt; dtype, ::std::optional&lt;at::Layout&gt; layout, ::std::optional&lt;at::Device&gt; device, ::std::optional&lt;bool&gt; pin_memory, bool non_blocking, bool copy, ::std::optional&lt;at::MemoryFormat&gt; memory_format) const {</span>
<span id="L4254"><span class="lineNum">    4254</span>              :     return at::_ops::to_dtype_layout::call(const_cast&lt;Tensor&amp;&gt;(*this), dtype, layout, device, pin_memory, non_blocking, copy, memory_format);</span>
<span id="L4255"><span class="lineNum">    4255</span>              : }</span>
<span id="L4256"><span class="lineNum">    4256</span>              : </span>
<span id="L4257"><span class="lineNum">    4257</span>              : // aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -&gt; Tensor(a)</span>
<span id="L4258"><span class="lineNum">    4258</span>              : inline at::Tensor Tensor::to(at::Device device, at::ScalarType dtype, bool non_blocking, bool copy, ::std::optional&lt;at::MemoryFormat&gt; memory_format) const {</span>
<span id="L4259"><span class="lineNum">    4259</span>              :     return at::_ops::to_device::call(const_cast&lt;Tensor&amp;&gt;(*this), device, dtype, non_blocking, copy, memory_format);</span>
<span id="L4260"><span class="lineNum">    4260</span>              : }</span>
<span id="L4261"><span class="lineNum">    4261</span>              : </span>
<span id="L4262"><span class="lineNum">    4262</span>              : // aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -&gt; Tensor(a)</span>
<span id="L4263"><span class="lineNum">    4263</span>              : inline at::Tensor Tensor::to(at::ScalarType dtype, bool non_blocking, bool copy, ::std::optional&lt;at::MemoryFormat&gt; memory_format) const {</span>
<span id="L4264"><span class="lineNum">    4264</span>              :     return at::_ops::to_dtype::call(const_cast&lt;Tensor&amp;&gt;(*this), dtype, non_blocking, copy, memory_format);</span>
<span id="L4265"><span class="lineNum">    4265</span>              : }</span>
<span id="L4266"><span class="lineNum">    4266</span>              : </span>
<span id="L4267"><span class="lineNum">    4267</span>              : // aten::to.other(Tensor(a) self, Tensor other, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -&gt; Tensor(a)</span>
<span id="L4268"><span class="lineNum">    4268</span>              : inline at::Tensor Tensor::to(const at::Tensor &amp; other, bool non_blocking, bool copy, ::std::optional&lt;at::MemoryFormat&gt; memory_format) const {</span>
<span id="L4269"><span class="lineNum">    4269</span>              :     return at::_ops::to_other::call(const_cast&lt;Tensor&amp;&gt;(*this), other, non_blocking, copy, memory_format);</span>
<span id="L4270"><span class="lineNum">    4270</span>              : }</span>
<span id="L4271"><span class="lineNum">    4271</span>              : </span>
<span id="L4272"><span class="lineNum">    4272</span>              : // aten::item(Tensor self) -&gt; Scalar</span>
<span id="L4273"><span class="lineNum">    4273</span>              : inline at::Scalar Tensor::item() const {</span>
<span id="L4274"><span class="lineNum">    4274</span>              :     return at::_ops::item::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L4275"><span class="lineNum">    4275</span>              : }</span>
<span id="L4276"><span class="lineNum">    4276</span>              : </span>
<span id="L4277"><span class="lineNum">    4277</span>              : // aten::set_.source_Storage(Tensor(a!) self, Storage source) -&gt; Tensor(a!)</span>
<span id="L4278"><span class="lineNum">    4278</span>              : inline at::Tensor &amp; Tensor::set_(at::Storage source) const {</span>
<span id="L4279"><span class="lineNum">    4279</span>              :     return at::_ops::set__source_Storage::call(const_cast&lt;Tensor&amp;&gt;(*this), source);</span>
<span id="L4280"><span class="lineNum">    4280</span>              : }</span>
<span id="L4281"><span class="lineNum">    4281</span>              : </span>
<span id="L4282"><span class="lineNum">    4282</span>              : // aten::set_.source_Storage_storage_offset(Tensor(a!) self, Storage source, SymInt storage_offset, SymInt[] size, SymInt[] stride=[]) -&gt; Tensor(a!)</span>
<span id="L4283"><span class="lineNum">    4283</span>              : inline at::Tensor &amp; Tensor::set_(at::Storage source, int64_t storage_offset, at::IntArrayRef size, at::IntArrayRef stride) const {</span>
<span id="L4284"><span class="lineNum">    4284</span>              :     return at::_ops::set__source_Storage_storage_offset::call(const_cast&lt;Tensor&amp;&gt;(*this), source, storage_offset, c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride));</span>
<span id="L4285"><span class="lineNum">    4285</span>              : }</span>
<span id="L4286"><span class="lineNum">    4286</span>              : </span>
<span id="L4287"><span class="lineNum">    4287</span>              : // aten::set_.source_Storage_storage_offset(Tensor(a!) self, Storage source, SymInt storage_offset, SymInt[] size, SymInt[] stride=[]) -&gt; Tensor(a!)</span>
<span id="L4288"><span class="lineNum">    4288</span>              : inline at::Tensor &amp; Tensor::set__symint(at::Storage source, c10::SymInt storage_offset, c10::SymIntArrayRef size, c10::SymIntArrayRef stride) const {</span>
<span id="L4289"><span class="lineNum">    4289</span>              :     return at::_ops::set__source_Storage_storage_offset::call(const_cast&lt;Tensor&amp;&gt;(*this), source, storage_offset, size, stride);</span>
<span id="L4290"><span class="lineNum">    4290</span>              : }</span>
<span id="L4291"><span class="lineNum">    4291</span>              : </span>
<span id="L4292"><span class="lineNum">    4292</span>              : // aten::set_.source_Tensor_storage_offset(Tensor(a!) self, Tensor source, SymInt storage_offset, SymInt[] size, SymInt[] stride=[]) -&gt; Tensor(a!)</span>
<span id="L4293"><span class="lineNum">    4293</span>              : inline at::Tensor &amp; Tensor::set_(const at::Tensor &amp; source, int64_t storage_offset, at::IntArrayRef size, at::IntArrayRef stride) const {</span>
<span id="L4294"><span class="lineNum">    4294</span>              :     return at::_ops::set__source_Tensor_storage_offset::call(const_cast&lt;Tensor&amp;&gt;(*this), source, storage_offset, c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride));</span>
<span id="L4295"><span class="lineNum">    4295</span>              : }</span>
<span id="L4296"><span class="lineNum">    4296</span>              : </span>
<span id="L4297"><span class="lineNum">    4297</span>              : // aten::set_.source_Tensor_storage_offset(Tensor(a!) self, Tensor source, SymInt storage_offset, SymInt[] size, SymInt[] stride=[]) -&gt; Tensor(a!)</span>
<span id="L4298"><span class="lineNum">    4298</span>              : inline at::Tensor &amp; Tensor::set__symint(const at::Tensor &amp; source, c10::SymInt storage_offset, c10::SymIntArrayRef size, c10::SymIntArrayRef stride) const {</span>
<span id="L4299"><span class="lineNum">    4299</span>              :     return at::_ops::set__source_Tensor_storage_offset::call(const_cast&lt;Tensor&amp;&gt;(*this), source, storage_offset, size, stride);</span>
<span id="L4300"><span class="lineNum">    4300</span>              : }</span>
<span id="L4301"><span class="lineNum">    4301</span>              : </span>
<span id="L4302"><span class="lineNum">    4302</span>              : // aten::set_.source_Tensor(Tensor(a!) self, Tensor source) -&gt; Tensor(a!)</span>
<span id="L4303"><span class="lineNum">    4303</span>              : inline at::Tensor &amp; Tensor::set_(const at::Tensor &amp; source) const {</span>
<span id="L4304"><span class="lineNum">    4304</span>              :     return at::_ops::set__source_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), source);</span>
<span id="L4305"><span class="lineNum">    4305</span>              : }</span>
<span id="L4306"><span class="lineNum">    4306</span>              : </span>
<span id="L4307"><span class="lineNum">    4307</span>              : // aten::set_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L4308"><span class="lineNum">    4308</span>              : inline at::Tensor &amp; Tensor::set_() const {</span>
<span id="L4309"><span class="lineNum">    4309</span>              :     return at::_ops::set_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L4310"><span class="lineNum">    4310</span>              : }</span>
<span id="L4311"><span class="lineNum">    4311</span>              : </span>
<span id="L4312"><span class="lineNum">    4312</span>              : // aten::is_set_to(Tensor self, Tensor tensor) -&gt; bool</span>
<span id="L4313"><span class="lineNum">    4313</span>              : inline bool Tensor::is_set_to(const at::Tensor &amp; tensor) const {</span>
<span id="L4314"><span class="lineNum">    4314</span>              :     return at::_ops::is_set_to::call(const_cast&lt;Tensor&amp;&gt;(*this), tensor);</span>
<span id="L4315"><span class="lineNum">    4315</span>              : }</span>
<span id="L4316"><span class="lineNum">    4316</span>              : </span>
<span id="L4317"><span class="lineNum">    4317</span>              : // aten::masked_fill_.Scalar(Tensor(a!) self, Tensor mask, Scalar value) -&gt; Tensor(a!)</span>
<span id="L4318"><span class="lineNum">    4318</span>              : inline at::Tensor &amp; Tensor::masked_fill_(const at::Tensor &amp; mask, const at::Scalar &amp; value) const {</span>
<span id="L4319"><span class="lineNum">    4319</span>              :     return at::_ops::masked_fill__Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), mask, value);</span>
<span id="L4320"><span class="lineNum">    4320</span>              : }</span>
<span id="L4321"><span class="lineNum">    4321</span>              : </span>
<span id="L4322"><span class="lineNum">    4322</span>              : // aten::masked_fill.Scalar(Tensor self, Tensor mask, Scalar value) -&gt; Tensor</span>
<span id="L4323"><span class="lineNum">    4323</span>              : inline at::Tensor Tensor::masked_fill(const at::Tensor &amp; mask, const at::Scalar &amp; value) const {</span>
<span id="L4324"><span class="lineNum">    4324</span>              :     return at::_ops::masked_fill_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), mask, value);</span>
<span id="L4325"><span class="lineNum">    4325</span>              : }</span>
<span id="L4326"><span class="lineNum">    4326</span>              : </span>
<span id="L4327"><span class="lineNum">    4327</span>              : // aten::masked_fill_.Tensor(Tensor(a!) self, Tensor mask, Tensor value) -&gt; Tensor(a!)</span>
<span id="L4328"><span class="lineNum">    4328</span>              : inline at::Tensor &amp; Tensor::masked_fill_(const at::Tensor &amp; mask, const at::Tensor &amp; value) const {</span>
<span id="L4329"><span class="lineNum">    4329</span>              :     return at::_ops::masked_fill__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), mask, value);</span>
<span id="L4330"><span class="lineNum">    4330</span>              : }</span>
<span id="L4331"><span class="lineNum">    4331</span>              : </span>
<span id="L4332"><span class="lineNum">    4332</span>              : // aten::masked_fill.Tensor(Tensor self, Tensor mask, Tensor value) -&gt; Tensor</span>
<span id="L4333"><span class="lineNum">    4333</span>              : inline at::Tensor Tensor::masked_fill(const at::Tensor &amp; mask, const at::Tensor &amp; value) const {</span>
<span id="L4334"><span class="lineNum">    4334</span>              :     return at::_ops::masked_fill_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), mask, value);</span>
<span id="L4335"><span class="lineNum">    4335</span>              : }</span>
<span id="L4336"><span class="lineNum">    4336</span>              : </span>
<span id="L4337"><span class="lineNum">    4337</span>              : // aten::masked_scatter_(Tensor(a!) self, Tensor mask, Tensor source) -&gt; Tensor(a!)</span>
<span id="L4338"><span class="lineNum">    4338</span>              : inline at::Tensor &amp; Tensor::masked_scatter_(const at::Tensor &amp; mask, const at::Tensor &amp; source) const {</span>
<span id="L4339"><span class="lineNum">    4339</span>              :     return at::_ops::masked_scatter_::call(const_cast&lt;Tensor&amp;&gt;(*this), mask, source);</span>
<span id="L4340"><span class="lineNum">    4340</span>              : }</span>
<span id="L4341"><span class="lineNum">    4341</span>              : </span>
<span id="L4342"><span class="lineNum">    4342</span>              : // aten::masked_scatter(Tensor self, Tensor mask, Tensor source) -&gt; Tensor</span>
<span id="L4343"><span class="lineNum">    4343</span>              : inline at::Tensor Tensor::masked_scatter(const at::Tensor &amp; mask, const at::Tensor &amp; source) const {</span>
<span id="L4344"><span class="lineNum">    4344</span>              :     return at::_ops::masked_scatter::call(const_cast&lt;Tensor&amp;&gt;(*this), mask, source);</span>
<span id="L4345"><span class="lineNum">    4345</span>              : }</span>
<span id="L4346"><span class="lineNum">    4346</span>              : </span>
<span id="L4347"><span class="lineNum">    4347</span>              : // aten::view(Tensor(a) self, SymInt[] size) -&gt; Tensor(a)</span>
<span id="L4348"><span class="lineNum">    4348</span>              : inline at::Tensor Tensor::view(at::IntArrayRef size) const {</span>
<span id="L4349"><span class="lineNum">    4349</span>              :     return at::_ops::view::call(const_cast&lt;Tensor&amp;&gt;(*this), c10::fromIntArrayRefSlow(size));</span>
<span id="L4350"><span class="lineNum">    4350</span>              : }</span>
<span id="L4351"><span class="lineNum">    4351</span>              : </span>
<span id="L4352"><span class="lineNum">    4352</span>              : // aten::view(Tensor(a) self, SymInt[] size) -&gt; Tensor(a)</span>
<span id="L4353"><span class="lineNum">    4353</span>              : inline at::Tensor Tensor::view_symint(c10::SymIntArrayRef size) const {</span>
<span id="L4354"><span class="lineNum">    4354</span>              :     return at::_ops::view::call(const_cast&lt;Tensor&amp;&gt;(*this), size);</span>
<span id="L4355"><span class="lineNum">    4355</span>              : }</span>
<span id="L4356"><span class="lineNum">    4356</span>              : </span>
<span id="L4357"><span class="lineNum">    4357</span>              : // aten::view.dtype(Tensor(a) self, ScalarType dtype) -&gt; Tensor(a)</span>
<span id="L4358"><span class="lineNum">    4358</span>              : inline at::Tensor Tensor::view(at::ScalarType dtype) const {</span>
<span id="L4359"><span class="lineNum">    4359</span>              :     return at::_ops::view_dtype::call(const_cast&lt;Tensor&amp;&gt;(*this), dtype);</span>
<span id="L4360"><span class="lineNum">    4360</span>              : }</span>
<span id="L4361"><span class="lineNum">    4361</span>              : </span>
<span id="L4362"><span class="lineNum">    4362</span>              : // aten::put_(Tensor(a!) self, Tensor index, Tensor source, bool accumulate=False) -&gt; Tensor(a!)</span>
<span id="L4363"><span class="lineNum">    4363</span>              : inline at::Tensor &amp; Tensor::put_(const at::Tensor &amp; index, const at::Tensor &amp; source, bool accumulate) const {</span>
<span id="L4364"><span class="lineNum">    4364</span>              :     return at::_ops::put_::call(const_cast&lt;Tensor&amp;&gt;(*this), index, source, accumulate);</span>
<span id="L4365"><span class="lineNum">    4365</span>              : }</span>
<span id="L4366"><span class="lineNum">    4366</span>              : </span>
<span id="L4367"><span class="lineNum">    4367</span>              : // aten::put(Tensor self, Tensor index, Tensor source, bool accumulate=False) -&gt; Tensor</span>
<span id="L4368"><span class="lineNum">    4368</span>              : inline at::Tensor Tensor::put(const at::Tensor &amp; index, const at::Tensor &amp; source, bool accumulate) const {</span>
<span id="L4369"><span class="lineNum">    4369</span>              :     return at::_ops::put::call(const_cast&lt;Tensor&amp;&gt;(*this), index, source, accumulate);</span>
<span id="L4370"><span class="lineNum">    4370</span>              : }</span>
<span id="L4371"><span class="lineNum">    4371</span>              : </span>
<span id="L4372"><span class="lineNum">    4372</span>              : // aten::index_add_(Tensor(a!) self, int dim, Tensor index, Tensor source, *, Scalar alpha=1) -&gt; Tensor(a!)</span>
<span id="L4373"><span class="lineNum">    4373</span>              : inline at::Tensor &amp; Tensor::index_add_(int64_t dim, const at::Tensor &amp; index, const at::Tensor &amp; source, const at::Scalar &amp; alpha) const {</span>
<span id="L4374"><span class="lineNum">    4374</span>              :     return at::_ops::index_add_::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index, source, alpha);</span>
<span id="L4375"><span class="lineNum">    4375</span>              : }</span>
<span id="L4376"><span class="lineNum">    4376</span>              : </span>
<span id="L4377"><span class="lineNum">    4377</span>              : // aten::index_add(Tensor self, int dim, Tensor index, Tensor source, *, Scalar alpha=1) -&gt; Tensor</span>
<span id="L4378"><span class="lineNum">    4378</span>              : inline at::Tensor Tensor::index_add(int64_t dim, const at::Tensor &amp; index, const at::Tensor &amp; source, const at::Scalar &amp; alpha) const {</span>
<span id="L4379"><span class="lineNum">    4379</span>              :     return at::_ops::index_add::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index, source, alpha);</span>
<span id="L4380"><span class="lineNum">    4380</span>              : }</span>
<span id="L4381"><span class="lineNum">    4381</span>              : </span>
<span id="L4382"><span class="lineNum">    4382</span>              : // aten::index_add.dimname(Tensor self, Dimname dim, Tensor index, Tensor source, *, Scalar alpha=1) -&gt; Tensor</span>
<span id="L4383"><span class="lineNum">    4383</span>              : inline at::Tensor Tensor::index_add(at::Dimname dim, const at::Tensor &amp; index, const at::Tensor &amp; source, const at::Scalar &amp; alpha) const {</span>
<span id="L4384"><span class="lineNum">    4384</span>              :     return at::_ops::index_add_dimname::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index, source, alpha);</span>
<span id="L4385"><span class="lineNum">    4385</span>              : }</span>
<span id="L4386"><span class="lineNum">    4386</span>              : </span>
<span id="L4387"><span class="lineNum">    4387</span>              : // aten::index_reduce_(Tensor(a!) self, int dim, Tensor index, Tensor source, str reduce, *, bool include_self=True) -&gt; Tensor(a!)</span>
<span id="L4388"><span class="lineNum">    4388</span>              : inline at::Tensor &amp; Tensor::index_reduce_(int64_t dim, const at::Tensor &amp; index, const at::Tensor &amp; source, c10::string_view reduce, bool include_self) const {</span>
<span id="L4389"><span class="lineNum">    4389</span>              :     return at::_ops::index_reduce_::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index, source, reduce, include_self);</span>
<span id="L4390"><span class="lineNum">    4390</span>              : }</span>
<span id="L4391"><span class="lineNum">    4391</span>              : </span>
<span id="L4392"><span class="lineNum">    4392</span>              : // aten::index_reduce(Tensor self, int dim, Tensor index, Tensor source, str reduce, *, bool include_self=True) -&gt; Tensor</span>
<span id="L4393"><span class="lineNum">    4393</span>              : inline at::Tensor Tensor::index_reduce(int64_t dim, const at::Tensor &amp; index, const at::Tensor &amp; source, c10::string_view reduce, bool include_self) const {</span>
<span id="L4394"><span class="lineNum">    4394</span>              :     return at::_ops::index_reduce::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index, source, reduce, include_self);</span>
<span id="L4395"><span class="lineNum">    4395</span>              : }</span>
<span id="L4396"><span class="lineNum">    4396</span>              : </span>
<span id="L4397"><span class="lineNum">    4397</span>              : // aten::index_fill_.int_Scalar(Tensor(a!) self, int dim, Tensor index, Scalar value) -&gt; Tensor(a!)</span>
<span id="L4398"><span class="lineNum">    4398</span>              : inline at::Tensor &amp; Tensor::index_fill_(int64_t dim, const at::Tensor &amp; index, const at::Scalar &amp; value) const {</span>
<span id="L4399"><span class="lineNum">    4399</span>              :     return at::_ops::index_fill__int_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index, value);</span>
<span id="L4400"><span class="lineNum">    4400</span>              : }</span>
<span id="L4401"><span class="lineNum">    4401</span>              : </span>
<span id="L4402"><span class="lineNum">    4402</span>              : // aten::index_fill.int_Scalar(Tensor self, int dim, Tensor index, Scalar value) -&gt; Tensor</span>
<span id="L4403"><span class="lineNum">    4403</span>              : inline at::Tensor Tensor::index_fill(int64_t dim, const at::Tensor &amp; index, const at::Scalar &amp; value) const {</span>
<span id="L4404"><span class="lineNum">    4404</span>              :     return at::_ops::index_fill_int_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index, value);</span>
<span id="L4405"><span class="lineNum">    4405</span>              : }</span>
<span id="L4406"><span class="lineNum">    4406</span>              : </span>
<span id="L4407"><span class="lineNum">    4407</span>              : // aten::index_fill_.int_Tensor(Tensor(a!) self, int dim, Tensor index, Tensor value) -&gt; Tensor(a!)</span>
<span id="L4408"><span class="lineNum">    4408</span>              : inline at::Tensor &amp; Tensor::index_fill_(int64_t dim, const at::Tensor &amp; index, const at::Tensor &amp; value) const {</span>
<span id="L4409"><span class="lineNum">    4409</span>              :     return at::_ops::index_fill__int_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index, value);</span>
<span id="L4410"><span class="lineNum">    4410</span>              : }</span>
<span id="L4411"><span class="lineNum">    4411</span>              : </span>
<span id="L4412"><span class="lineNum">    4412</span>              : // aten::index_fill.int_Tensor(Tensor self, int dim, Tensor index, Tensor value) -&gt; Tensor</span>
<span id="L4413"><span class="lineNum">    4413</span>              : inline at::Tensor Tensor::index_fill(int64_t dim, const at::Tensor &amp; index, const at::Tensor &amp; value) const {</span>
<span id="L4414"><span class="lineNum">    4414</span>              :     return at::_ops::index_fill_int_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index, value);</span>
<span id="L4415"><span class="lineNum">    4415</span>              : }</span>
<span id="L4416"><span class="lineNum">    4416</span>              : </span>
<span id="L4417"><span class="lineNum">    4417</span>              : // aten::index_fill_.Dimname_Scalar(Tensor(a!) self, Dimname dim, Tensor index, Scalar value) -&gt; Tensor(a!)</span>
<span id="L4418"><span class="lineNum">    4418</span>              : inline at::Tensor &amp; Tensor::index_fill_(at::Dimname dim, const at::Tensor &amp; index, const at::Scalar &amp; value) const {</span>
<span id="L4419"><span class="lineNum">    4419</span>              :     return at::_ops::index_fill__Dimname_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index, value);</span>
<span id="L4420"><span class="lineNum">    4420</span>              : }</span>
<span id="L4421"><span class="lineNum">    4421</span>              : </span>
<span id="L4422"><span class="lineNum">    4422</span>              : // aten::index_fill_.Dimname_Tensor(Tensor(a!) self, Dimname dim, Tensor index, Tensor value) -&gt; Tensor(a!)</span>
<span id="L4423"><span class="lineNum">    4423</span>              : inline at::Tensor &amp; Tensor::index_fill_(at::Dimname dim, const at::Tensor &amp; index, const at::Tensor &amp; value) const {</span>
<span id="L4424"><span class="lineNum">    4424</span>              :     return at::_ops::index_fill__Dimname_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index, value);</span>
<span id="L4425"><span class="lineNum">    4425</span>              : }</span>
<span id="L4426"><span class="lineNum">    4426</span>              : </span>
<span id="L4427"><span class="lineNum">    4427</span>              : // aten::index_fill.Dimname_Scalar(Tensor self, Dimname dim, Tensor index, Scalar value) -&gt; Tensor</span>
<span id="L4428"><span class="lineNum">    4428</span>              : inline at::Tensor Tensor::index_fill(at::Dimname dim, const at::Tensor &amp; index, const at::Scalar &amp; value) const {</span>
<span id="L4429"><span class="lineNum">    4429</span>              :     return at::_ops::index_fill_Dimname_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index, value);</span>
<span id="L4430"><span class="lineNum">    4430</span>              : }</span>
<span id="L4431"><span class="lineNum">    4431</span>              : </span>
<span id="L4432"><span class="lineNum">    4432</span>              : // aten::index_fill.Dimname_Tensor(Tensor self, Dimname dim, Tensor index, Tensor value) -&gt; Tensor</span>
<span id="L4433"><span class="lineNum">    4433</span>              : inline at::Tensor Tensor::index_fill(at::Dimname dim, const at::Tensor &amp; index, const at::Tensor &amp; value) const {</span>
<span id="L4434"><span class="lineNum">    4434</span>              :     return at::_ops::index_fill_Dimname_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index, value);</span>
<span id="L4435"><span class="lineNum">    4435</span>              : }</span>
<span id="L4436"><span class="lineNum">    4436</span>              : </span>
<span id="L4437"><span class="lineNum">    4437</span>              : // aten::scatter.src(Tensor self, int dim, Tensor index, Tensor src) -&gt; Tensor</span>
<span id="L4438"><span class="lineNum">    4438</span>              : inline at::Tensor Tensor::scatter(int64_t dim, const at::Tensor &amp; index, const at::Tensor &amp; src) const {</span>
<span id="L4439"><span class="lineNum">    4439</span>              :     return at::_ops::scatter_src::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index, src);</span>
<span id="L4440"><span class="lineNum">    4440</span>              : }</span>
<span id="L4441"><span class="lineNum">    4441</span>              : </span>
<span id="L4442"><span class="lineNum">    4442</span>              : // aten::scatter_.src(Tensor(a!) self, int dim, Tensor index, Tensor src) -&gt; Tensor(a!)</span>
<span id="L4443"><span class="lineNum">    4443</span>              : inline at::Tensor &amp; Tensor::scatter_(int64_t dim, const at::Tensor &amp; index, const at::Tensor &amp; src) const {</span>
<span id="L4444"><span class="lineNum">    4444</span>              :     return at::_ops::scatter__src::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index, src);</span>
<span id="L4445"><span class="lineNum">    4445</span>              : }</span>
<span id="L4446"><span class="lineNum">    4446</span>              : </span>
<span id="L4447"><span class="lineNum">    4447</span>              : // aten::scatter.value(Tensor self, int dim, Tensor index, Scalar value) -&gt; Tensor</span>
<span id="L4448"><span class="lineNum">    4448</span>              : inline at::Tensor Tensor::scatter(int64_t dim, const at::Tensor &amp; index, const at::Scalar &amp; value) const {</span>
<span id="L4449"><span class="lineNum">    4449</span>              :     return at::_ops::scatter_value::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index, value);</span>
<span id="L4450"><span class="lineNum">    4450</span>              : }</span>
<span id="L4451"><span class="lineNum">    4451</span>              : </span>
<span id="L4452"><span class="lineNum">    4452</span>              : // aten::scatter_.value(Tensor(a!) self, int dim, Tensor index, Scalar value) -&gt; Tensor(a!)</span>
<span id="L4453"><span class="lineNum">    4453</span>              : inline at::Tensor &amp; Tensor::scatter_(int64_t dim, const at::Tensor &amp; index, const at::Scalar &amp; value) const {</span>
<span id="L4454"><span class="lineNum">    4454</span>              :     return at::_ops::scatter__value::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index, value);</span>
<span id="L4455"><span class="lineNum">    4455</span>              : }</span>
<span id="L4456"><span class="lineNum">    4456</span>              : </span>
<span id="L4457"><span class="lineNum">    4457</span>              : // aten::scatter.reduce(Tensor self, int dim, Tensor index, Tensor src, *, str reduce) -&gt; Tensor</span>
<span id="L4458"><span class="lineNum">    4458</span>              : inline at::Tensor Tensor::scatter(int64_t dim, const at::Tensor &amp; index, const at::Tensor &amp; src, c10::string_view reduce) const {</span>
<span id="L4459"><span class="lineNum">    4459</span>              :     return at::_ops::scatter_reduce::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index, src, reduce);</span>
<span id="L4460"><span class="lineNum">    4460</span>              : }</span>
<span id="L4461"><span class="lineNum">    4461</span>              : </span>
<span id="L4462"><span class="lineNum">    4462</span>              : // aten::scatter_.reduce(Tensor(a!) self, int dim, Tensor index, Tensor src, *, str reduce) -&gt; Tensor(a!)</span>
<span id="L4463"><span class="lineNum">    4463</span>              : inline at::Tensor &amp; Tensor::scatter_(int64_t dim, const at::Tensor &amp; index, const at::Tensor &amp; src, c10::string_view reduce) const {</span>
<span id="L4464"><span class="lineNum">    4464</span>              :     return at::_ops::scatter__reduce::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index, src, reduce);</span>
<span id="L4465"><span class="lineNum">    4465</span>              : }</span>
<span id="L4466"><span class="lineNum">    4466</span>              : </span>
<span id="L4467"><span class="lineNum">    4467</span>              : // aten::scatter.value_reduce(Tensor self, int dim, Tensor index, Scalar value, *, str reduce) -&gt; Tensor</span>
<span id="L4468"><span class="lineNum">    4468</span>              : inline at::Tensor Tensor::scatter(int64_t dim, const at::Tensor &amp; index, const at::Scalar &amp; value, c10::string_view reduce) const {</span>
<span id="L4469"><span class="lineNum">    4469</span>              :     return at::_ops::scatter_value_reduce::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index, value, reduce);</span>
<span id="L4470"><span class="lineNum">    4470</span>              : }</span>
<span id="L4471"><span class="lineNum">    4471</span>              : </span>
<span id="L4472"><span class="lineNum">    4472</span>              : // aten::scatter_.value_reduce(Tensor(a!) self, int dim, Tensor index, Scalar value, *, str reduce) -&gt; Tensor(a!)</span>
<span id="L4473"><span class="lineNum">    4473</span>              : inline at::Tensor &amp; Tensor::scatter_(int64_t dim, const at::Tensor &amp; index, const at::Scalar &amp; value, c10::string_view reduce) const {</span>
<span id="L4474"><span class="lineNum">    4474</span>              :     return at::_ops::scatter__value_reduce::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index, value, reduce);</span>
<span id="L4475"><span class="lineNum">    4475</span>              : }</span>
<span id="L4476"><span class="lineNum">    4476</span>              : </span>
<span id="L4477"><span class="lineNum">    4477</span>              : // aten::scatter.dimname_src(Tensor self, Dimname dim, Tensor index, Tensor src) -&gt; Tensor</span>
<span id="L4478"><span class="lineNum">    4478</span>              : inline at::Tensor Tensor::scatter(at::Dimname dim, const at::Tensor &amp; index, const at::Tensor &amp; src) const {</span>
<span id="L4479"><span class="lineNum">    4479</span>              :     return at::_ops::scatter_dimname_src::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index, src);</span>
<span id="L4480"><span class="lineNum">    4480</span>              : }</span>
<span id="L4481"><span class="lineNum">    4481</span>              : </span>
<span id="L4482"><span class="lineNum">    4482</span>              : // aten::scatter.dimname_value(Tensor self, Dimname dim, Tensor index, Scalar value) -&gt; Tensor</span>
<span id="L4483"><span class="lineNum">    4483</span>              : inline at::Tensor Tensor::scatter(at::Dimname dim, const at::Tensor &amp; index, const at::Scalar &amp; value) const {</span>
<span id="L4484"><span class="lineNum">    4484</span>              :     return at::_ops::scatter_dimname_value::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index, value);</span>
<span id="L4485"><span class="lineNum">    4485</span>              : }</span>
<span id="L4486"><span class="lineNum">    4486</span>              : </span>
<span id="L4487"><span class="lineNum">    4487</span>              : // aten::scatter_add(Tensor self, int dim, Tensor index, Tensor src) -&gt; Tensor</span>
<span id="L4488"><span class="lineNum">    4488</span>              : inline at::Tensor Tensor::scatter_add(int64_t dim, const at::Tensor &amp; index, const at::Tensor &amp; src) const {</span>
<span id="L4489"><span class="lineNum">    4489</span>              :     return at::_ops::scatter_add::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index, src);</span>
<span id="L4490"><span class="lineNum">    4490</span>              : }</span>
<span id="L4491"><span class="lineNum">    4491</span>              : </span>
<span id="L4492"><span class="lineNum">    4492</span>              : // aten::scatter_add_(Tensor(a!) self, int dim, Tensor index, Tensor src) -&gt; Tensor(a!)</span>
<span id="L4493"><span class="lineNum">    4493</span>              : inline at::Tensor &amp; Tensor::scatter_add_(int64_t dim, const at::Tensor &amp; index, const at::Tensor &amp; src) const {</span>
<span id="L4494"><span class="lineNum">    4494</span>              :     return at::_ops::scatter_add_::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index, src);</span>
<span id="L4495"><span class="lineNum">    4495</span>              : }</span>
<span id="L4496"><span class="lineNum">    4496</span>              : </span>
<span id="L4497"><span class="lineNum">    4497</span>              : // aten::scatter_add.dimname(Tensor self, Dimname dim, Tensor index, Tensor src) -&gt; Tensor</span>
<span id="L4498"><span class="lineNum">    4498</span>              : inline at::Tensor Tensor::scatter_add(at::Dimname dim, const at::Tensor &amp; index, const at::Tensor &amp; src) const {</span>
<span id="L4499"><span class="lineNum">    4499</span>              :     return at::_ops::scatter_add_dimname::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index, src);</span>
<span id="L4500"><span class="lineNum">    4500</span>              : }</span>
<span id="L4501"><span class="lineNum">    4501</span>              : </span>
<span id="L4502"><span class="lineNum">    4502</span>              : // aten::scatter_reduce.two(Tensor self, int dim, Tensor index, Tensor src, str reduce, *, bool include_self=True) -&gt; Tensor</span>
<span id="L4503"><span class="lineNum">    4503</span>              : inline at::Tensor Tensor::scatter_reduce(int64_t dim, const at::Tensor &amp; index, const at::Tensor &amp; src, c10::string_view reduce, bool include_self) const {</span>
<span id="L4504"><span class="lineNum">    4504</span>              :     return at::_ops::scatter_reduce_two::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index, src, reduce, include_self);</span>
<span id="L4505"><span class="lineNum">    4505</span>              : }</span>
<span id="L4506"><span class="lineNum">    4506</span>              : </span>
<span id="L4507"><span class="lineNum">    4507</span>              : // aten::scatter_reduce_.two(Tensor(a!) self, int dim, Tensor index, Tensor src, str reduce, *, bool include_self=True) -&gt; Tensor(a!)</span>
<span id="L4508"><span class="lineNum">    4508</span>              : inline at::Tensor &amp; Tensor::scatter_reduce_(int64_t dim, const at::Tensor &amp; index, const at::Tensor &amp; src, c10::string_view reduce, bool include_self) const {</span>
<span id="L4509"><span class="lineNum">    4509</span>              :     return at::_ops::scatter_reduce__two::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index, src, reduce, include_self);</span>
<span id="L4510"><span class="lineNum">    4510</span>              : }</span>
<span id="L4511"><span class="lineNum">    4511</span>              : </span>
<span id="L4512"><span class="lineNum">    4512</span>              : // aten::eq_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span id="L4513"><span class="lineNum">    4513</span>              : inline at::Tensor &amp; Tensor::eq_(const at::Scalar &amp; other) const {</span>
<span id="L4514"><span class="lineNum">    4514</span>              :     return at::_ops::eq__Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4515"><span class="lineNum">    4515</span>              : }</span>
<span id="L4516"><span class="lineNum">    4516</span>              : </span>
<span id="L4517"><span class="lineNum">    4517</span>              : // aten::eq_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L4518"><span class="lineNum">    4518</span>              : inline at::Tensor &amp; Tensor::eq_(const at::Tensor &amp; other) const {</span>
<span id="L4519"><span class="lineNum">    4519</span>              :     return at::_ops::eq__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4520"><span class="lineNum">    4520</span>              : }</span>
<span id="L4521"><span class="lineNum">    4521</span>              : </span>
<span id="L4522"><span class="lineNum">    4522</span>              : // aten::bitwise_and.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span id="L4523"><span class="lineNum">    4523</span>              : inline at::Tensor Tensor::bitwise_and(const at::Scalar &amp; other) const {</span>
<span id="L4524"><span class="lineNum">    4524</span>              :     return at::_ops::bitwise_and_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4525"><span class="lineNum">    4525</span>              : }</span>
<span id="L4526"><span class="lineNum">    4526</span>              : </span>
<span id="L4527"><span class="lineNum">    4527</span>              : // aten::bitwise_and.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L4528"><span class="lineNum">    4528</span>              : inline at::Tensor Tensor::bitwise_and(const at::Tensor &amp; other) const {</span>
<span id="L4529"><span class="lineNum">    4529</span>              :     return at::_ops::bitwise_and_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4530"><span class="lineNum">    4530</span>              : }</span>
<span id="L4531"><span class="lineNum">    4531</span>              : </span>
<span id="L4532"><span class="lineNum">    4532</span>              : // aten::bitwise_and_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span id="L4533"><span class="lineNum">    4533</span>              : inline at::Tensor &amp; Tensor::bitwise_and_(const at::Scalar &amp; other) const {</span>
<span id="L4534"><span class="lineNum">    4534</span>              :     return at::_ops::bitwise_and__Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4535"><span class="lineNum">    4535</span>              : }</span>
<span id="L4536"><span class="lineNum">    4536</span>              : </span>
<span id="L4537"><span class="lineNum">    4537</span>              : // aten::bitwise_and_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L4538"><span class="lineNum">    4538</span>              : inline at::Tensor &amp; Tensor::bitwise_and_(const at::Tensor &amp; other) const {</span>
<span id="L4539"><span class="lineNum">    4539</span>              :     return at::_ops::bitwise_and__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4540"><span class="lineNum">    4540</span>              : }</span>
<span id="L4541"><span class="lineNum">    4541</span>              : </span>
<span id="L4542"><span class="lineNum">    4542</span>              : // aten::__and__.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span id="L4543"><span class="lineNum">    4543</span>              : inline at::Tensor Tensor::__and__(const at::Scalar &amp; other) const {</span>
<span id="L4544"><span class="lineNum">    4544</span>              :     return at::_ops::__and___Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4545"><span class="lineNum">    4545</span>              : }</span>
<span id="L4546"><span class="lineNum">    4546</span>              : </span>
<span id="L4547"><span class="lineNum">    4547</span>              : // aten::__and__.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L4548"><span class="lineNum">    4548</span>              : inline at::Tensor Tensor::__and__(const at::Tensor &amp; other) const {</span>
<span id="L4549"><span class="lineNum">    4549</span>              :     return at::_ops::__and___Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4550"><span class="lineNum">    4550</span>              : }</span>
<span id="L4551"><span class="lineNum">    4551</span>              : </span>
<span id="L4552"><span class="lineNum">    4552</span>              : // aten::__iand__.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span id="L4553"><span class="lineNum">    4553</span>              : inline at::Tensor &amp; Tensor::__iand__(const at::Scalar &amp; other) const {</span>
<span id="L4554"><span class="lineNum">    4554</span>              :     return at::_ops::__iand___Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4555"><span class="lineNum">    4555</span>              : }</span>
<span id="L4556"><span class="lineNum">    4556</span>              : </span>
<span id="L4557"><span class="lineNum">    4557</span>              : // aten::__iand__.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L4558"><span class="lineNum">    4558</span>              : inline at::Tensor &amp; Tensor::__iand__(const at::Tensor &amp; other) const {</span>
<span id="L4559"><span class="lineNum">    4559</span>              :     return at::_ops::__iand___Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4560"><span class="lineNum">    4560</span>              : }</span>
<span id="L4561"><span class="lineNum">    4561</span>              : </span>
<span id="L4562"><span class="lineNum">    4562</span>              : // aten::bitwise_or.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span id="L4563"><span class="lineNum">    4563</span>              : inline at::Tensor Tensor::bitwise_or(const at::Scalar &amp; other) const {</span>
<span id="L4564"><span class="lineNum">    4564</span>              :     return at::_ops::bitwise_or_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4565"><span class="lineNum">    4565</span>              : }</span>
<span id="L4566"><span class="lineNum">    4566</span>              : </span>
<span id="L4567"><span class="lineNum">    4567</span>              : // aten::bitwise_or.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L4568"><span class="lineNum">    4568</span>              : inline at::Tensor Tensor::bitwise_or(const at::Tensor &amp; other) const {</span>
<span id="L4569"><span class="lineNum">    4569</span>              :     return at::_ops::bitwise_or_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4570"><span class="lineNum">    4570</span>              : }</span>
<span id="L4571"><span class="lineNum">    4571</span>              : </span>
<span id="L4572"><span class="lineNum">    4572</span>              : // aten::bitwise_or_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span id="L4573"><span class="lineNum">    4573</span>              : inline at::Tensor &amp; Tensor::bitwise_or_(const at::Scalar &amp; other) const {</span>
<span id="L4574"><span class="lineNum">    4574</span>              :     return at::_ops::bitwise_or__Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4575"><span class="lineNum">    4575</span>              : }</span>
<span id="L4576"><span class="lineNum">    4576</span>              : </span>
<span id="L4577"><span class="lineNum">    4577</span>              : // aten::bitwise_or_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L4578"><span class="lineNum">    4578</span>              : inline at::Tensor &amp; Tensor::bitwise_or_(const at::Tensor &amp; other) const {</span>
<span id="L4579"><span class="lineNum">    4579</span>              :     return at::_ops::bitwise_or__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4580"><span class="lineNum">    4580</span>              : }</span>
<span id="L4581"><span class="lineNum">    4581</span>              : </span>
<span id="L4582"><span class="lineNum">    4582</span>              : // aten::__or__.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span id="L4583"><span class="lineNum">    4583</span>              : inline at::Tensor Tensor::__or__(const at::Scalar &amp; other) const {</span>
<span id="L4584"><span class="lineNum">    4584</span>              :     return at::_ops::__or___Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4585"><span class="lineNum">    4585</span>              : }</span>
<span id="L4586"><span class="lineNum">    4586</span>              : </span>
<span id="L4587"><span class="lineNum">    4587</span>              : // aten::__or__.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L4588"><span class="lineNum">    4588</span>              : inline at::Tensor Tensor::__or__(const at::Tensor &amp; other) const {</span>
<span id="L4589"><span class="lineNum">    4589</span>              :     return at::_ops::__or___Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4590"><span class="lineNum">    4590</span>              : }</span>
<span id="L4591"><span class="lineNum">    4591</span>              : </span>
<span id="L4592"><span class="lineNum">    4592</span>              : // aten::__ior__.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span id="L4593"><span class="lineNum">    4593</span>              : inline at::Tensor &amp; Tensor::__ior__(const at::Scalar &amp; other) const {</span>
<span id="L4594"><span class="lineNum">    4594</span>              :     return at::_ops::__ior___Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4595"><span class="lineNum">    4595</span>              : }</span>
<span id="L4596"><span class="lineNum">    4596</span>              : </span>
<span id="L4597"><span class="lineNum">    4597</span>              : // aten::__ior__.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L4598"><span class="lineNum">    4598</span>              : inline at::Tensor &amp; Tensor::__ior__(const at::Tensor &amp; other) const {</span>
<span id="L4599"><span class="lineNum">    4599</span>              :     return at::_ops::__ior___Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4600"><span class="lineNum">    4600</span>              : }</span>
<span id="L4601"><span class="lineNum">    4601</span>              : </span>
<span id="L4602"><span class="lineNum">    4602</span>              : // aten::bitwise_xor.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span id="L4603"><span class="lineNum">    4603</span>              : inline at::Tensor Tensor::bitwise_xor(const at::Scalar &amp; other) const {</span>
<span id="L4604"><span class="lineNum">    4604</span>              :     return at::_ops::bitwise_xor_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4605"><span class="lineNum">    4605</span>              : }</span>
<span id="L4606"><span class="lineNum">    4606</span>              : </span>
<span id="L4607"><span class="lineNum">    4607</span>              : // aten::bitwise_xor.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L4608"><span class="lineNum">    4608</span>              : inline at::Tensor Tensor::bitwise_xor(const at::Tensor &amp; other) const {</span>
<span id="L4609"><span class="lineNum">    4609</span>              :     return at::_ops::bitwise_xor_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4610"><span class="lineNum">    4610</span>              : }</span>
<span id="L4611"><span class="lineNum">    4611</span>              : </span>
<span id="L4612"><span class="lineNum">    4612</span>              : // aten::bitwise_xor_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span id="L4613"><span class="lineNum">    4613</span>              : inline at::Tensor &amp; Tensor::bitwise_xor_(const at::Scalar &amp; other) const {</span>
<span id="L4614"><span class="lineNum">    4614</span>              :     return at::_ops::bitwise_xor__Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4615"><span class="lineNum">    4615</span>              : }</span>
<span id="L4616"><span class="lineNum">    4616</span>              : </span>
<span id="L4617"><span class="lineNum">    4617</span>              : // aten::bitwise_xor_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L4618"><span class="lineNum">    4618</span>              : inline at::Tensor &amp; Tensor::bitwise_xor_(const at::Tensor &amp; other) const {</span>
<span id="L4619"><span class="lineNum">    4619</span>              :     return at::_ops::bitwise_xor__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4620"><span class="lineNum">    4620</span>              : }</span>
<span id="L4621"><span class="lineNum">    4621</span>              : </span>
<span id="L4622"><span class="lineNum">    4622</span>              : // aten::__xor__.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span id="L4623"><span class="lineNum">    4623</span>              : inline at::Tensor Tensor::__xor__(const at::Scalar &amp; other) const {</span>
<span id="L4624"><span class="lineNum">    4624</span>              :     return at::_ops::__xor___Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4625"><span class="lineNum">    4625</span>              : }</span>
<span id="L4626"><span class="lineNum">    4626</span>              : </span>
<span id="L4627"><span class="lineNum">    4627</span>              : // aten::__xor__.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L4628"><span class="lineNum">    4628</span>              : inline at::Tensor Tensor::__xor__(const at::Tensor &amp; other) const {</span>
<span id="L4629"><span class="lineNum">    4629</span>              :     return at::_ops::__xor___Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4630"><span class="lineNum">    4630</span>              : }</span>
<span id="L4631"><span class="lineNum">    4631</span>              : </span>
<span id="L4632"><span class="lineNum">    4632</span>              : // aten::__ixor__.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span id="L4633"><span class="lineNum">    4633</span>              : inline at::Tensor &amp; Tensor::__ixor__(const at::Scalar &amp; other) const {</span>
<span id="L4634"><span class="lineNum">    4634</span>              :     return at::_ops::__ixor___Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4635"><span class="lineNum">    4635</span>              : }</span>
<span id="L4636"><span class="lineNum">    4636</span>              : </span>
<span id="L4637"><span class="lineNum">    4637</span>              : // aten::__ixor__.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L4638"><span class="lineNum">    4638</span>              : inline at::Tensor &amp; Tensor::__ixor__(const at::Tensor &amp; other) const {</span>
<span id="L4639"><span class="lineNum">    4639</span>              :     return at::_ops::__ixor___Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4640"><span class="lineNum">    4640</span>              : }</span>
<span id="L4641"><span class="lineNum">    4641</span>              : </span>
<span id="L4642"><span class="lineNum">    4642</span>              : // aten::__lshift__.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span id="L4643"><span class="lineNum">    4643</span>              : inline at::Tensor Tensor::__lshift__(const at::Scalar &amp; other) const {</span>
<span id="L4644"><span class="lineNum">    4644</span>              :     return at::_ops::__lshift___Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4645"><span class="lineNum">    4645</span>              : }</span>
<span id="L4646"><span class="lineNum">    4646</span>              : </span>
<span id="L4647"><span class="lineNum">    4647</span>              : // aten::__lshift__.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L4648"><span class="lineNum">    4648</span>              : inline at::Tensor Tensor::__lshift__(const at::Tensor &amp; other) const {</span>
<span id="L4649"><span class="lineNum">    4649</span>              :     return at::_ops::__lshift___Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4650"><span class="lineNum">    4650</span>              : }</span>
<span id="L4651"><span class="lineNum">    4651</span>              : </span>
<span id="L4652"><span class="lineNum">    4652</span>              : // aten::__ilshift__.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span id="L4653"><span class="lineNum">    4653</span>              : inline at::Tensor &amp; Tensor::__ilshift__(const at::Scalar &amp; other) const {</span>
<span id="L4654"><span class="lineNum">    4654</span>              :     return at::_ops::__ilshift___Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4655"><span class="lineNum">    4655</span>              : }</span>
<span id="L4656"><span class="lineNum">    4656</span>              : </span>
<span id="L4657"><span class="lineNum">    4657</span>              : // aten::__ilshift__.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L4658"><span class="lineNum">    4658</span>              : inline at::Tensor &amp; Tensor::__ilshift__(const at::Tensor &amp; other) const {</span>
<span id="L4659"><span class="lineNum">    4659</span>              :     return at::_ops::__ilshift___Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4660"><span class="lineNum">    4660</span>              : }</span>
<span id="L4661"><span class="lineNum">    4661</span>              : </span>
<span id="L4662"><span class="lineNum">    4662</span>              : // aten::bitwise_left_shift.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L4663"><span class="lineNum">    4663</span>              : inline at::Tensor Tensor::bitwise_left_shift(const at::Tensor &amp; other) const {</span>
<span id="L4664"><span class="lineNum">    4664</span>              :     return at::_ops::bitwise_left_shift_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4665"><span class="lineNum">    4665</span>              : }</span>
<span id="L4666"><span class="lineNum">    4666</span>              : </span>
<span id="L4667"><span class="lineNum">    4667</span>              : // aten::bitwise_left_shift_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L4668"><span class="lineNum">    4668</span>              : inline at::Tensor &amp; Tensor::bitwise_left_shift_(const at::Tensor &amp; other) const {</span>
<span id="L4669"><span class="lineNum">    4669</span>              :     return at::_ops::bitwise_left_shift__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4670"><span class="lineNum">    4670</span>              : }</span>
<span id="L4671"><span class="lineNum">    4671</span>              : </span>
<span id="L4672"><span class="lineNum">    4672</span>              : // aten::bitwise_left_shift.Tensor_Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span id="L4673"><span class="lineNum">    4673</span>              : inline at::Tensor Tensor::bitwise_left_shift(const at::Scalar &amp; other) const {</span>
<span id="L4674"><span class="lineNum">    4674</span>              :     return at::_ops::bitwise_left_shift_Tensor_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4675"><span class="lineNum">    4675</span>              : }</span>
<span id="L4676"><span class="lineNum">    4676</span>              : </span>
<span id="L4677"><span class="lineNum">    4677</span>              : // aten::bitwise_left_shift_.Tensor_Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span id="L4678"><span class="lineNum">    4678</span>              : inline at::Tensor &amp; Tensor::bitwise_left_shift_(const at::Scalar &amp; other) const {</span>
<span id="L4679"><span class="lineNum">    4679</span>              :     return at::_ops::bitwise_left_shift__Tensor_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4680"><span class="lineNum">    4680</span>              : }</span>
<span id="L4681"><span class="lineNum">    4681</span>              : </span>
<span id="L4682"><span class="lineNum">    4682</span>              : // aten::__rshift__.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span id="L4683"><span class="lineNum">    4683</span>              : inline at::Tensor Tensor::__rshift__(const at::Scalar &amp; other) const {</span>
<span id="L4684"><span class="lineNum">    4684</span>              :     return at::_ops::__rshift___Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4685"><span class="lineNum">    4685</span>              : }</span>
<span id="L4686"><span class="lineNum">    4686</span>              : </span>
<span id="L4687"><span class="lineNum">    4687</span>              : // aten::__rshift__.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L4688"><span class="lineNum">    4688</span>              : inline at::Tensor Tensor::__rshift__(const at::Tensor &amp; other) const {</span>
<span id="L4689"><span class="lineNum">    4689</span>              :     return at::_ops::__rshift___Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4690"><span class="lineNum">    4690</span>              : }</span>
<span id="L4691"><span class="lineNum">    4691</span>              : </span>
<span id="L4692"><span class="lineNum">    4692</span>              : // aten::__irshift__.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span id="L4693"><span class="lineNum">    4693</span>              : inline at::Tensor &amp; Tensor::__irshift__(const at::Scalar &amp; other) const {</span>
<span id="L4694"><span class="lineNum">    4694</span>              :     return at::_ops::__irshift___Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4695"><span class="lineNum">    4695</span>              : }</span>
<span id="L4696"><span class="lineNum">    4696</span>              : </span>
<span id="L4697"><span class="lineNum">    4697</span>              : // aten::__irshift__.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L4698"><span class="lineNum">    4698</span>              : inline at::Tensor &amp; Tensor::__irshift__(const at::Tensor &amp; other) const {</span>
<span id="L4699"><span class="lineNum">    4699</span>              :     return at::_ops::__irshift___Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4700"><span class="lineNum">    4700</span>              : }</span>
<span id="L4701"><span class="lineNum">    4701</span>              : </span>
<span id="L4702"><span class="lineNum">    4702</span>              : // aten::bitwise_right_shift.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L4703"><span class="lineNum">    4703</span>              : inline at::Tensor Tensor::bitwise_right_shift(const at::Tensor &amp; other) const {</span>
<span id="L4704"><span class="lineNum">    4704</span>              :     return at::_ops::bitwise_right_shift_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4705"><span class="lineNum">    4705</span>              : }</span>
<span id="L4706"><span class="lineNum">    4706</span>              : </span>
<span id="L4707"><span class="lineNum">    4707</span>              : // aten::bitwise_right_shift_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L4708"><span class="lineNum">    4708</span>              : inline at::Tensor &amp; Tensor::bitwise_right_shift_(const at::Tensor &amp; other) const {</span>
<span id="L4709"><span class="lineNum">    4709</span>              :     return at::_ops::bitwise_right_shift__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4710"><span class="lineNum">    4710</span>              : }</span>
<span id="L4711"><span class="lineNum">    4711</span>              : </span>
<span id="L4712"><span class="lineNum">    4712</span>              : // aten::bitwise_right_shift.Tensor_Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span id="L4713"><span class="lineNum">    4713</span>              : inline at::Tensor Tensor::bitwise_right_shift(const at::Scalar &amp; other) const {</span>
<span id="L4714"><span class="lineNum">    4714</span>              :     return at::_ops::bitwise_right_shift_Tensor_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4715"><span class="lineNum">    4715</span>              : }</span>
<span id="L4716"><span class="lineNum">    4716</span>              : </span>
<span id="L4717"><span class="lineNum">    4717</span>              : // aten::bitwise_right_shift_.Tensor_Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span id="L4718"><span class="lineNum">    4718</span>              : inline at::Tensor &amp; Tensor::bitwise_right_shift_(const at::Scalar &amp; other) const {</span>
<span id="L4719"><span class="lineNum">    4719</span>              :     return at::_ops::bitwise_right_shift__Tensor_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4720"><span class="lineNum">    4720</span>              : }</span>
<span id="L4721"><span class="lineNum">    4721</span>              : </span>
<span id="L4722"><span class="lineNum">    4722</span>              : // aten::tril_(Tensor(a!) self, int diagonal=0) -&gt; Tensor(a!)</span>
<span id="L4723"><span class="lineNum">    4723</span>              : inline at::Tensor &amp; Tensor::tril_(int64_t diagonal) const {</span>
<span id="L4724"><span class="lineNum">    4724</span>              :     return at::_ops::tril_::call(const_cast&lt;Tensor&amp;&gt;(*this), diagonal);</span>
<span id="L4725"><span class="lineNum">    4725</span>              : }</span>
<span id="L4726"><span class="lineNum">    4726</span>              : </span>
<span id="L4727"><span class="lineNum">    4727</span>              : // aten::triu_(Tensor(a!) self, int diagonal=0) -&gt; Tensor(a!)</span>
<span id="L4728"><span class="lineNum">    4728</span>              : inline at::Tensor &amp; Tensor::triu_(int64_t diagonal) const {</span>
<span id="L4729"><span class="lineNum">    4729</span>              :     return at::_ops::triu_::call(const_cast&lt;Tensor&amp;&gt;(*this), diagonal);</span>
<span id="L4730"><span class="lineNum">    4730</span>              : }</span>
<span id="L4731"><span class="lineNum">    4731</span>              : </span>
<span id="L4732"><span class="lineNum">    4732</span>              : // aten::digamma_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L4733"><span class="lineNum">    4733</span>              : inline at::Tensor &amp; Tensor::digamma_() const {</span>
<span id="L4734"><span class="lineNum">    4734</span>              :     return at::_ops::digamma_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L4735"><span class="lineNum">    4735</span>              : }</span>
<span id="L4736"><span class="lineNum">    4736</span>              : </span>
<span id="L4737"><span class="lineNum">    4737</span>              : // aten::lerp_.Scalar(Tensor(a!) self, Tensor end, Scalar weight) -&gt; Tensor(a!)</span>
<span id="L4738"><span class="lineNum">    4738</span>              : inline at::Tensor &amp; Tensor::lerp_(const at::Tensor &amp; end, const at::Scalar &amp; weight) const {</span>
<span id="L4739"><span class="lineNum">    4739</span>              :     return at::_ops::lerp__Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), end, weight);</span>
<span id="L4740"><span class="lineNum">    4740</span>              : }</span>
<span id="L4741"><span class="lineNum">    4741</span>              : </span>
<span id="L4742"><span class="lineNum">    4742</span>              : // aten::lerp_.Tensor(Tensor(a!) self, Tensor end, Tensor weight) -&gt; Tensor(a!)</span>
<span id="L4743"><span class="lineNum">    4743</span>              : inline at::Tensor &amp; Tensor::lerp_(const at::Tensor &amp; end, const at::Tensor &amp; weight) const {</span>
<span id="L4744"><span class="lineNum">    4744</span>              :     return at::_ops::lerp__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), end, weight);</span>
<span id="L4745"><span class="lineNum">    4745</span>              : }</span>
<span id="L4746"><span class="lineNum">    4746</span>              : </span>
<span id="L4747"><span class="lineNum">    4747</span>              : // aten::addbmm_(Tensor(a!) self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor(a!)</span>
<span id="L4748"><span class="lineNum">    4748</span>              : inline at::Tensor &amp; Tensor::addbmm_(const at::Tensor &amp; batch1, const at::Tensor &amp; batch2, const at::Scalar &amp; beta, const at::Scalar &amp; alpha) const {</span>
<span id="L4749"><span class="lineNum">    4749</span>              :     return at::_ops::addbmm_::call(const_cast&lt;Tensor&amp;&gt;(*this), batch1, batch2, beta, alpha);</span>
<span id="L4750"><span class="lineNum">    4750</span>              : }</span>
<span id="L4751"><span class="lineNum">    4751</span>              : </span>
<span id="L4752"><span class="lineNum">    4752</span>              : // aten::addbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor</span>
<span id="L4753"><span class="lineNum">    4753</span>              : inline at::Tensor Tensor::addbmm(const at::Tensor &amp; batch1, const at::Tensor &amp; batch2, const at::Scalar &amp; beta, const at::Scalar &amp; alpha) const {</span>
<span id="L4754"><span class="lineNum">    4754</span>              :     return at::_ops::addbmm::call(const_cast&lt;Tensor&amp;&gt;(*this), batch1, batch2, beta, alpha);</span>
<span id="L4755"><span class="lineNum">    4755</span>              : }</span>
<span id="L4756"><span class="lineNum">    4756</span>              : </span>
<span id="L4757"><span class="lineNum">    4757</span>              : // aten::random_.from(Tensor(a!) self, int from, int? to, *, Generator? generator=None) -&gt; Tensor(a!)</span>
<span id="L4758"><span class="lineNum">    4758</span>              : inline at::Tensor &amp; Tensor::random_(int64_t from, ::std::optional&lt;int64_t&gt; to, ::std::optional&lt;at::Generator&gt; generator) const {</span>
<span id="L4759"><span class="lineNum">    4759</span>              :     return at::_ops::random__from::call(const_cast&lt;Tensor&amp;&gt;(*this), from, to, generator);</span>
<span id="L4760"><span class="lineNum">    4760</span>              : }</span>
<span id="L4761"><span class="lineNum">    4761</span>              : </span>
<span id="L4762"><span class="lineNum">    4762</span>              : // aten::random_.to(Tensor(a!) self, int to, *, Generator? generator=None) -&gt; Tensor(a!)</span>
<span id="L4763"><span class="lineNum">    4763</span>              : inline at::Tensor &amp; Tensor::random_(int64_t to, ::std::optional&lt;at::Generator&gt; generator) const {</span>
<span id="L4764"><span class="lineNum">    4764</span>              :     return at::_ops::random__to::call(const_cast&lt;Tensor&amp;&gt;(*this), to, generator);</span>
<span id="L4765"><span class="lineNum">    4765</span>              : }</span>
<span id="L4766"><span class="lineNum">    4766</span>              : </span>
<span id="L4767"><span class="lineNum">    4767</span>              : // aten::random_(Tensor(a!) self, *, Generator? generator=None) -&gt; Tensor(a!)</span>
<span id="L4768"><span class="lineNum">    4768</span>              : inline at::Tensor &amp; Tensor::random_(::std::optional&lt;at::Generator&gt; generator) const {</span>
<span id="L4769"><span class="lineNum">    4769</span>              :     return at::_ops::random_::call(const_cast&lt;Tensor&amp;&gt;(*this), generator);</span>
<span id="L4770"><span class="lineNum">    4770</span>              : }</span>
<span id="L4771"><span class="lineNum">    4771</span>              : </span>
<span id="L4772"><span class="lineNum">    4772</span>              : // aten::uniform_(Tensor(a!) self, float from=0, float to=1, *, Generator? generator=None) -&gt; Tensor(a!)</span>
<span id="L4773"><span class="lineNum">    4773</span>              : inline at::Tensor &amp; Tensor::uniform_(double from, double to, ::std::optional&lt;at::Generator&gt; generator) const {</span>
<span id="L4774"><span class="lineNum">    4774</span>              :     return at::_ops::uniform_::call(const_cast&lt;Tensor&amp;&gt;(*this), from, to, generator);</span>
<span id="L4775"><span class="lineNum">    4775</span>              : }</span>
<span id="L4776"><span class="lineNum">    4776</span>              : </span>
<span id="L4777"><span class="lineNum">    4777</span>              : // aten::cauchy_(Tensor(a!) self, float median=0, float sigma=1, *, Generator? generator=None) -&gt; Tensor(a!)</span>
<span id="L4778"><span class="lineNum">    4778</span>              : inline at::Tensor &amp; Tensor::cauchy_(double median, double sigma, ::std::optional&lt;at::Generator&gt; generator) const {</span>
<span id="L4779"><span class="lineNum">    4779</span>              :     return at::_ops::cauchy_::call(const_cast&lt;Tensor&amp;&gt;(*this), median, sigma, generator);</span>
<span id="L4780"><span class="lineNum">    4780</span>              : }</span>
<span id="L4781"><span class="lineNum">    4781</span>              : </span>
<span id="L4782"><span class="lineNum">    4782</span>              : // aten::log_normal_(Tensor(a!) self, float mean=1, float std=2, *, Generator? generator=None) -&gt; Tensor(a!)</span>
<span id="L4783"><span class="lineNum">    4783</span>              : inline at::Tensor &amp; Tensor::log_normal_(double mean, double std, ::std::optional&lt;at::Generator&gt; generator) const {</span>
<span id="L4784"><span class="lineNum">    4784</span>              :     return at::_ops::log_normal_::call(const_cast&lt;Tensor&amp;&gt;(*this), mean, std, generator);</span>
<span id="L4785"><span class="lineNum">    4785</span>              : }</span>
<span id="L4786"><span class="lineNum">    4786</span>              : </span>
<span id="L4787"><span class="lineNum">    4787</span>              : // aten::exponential_(Tensor(a!) self, float lambd=1, *, Generator? generator=None) -&gt; Tensor(a!)</span>
<span id="L4788"><span class="lineNum">    4788</span>              : inline at::Tensor &amp; Tensor::exponential_(double lambd, ::std::optional&lt;at::Generator&gt; generator) const {</span>
<span id="L4789"><span class="lineNum">    4789</span>              :     return at::_ops::exponential_::call(const_cast&lt;Tensor&amp;&gt;(*this), lambd, generator);</span>
<span id="L4790"><span class="lineNum">    4790</span>              : }</span>
<span id="L4791"><span class="lineNum">    4791</span>              : </span>
<span id="L4792"><span class="lineNum">    4792</span>              : // aten::geometric_(Tensor(a!) self, float p, *, Generator? generator=None) -&gt; Tensor(a!)</span>
<span id="L4793"><span class="lineNum">    4793</span>              : inline at::Tensor &amp; Tensor::geometric_(double p, ::std::optional&lt;at::Generator&gt; generator) const {</span>
<span id="L4794"><span class="lineNum">    4794</span>              :     return at::_ops::geometric_::call(const_cast&lt;Tensor&amp;&gt;(*this), p, generator);</span>
<span id="L4795"><span class="lineNum">    4795</span>              : }</span>
<span id="L4796"><span class="lineNum">    4796</span>              : </span>
<span id="L4797"><span class="lineNum">    4797</span>              : // aten::diag(Tensor self, int diagonal=0) -&gt; Tensor</span>
<span id="L4798"><span class="lineNum">    4798</span>              : inline at::Tensor Tensor::diag(int64_t diagonal) const {</span>
<span id="L4799"><span class="lineNum">    4799</span>              :     return at::_ops::diag::call(const_cast&lt;Tensor&amp;&gt;(*this), diagonal);</span>
<span id="L4800"><span class="lineNum">    4800</span>              : }</span>
<span id="L4801"><span class="lineNum">    4801</span>              : </span>
<span id="L4802"><span class="lineNum">    4802</span>              : // aten::cross(Tensor self, Tensor other, int? dim=None) -&gt; Tensor</span>
<span id="L4803"><span class="lineNum">    4803</span>              : inline at::Tensor Tensor::cross(const at::Tensor &amp; other, ::std::optional&lt;int64_t&gt; dim) const {</span>
<span id="L4804"><span class="lineNum">    4804</span>              :     return at::_ops::cross::call(const_cast&lt;Tensor&amp;&gt;(*this), other, dim);</span>
<span id="L4805"><span class="lineNum">    4805</span>              : }</span>
<span id="L4806"><span class="lineNum">    4806</span>              : </span>
<span id="L4807"><span class="lineNum">    4807</span>              : // aten::triu(Tensor self, int diagonal=0) -&gt; Tensor</span>
<span id="L4808"><span class="lineNum">    4808</span>              : inline at::Tensor Tensor::triu(int64_t diagonal) const {</span>
<span id="L4809"><span class="lineNum">    4809</span>              :     return at::_ops::triu::call(const_cast&lt;Tensor&amp;&gt;(*this), diagonal);</span>
<span id="L4810"><span class="lineNum">    4810</span>              : }</span>
<span id="L4811"><span class="lineNum">    4811</span>              : </span>
<span id="L4812"><span class="lineNum">    4812</span>              : // aten::tril(Tensor self, int diagonal=0) -&gt; Tensor</span>
<span id="L4813"><span class="lineNum">    4813</span>              : inline at::Tensor Tensor::tril(int64_t diagonal) const {</span>
<span id="L4814"><span class="lineNum">    4814</span>              :     return at::_ops::tril::call(const_cast&lt;Tensor&amp;&gt;(*this), diagonal);</span>
<span id="L4815"><span class="lineNum">    4815</span>              : }</span>
<span id="L4816"><span class="lineNum">    4816</span>              : </span>
<span id="L4817"><span class="lineNum">    4817</span>              : // aten::trace(Tensor self) -&gt; Tensor</span>
<span id="L4818"><span class="lineNum">    4818</span>              : inline at::Tensor Tensor::trace() const {</span>
<span id="L4819"><span class="lineNum">    4819</span>              :     return at::_ops::trace::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L4820"><span class="lineNum">    4820</span>              : }</span>
<span id="L4821"><span class="lineNum">    4821</span>              : </span>
<span id="L4822"><span class="lineNum">    4822</span>              : // aten::ne.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span id="L4823"><span class="lineNum">    4823</span>              : inline at::Tensor Tensor::ne(const at::Scalar &amp; other) const {</span>
<span id="L4824"><span class="lineNum">    4824</span>              :     return at::_ops::ne_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4825"><span class="lineNum">    4825</span>              : }</span>
<span id="L4826"><span class="lineNum">    4826</span>              : </span>
<span id="L4827"><span class="lineNum">    4827</span>              : // aten::ne.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L4828"><span class="lineNum">    4828</span>              : inline at::Tensor Tensor::ne(const at::Tensor &amp; other) const {</span>
<span id="L4829"><span class="lineNum">    4829</span>              :     return at::_ops::ne_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4830"><span class="lineNum">    4830</span>              : }</span>
<span id="L4831"><span class="lineNum">    4831</span>              : </span>
<span id="L4832"><span class="lineNum">    4832</span>              : // aten::ne_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span id="L4833"><span class="lineNum">    4833</span>              : inline at::Tensor &amp; Tensor::ne_(const at::Scalar &amp; other) const {</span>
<span id="L4834"><span class="lineNum">    4834</span>              :     return at::_ops::ne__Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4835"><span class="lineNum">    4835</span>              : }</span>
<span id="L4836"><span class="lineNum">    4836</span>              : </span>
<span id="L4837"><span class="lineNum">    4837</span>              : // aten::ne_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L4838"><span class="lineNum">    4838</span>              : inline at::Tensor &amp; Tensor::ne_(const at::Tensor &amp; other) const {</span>
<span id="L4839"><span class="lineNum">    4839</span>              :     return at::_ops::ne__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4840"><span class="lineNum">    4840</span>              : }</span>
<span id="L4841"><span class="lineNum">    4841</span>              : </span>
<span id="L4842"><span class="lineNum">    4842</span>              : // aten::not_equal.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span id="L4843"><span class="lineNum">    4843</span>              : inline at::Tensor Tensor::not_equal(const at::Scalar &amp; other) const {</span>
<span id="L4844"><span class="lineNum">    4844</span>              :     return at::_ops::not_equal_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4845"><span class="lineNum">    4845</span>              : }</span>
<span id="L4846"><span class="lineNum">    4846</span>              : </span>
<span id="L4847"><span class="lineNum">    4847</span>              : // aten::not_equal.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L4848"><span class="lineNum">    4848</span>              : inline at::Tensor Tensor::not_equal(const at::Tensor &amp; other) const {</span>
<span id="L4849"><span class="lineNum">    4849</span>              :     return at::_ops::not_equal_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4850"><span class="lineNum">    4850</span>              : }</span>
<span id="L4851"><span class="lineNum">    4851</span>              : </span>
<span id="L4852"><span class="lineNum">    4852</span>              : // aten::not_equal_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span id="L4853"><span class="lineNum">    4853</span>              : inline at::Tensor &amp; Tensor::not_equal_(const at::Scalar &amp; other) const {</span>
<span id="L4854"><span class="lineNum">    4854</span>              :     return at::_ops::not_equal__Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4855"><span class="lineNum">    4855</span>              : }</span>
<span id="L4856"><span class="lineNum">    4856</span>              : </span>
<span id="L4857"><span class="lineNum">    4857</span>              : // aten::not_equal_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L4858"><span class="lineNum">    4858</span>              : inline at::Tensor &amp; Tensor::not_equal_(const at::Tensor &amp; other) const {</span>
<span id="L4859"><span class="lineNum">    4859</span>              :     return at::_ops::not_equal__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4860"><span class="lineNum">    4860</span>              : }</span>
<span id="L4861"><span class="lineNum">    4861</span>              : </span>
<span id="L4862"><span class="lineNum">    4862</span>              : // aten::eq.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span id="L4863"><span class="lineNum">    4863</span>              : inline at::Tensor Tensor::eq(const at::Scalar &amp; other) const {</span>
<span id="L4864"><span class="lineNum">    4864</span>              :     return at::_ops::eq_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4865"><span class="lineNum">    4865</span>              : }</span>
<span id="L4866"><span class="lineNum">    4866</span>              : </span>
<span id="L4867"><span class="lineNum">    4867</span>              : // aten::eq.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L4868"><span class="lineNum">    4868</span>              : inline at::Tensor Tensor::eq(const at::Tensor &amp; other) const {</span>
<span id="L4869"><span class="lineNum">    4869</span>              :     return at::_ops::eq_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4870"><span class="lineNum">    4870</span>              : }</span>
<span id="L4871"><span class="lineNum">    4871</span>              : </span>
<span id="L4872"><span class="lineNum">    4872</span>              : // aten::ge.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span id="L4873"><span class="lineNum">    4873</span>              : inline at::Tensor Tensor::ge(const at::Scalar &amp; other) const {</span>
<span id="L4874"><span class="lineNum">    4874</span>              :     return at::_ops::ge_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4875"><span class="lineNum">    4875</span>              : }</span>
<span id="L4876"><span class="lineNum">    4876</span>              : </span>
<span id="L4877"><span class="lineNum">    4877</span>              : // aten::ge.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L4878"><span class="lineNum">    4878</span>              : inline at::Tensor Tensor::ge(const at::Tensor &amp; other) const {</span>
<span id="L4879"><span class="lineNum">    4879</span>              :     return at::_ops::ge_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4880"><span class="lineNum">    4880</span>              : }</span>
<span id="L4881"><span class="lineNum">    4881</span>              : </span>
<span id="L4882"><span class="lineNum">    4882</span>              : // aten::ge_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span id="L4883"><span class="lineNum">    4883</span>              : inline at::Tensor &amp; Tensor::ge_(const at::Scalar &amp; other) const {</span>
<span id="L4884"><span class="lineNum">    4884</span>              :     return at::_ops::ge__Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4885"><span class="lineNum">    4885</span>              : }</span>
<span id="L4886"><span class="lineNum">    4886</span>              : </span>
<span id="L4887"><span class="lineNum">    4887</span>              : // aten::ge_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L4888"><span class="lineNum">    4888</span>              : inline at::Tensor &amp; Tensor::ge_(const at::Tensor &amp; other) const {</span>
<span id="L4889"><span class="lineNum">    4889</span>              :     return at::_ops::ge__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4890"><span class="lineNum">    4890</span>              : }</span>
<span id="L4891"><span class="lineNum">    4891</span>              : </span>
<span id="L4892"><span class="lineNum">    4892</span>              : // aten::greater_equal.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span id="L4893"><span class="lineNum">    4893</span>              : inline at::Tensor Tensor::greater_equal(const at::Scalar &amp; other) const {</span>
<span id="L4894"><span class="lineNum">    4894</span>              :     return at::_ops::greater_equal_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4895"><span class="lineNum">    4895</span>              : }</span>
<span id="L4896"><span class="lineNum">    4896</span>              : </span>
<span id="L4897"><span class="lineNum">    4897</span>              : // aten::greater_equal.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L4898"><span class="lineNum">    4898</span>              : inline at::Tensor Tensor::greater_equal(const at::Tensor &amp; other) const {</span>
<span id="L4899"><span class="lineNum">    4899</span>              :     return at::_ops::greater_equal_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4900"><span class="lineNum">    4900</span>              : }</span>
<span id="L4901"><span class="lineNum">    4901</span>              : </span>
<span id="L4902"><span class="lineNum">    4902</span>              : // aten::greater_equal_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span id="L4903"><span class="lineNum">    4903</span>              : inline at::Tensor &amp; Tensor::greater_equal_(const at::Scalar &amp; other) const {</span>
<span id="L4904"><span class="lineNum">    4904</span>              :     return at::_ops::greater_equal__Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4905"><span class="lineNum">    4905</span>              : }</span>
<span id="L4906"><span class="lineNum">    4906</span>              : </span>
<span id="L4907"><span class="lineNum">    4907</span>              : // aten::greater_equal_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L4908"><span class="lineNum">    4908</span>              : inline at::Tensor &amp; Tensor::greater_equal_(const at::Tensor &amp; other) const {</span>
<span id="L4909"><span class="lineNum">    4909</span>              :     return at::_ops::greater_equal__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4910"><span class="lineNum">    4910</span>              : }</span>
<span id="L4911"><span class="lineNum">    4911</span>              : </span>
<span id="L4912"><span class="lineNum">    4912</span>              : // aten::le.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span id="L4913"><span class="lineNum">    4913</span>              : inline at::Tensor Tensor::le(const at::Scalar &amp; other) const {</span>
<span id="L4914"><span class="lineNum">    4914</span>              :     return at::_ops::le_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4915"><span class="lineNum">    4915</span>              : }</span>
<span id="L4916"><span class="lineNum">    4916</span>              : </span>
<span id="L4917"><span class="lineNum">    4917</span>              : // aten::le.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L4918"><span class="lineNum">    4918</span>              : inline at::Tensor Tensor::le(const at::Tensor &amp; other) const {</span>
<span id="L4919"><span class="lineNum">    4919</span>              :     return at::_ops::le_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4920"><span class="lineNum">    4920</span>              : }</span>
<span id="L4921"><span class="lineNum">    4921</span>              : </span>
<span id="L4922"><span class="lineNum">    4922</span>              : // aten::le_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span id="L4923"><span class="lineNum">    4923</span>              : inline at::Tensor &amp; Tensor::le_(const at::Scalar &amp; other) const {</span>
<span id="L4924"><span class="lineNum">    4924</span>              :     return at::_ops::le__Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4925"><span class="lineNum">    4925</span>              : }</span>
<span id="L4926"><span class="lineNum">    4926</span>              : </span>
<span id="L4927"><span class="lineNum">    4927</span>              : // aten::le_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L4928"><span class="lineNum">    4928</span>              : inline at::Tensor &amp; Tensor::le_(const at::Tensor &amp; other) const {</span>
<span id="L4929"><span class="lineNum">    4929</span>              :     return at::_ops::le__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4930"><span class="lineNum">    4930</span>              : }</span>
<span id="L4931"><span class="lineNum">    4931</span>              : </span>
<span id="L4932"><span class="lineNum">    4932</span>              : // aten::less_equal.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span id="L4933"><span class="lineNum">    4933</span>              : inline at::Tensor Tensor::less_equal(const at::Scalar &amp; other) const {</span>
<span id="L4934"><span class="lineNum">    4934</span>              :     return at::_ops::less_equal_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4935"><span class="lineNum">    4935</span>              : }</span>
<span id="L4936"><span class="lineNum">    4936</span>              : </span>
<span id="L4937"><span class="lineNum">    4937</span>              : // aten::less_equal.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L4938"><span class="lineNum">    4938</span>              : inline at::Tensor Tensor::less_equal(const at::Tensor &amp; other) const {</span>
<span id="L4939"><span class="lineNum">    4939</span>              :     return at::_ops::less_equal_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4940"><span class="lineNum">    4940</span>              : }</span>
<span id="L4941"><span class="lineNum">    4941</span>              : </span>
<span id="L4942"><span class="lineNum">    4942</span>              : // aten::less_equal_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span id="L4943"><span class="lineNum">    4943</span>              : inline at::Tensor &amp; Tensor::less_equal_(const at::Scalar &amp; other) const {</span>
<span id="L4944"><span class="lineNum">    4944</span>              :     return at::_ops::less_equal__Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4945"><span class="lineNum">    4945</span>              : }</span>
<span id="L4946"><span class="lineNum">    4946</span>              : </span>
<span id="L4947"><span class="lineNum">    4947</span>              : // aten::less_equal_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L4948"><span class="lineNum">    4948</span>              : inline at::Tensor &amp; Tensor::less_equal_(const at::Tensor &amp; other) const {</span>
<span id="L4949"><span class="lineNum">    4949</span>              :     return at::_ops::less_equal__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4950"><span class="lineNum">    4950</span>              : }</span>
<span id="L4951"><span class="lineNum">    4951</span>              : </span>
<span id="L4952"><span class="lineNum">    4952</span>              : // aten::gt.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span id="L4953"><span class="lineNum">    4953</span>              : inline at::Tensor Tensor::gt(const at::Scalar &amp; other) const {</span>
<span id="L4954"><span class="lineNum">    4954</span>              :     return at::_ops::gt_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4955"><span class="lineNum">    4955</span>              : }</span>
<span id="L4956"><span class="lineNum">    4956</span>              : </span>
<span id="L4957"><span class="lineNum">    4957</span>              : // aten::gt.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L4958"><span class="lineNum">    4958</span>              : inline at::Tensor Tensor::gt(const at::Tensor &amp; other) const {</span>
<span id="L4959"><span class="lineNum">    4959</span>              :     return at::_ops::gt_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4960"><span class="lineNum">    4960</span>              : }</span>
<span id="L4961"><span class="lineNum">    4961</span>              : </span>
<span id="L4962"><span class="lineNum">    4962</span>              : // aten::gt_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span id="L4963"><span class="lineNum">    4963</span>              : inline at::Tensor &amp; Tensor::gt_(const at::Scalar &amp; other) const {</span>
<span id="L4964"><span class="lineNum">    4964</span>              :     return at::_ops::gt__Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4965"><span class="lineNum">    4965</span>              : }</span>
<span id="L4966"><span class="lineNum">    4966</span>              : </span>
<span id="L4967"><span class="lineNum">    4967</span>              : // aten::gt_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L4968"><span class="lineNum">    4968</span>              : inline at::Tensor &amp; Tensor::gt_(const at::Tensor &amp; other) const {</span>
<span id="L4969"><span class="lineNum">    4969</span>              :     return at::_ops::gt__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4970"><span class="lineNum">    4970</span>              : }</span>
<span id="L4971"><span class="lineNum">    4971</span>              : </span>
<span id="L4972"><span class="lineNum">    4972</span>              : // aten::greater.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span id="L4973"><span class="lineNum">    4973</span>              : inline at::Tensor Tensor::greater(const at::Scalar &amp; other) const {</span>
<span id="L4974"><span class="lineNum">    4974</span>              :     return at::_ops::greater_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4975"><span class="lineNum">    4975</span>              : }</span>
<span id="L4976"><span class="lineNum">    4976</span>              : </span>
<span id="L4977"><span class="lineNum">    4977</span>              : // aten::greater.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L4978"><span class="lineNum">    4978</span>              : inline at::Tensor Tensor::greater(const at::Tensor &amp; other) const {</span>
<span id="L4979"><span class="lineNum">    4979</span>              :     return at::_ops::greater_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4980"><span class="lineNum">    4980</span>              : }</span>
<span id="L4981"><span class="lineNum">    4981</span>              : </span>
<span id="L4982"><span class="lineNum">    4982</span>              : // aten::greater_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span id="L4983"><span class="lineNum">    4983</span>              : inline at::Tensor &amp; Tensor::greater_(const at::Scalar &amp; other) const {</span>
<span id="L4984"><span class="lineNum">    4984</span>              :     return at::_ops::greater__Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4985"><span class="lineNum">    4985</span>              : }</span>
<span id="L4986"><span class="lineNum">    4986</span>              : </span>
<span id="L4987"><span class="lineNum">    4987</span>              : // aten::greater_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L4988"><span class="lineNum">    4988</span>              : inline at::Tensor &amp; Tensor::greater_(const at::Tensor &amp; other) const {</span>
<span id="L4989"><span class="lineNum">    4989</span>              :     return at::_ops::greater__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4990"><span class="lineNum">    4990</span>              : }</span>
<span id="L4991"><span class="lineNum">    4991</span>              : </span>
<span id="L4992"><span class="lineNum">    4992</span>              : // aten::lt.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span id="L4993"><span class="lineNum">    4993</span>              : inline at::Tensor Tensor::lt(const at::Scalar &amp; other) const {</span>
<span id="L4994"><span class="lineNum">    4994</span>              :     return at::_ops::lt_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L4995"><span class="lineNum">    4995</span>              : }</span>
<span id="L4996"><span class="lineNum">    4996</span>              : </span>
<span id="L4997"><span class="lineNum">    4997</span>              : // aten::lt.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L4998"><span class="lineNum">    4998</span>              : inline at::Tensor Tensor::lt(const at::Tensor &amp; other) const {</span>
<span id="L4999"><span class="lineNum">    4999</span>              :     return at::_ops::lt_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L5000"><span class="lineNum">    5000</span>              : }</span>
<span id="L5001"><span class="lineNum">    5001</span>              : </span>
<span id="L5002"><span class="lineNum">    5002</span>              : // aten::lt_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span id="L5003"><span class="lineNum">    5003</span>              : inline at::Tensor &amp; Tensor::lt_(const at::Scalar &amp; other) const {</span>
<span id="L5004"><span class="lineNum">    5004</span>              :     return at::_ops::lt__Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L5005"><span class="lineNum">    5005</span>              : }</span>
<span id="L5006"><span class="lineNum">    5006</span>              : </span>
<span id="L5007"><span class="lineNum">    5007</span>              : // aten::lt_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L5008"><span class="lineNum">    5008</span>              : inline at::Tensor &amp; Tensor::lt_(const at::Tensor &amp; other) const {</span>
<span id="L5009"><span class="lineNum">    5009</span>              :     return at::_ops::lt__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L5010"><span class="lineNum">    5010</span>              : }</span>
<span id="L5011"><span class="lineNum">    5011</span>              : </span>
<span id="L5012"><span class="lineNum">    5012</span>              : // aten::less.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span id="L5013"><span class="lineNum">    5013</span>              : inline at::Tensor Tensor::less(const at::Scalar &amp; other) const {</span>
<span id="L5014"><span class="lineNum">    5014</span>              :     return at::_ops::less_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L5015"><span class="lineNum">    5015</span>              : }</span>
<span id="L5016"><span class="lineNum">    5016</span>              : </span>
<span id="L5017"><span class="lineNum">    5017</span>              : // aten::less.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L5018"><span class="lineNum">    5018</span>              : inline at::Tensor Tensor::less(const at::Tensor &amp; other) const {</span>
<span id="L5019"><span class="lineNum">    5019</span>              :     return at::_ops::less_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L5020"><span class="lineNum">    5020</span>              : }</span>
<span id="L5021"><span class="lineNum">    5021</span>              : </span>
<span id="L5022"><span class="lineNum">    5022</span>              : // aten::less_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span id="L5023"><span class="lineNum">    5023</span>              : inline at::Tensor &amp; Tensor::less_(const at::Scalar &amp; other) const {</span>
<span id="L5024"><span class="lineNum">    5024</span>              :     return at::_ops::less__Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L5025"><span class="lineNum">    5025</span>              : }</span>
<span id="L5026"><span class="lineNum">    5026</span>              : </span>
<span id="L5027"><span class="lineNum">    5027</span>              : // aten::less_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L5028"><span class="lineNum">    5028</span>              : inline at::Tensor &amp; Tensor::less_(const at::Tensor &amp; other) const {</span>
<span id="L5029"><span class="lineNum">    5029</span>              :     return at::_ops::less__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L5030"><span class="lineNum">    5030</span>              : }</span>
<span id="L5031"><span class="lineNum">    5031</span>              : </span>
<span id="L5032"><span class="lineNum">    5032</span>              : // aten::take(Tensor self, Tensor index) -&gt; Tensor</span>
<span id="L5033"><span class="lineNum">    5033</span>              : inline at::Tensor Tensor::take(const at::Tensor &amp; index) const {</span>
<span id="L5034"><span class="lineNum">    5034</span>              :     return at::_ops::take::call(const_cast&lt;Tensor&amp;&gt;(*this), index);</span>
<span id="L5035"><span class="lineNum">    5035</span>              : }</span>
<span id="L5036"><span class="lineNum">    5036</span>              : </span>
<span id="L5037"><span class="lineNum">    5037</span>              : // aten::take_along_dim(Tensor self, Tensor indices, int? dim=None) -&gt; Tensor</span>
<span id="L5038"><span class="lineNum">    5038</span>              : inline at::Tensor Tensor::take_along_dim(const at::Tensor &amp; indices, ::std::optional&lt;int64_t&gt; dim) const {</span>
<span id="L5039"><span class="lineNum">    5039</span>              :     return at::_ops::take_along_dim::call(const_cast&lt;Tensor&amp;&gt;(*this), indices, dim);</span>
<span id="L5040"><span class="lineNum">    5040</span>              : }</span>
<span id="L5041"><span class="lineNum">    5041</span>              : </span>
<span id="L5042"><span class="lineNum">    5042</span>              : // aten::index_select(Tensor self, int dim, Tensor index) -&gt; Tensor</span>
<span id="L5043"><span class="lineNum">    5043</span>              : inline at::Tensor Tensor::index_select(int64_t dim, const at::Tensor &amp; index) const {</span>
<span id="L5044"><span class="lineNum">    5044</span>              :     return at::_ops::index_select::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index);</span>
<span id="L5045"><span class="lineNum">    5045</span>              : }</span>
<span id="L5046"><span class="lineNum">    5046</span>              : </span>
<span id="L5047"><span class="lineNum">    5047</span>              : // aten::index_select.dimname(Tensor self, Dimname dim, Tensor index) -&gt; Tensor</span>
<span id="L5048"><span class="lineNum">    5048</span>              : inline at::Tensor Tensor::index_select(at::Dimname dim, const at::Tensor &amp; index) const {</span>
<span id="L5049"><span class="lineNum">    5049</span>              :     return at::_ops::index_select_dimname::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index);</span>
<span id="L5050"><span class="lineNum">    5050</span>              : }</span>
<span id="L5051"><span class="lineNum">    5051</span>              : </span>
<span id="L5052"><span class="lineNum">    5052</span>              : // aten::masked_select(Tensor self, Tensor mask) -&gt; Tensor</span>
<span id="L5053"><span class="lineNum">    5053</span>              : inline at::Tensor Tensor::masked_select(const at::Tensor &amp; mask) const {</span>
<span id="L5054"><span class="lineNum">    5054</span>              :     return at::_ops::masked_select::call(const_cast&lt;Tensor&amp;&gt;(*this), mask);</span>
<span id="L5055"><span class="lineNum">    5055</span>              : }</span>
<span id="L5056"><span class="lineNum">    5056</span>              : </span>
<span id="L5057"><span class="lineNum">    5057</span>              : // aten::nonzero(Tensor self) -&gt; Tensor</span>
<span id="L5058"><span class="lineNum">    5058</span>              : inline at::Tensor Tensor::nonzero() const {</span>
<span id="L5059"><span class="lineNum">    5059</span>              :     return at::_ops::nonzero::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L5060"><span class="lineNum">    5060</span>              : }</span>
<span id="L5061"><span class="lineNum">    5061</span>              : </span>
<span id="L5062"><span class="lineNum">    5062</span>              : // aten::nonzero_static(Tensor self, *, int size, int fill_value=-1) -&gt; Tensor</span>
<span id="L5063"><span class="lineNum">    5063</span>              : inline at::Tensor Tensor::nonzero_static(int64_t size, int64_t fill_value) const {</span>
<span id="L5064"><span class="lineNum">    5064</span>              :     return at::_ops::nonzero_static::call(const_cast&lt;Tensor&amp;&gt;(*this), size, fill_value);</span>
<span id="L5065"><span class="lineNum">    5065</span>              : }</span>
<span id="L5066"><span class="lineNum">    5066</span>              : </span>
<span id="L5067"><span class="lineNum">    5067</span>              : // aten::nonzero_numpy(Tensor self) -&gt; Tensor[]</span>
<span id="L5068"><span class="lineNum">    5068</span>              : inline ::std::vector&lt;at::Tensor&gt; Tensor::nonzero_numpy() const {</span>
<span id="L5069"><span class="lineNum">    5069</span>              :     return at::_ops::nonzero_numpy::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L5070"><span class="lineNum">    5070</span>              : }</span>
<span id="L5071"><span class="lineNum">    5071</span>              : </span>
<span id="L5072"><span class="lineNum">    5072</span>              : // aten::argwhere(Tensor self) -&gt; Tensor</span>
<span id="L5073"><span class="lineNum">    5073</span>              : inline at::Tensor Tensor::argwhere() const {</span>
<span id="L5074"><span class="lineNum">    5074</span>              :     return at::_ops::argwhere::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L5075"><span class="lineNum">    5075</span>              : }</span>
<span id="L5076"><span class="lineNum">    5076</span>              : </span>
<span id="L5077"><span class="lineNum">    5077</span>              : // aten::gather(Tensor self, int dim, Tensor index, *, bool sparse_grad=False) -&gt; Tensor</span>
<span id="L5078"><span class="lineNum">    5078</span>              : inline at::Tensor Tensor::gather(int64_t dim, const at::Tensor &amp; index, bool sparse_grad) const {</span>
<span id="L5079"><span class="lineNum">    5079</span>              :     return at::_ops::gather::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index, sparse_grad);</span>
<span id="L5080"><span class="lineNum">    5080</span>              : }</span>
<span id="L5081"><span class="lineNum">    5081</span>              : </span>
<span id="L5082"><span class="lineNum">    5082</span>              : // aten::gather.dimname(Tensor self, Dimname dim, Tensor index, *, bool sparse_grad=False) -&gt; Tensor</span>
<span id="L5083"><span class="lineNum">    5083</span>              : inline at::Tensor Tensor::gather(at::Dimname dim, const at::Tensor &amp; index, bool sparse_grad) const {</span>
<span id="L5084"><span class="lineNum">    5084</span>              :     return at::_ops::gather_dimname::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, index, sparse_grad);</span>
<span id="L5085"><span class="lineNum">    5085</span>              : }</span>
<span id="L5086"><span class="lineNum">    5086</span>              : </span>
<span id="L5087"><span class="lineNum">    5087</span>              : // aten::addcmul(Tensor self, Tensor tensor1, Tensor tensor2, *, Scalar value=1) -&gt; Tensor</span>
<span id="L5088"><span class="lineNum">    5088</span>              : inline at::Tensor Tensor::addcmul(const at::Tensor &amp; tensor1, const at::Tensor &amp; tensor2, const at::Scalar &amp; value) const {</span>
<span id="L5089"><span class="lineNum">    5089</span>              :     return at::_ops::addcmul::call(const_cast&lt;Tensor&amp;&gt;(*this), tensor1, tensor2, value);</span>
<span id="L5090"><span class="lineNum">    5090</span>              : }</span>
<span id="L5091"><span class="lineNum">    5091</span>              : </span>
<span id="L5092"><span class="lineNum">    5092</span>              : // aten::addcmul_(Tensor(a!) self, Tensor tensor1, Tensor tensor2, *, Scalar value=1) -&gt; Tensor(a!)</span>
<span id="L5093"><span class="lineNum">    5093</span>              : inline at::Tensor &amp; Tensor::addcmul_(const at::Tensor &amp; tensor1, const at::Tensor &amp; tensor2, const at::Scalar &amp; value) const {</span>
<span id="L5094"><span class="lineNum">    5094</span>              :     return at::_ops::addcmul_::call(const_cast&lt;Tensor&amp;&gt;(*this), tensor1, tensor2, value);</span>
<span id="L5095"><span class="lineNum">    5095</span>              : }</span>
<span id="L5096"><span class="lineNum">    5096</span>              : </span>
<span id="L5097"><span class="lineNum">    5097</span>              : // aten::addcdiv(Tensor self, Tensor tensor1, Tensor tensor2, *, Scalar value=1) -&gt; Tensor</span>
<span id="L5098"><span class="lineNum">    5098</span>              : inline at::Tensor Tensor::addcdiv(const at::Tensor &amp; tensor1, const at::Tensor &amp; tensor2, const at::Scalar &amp; value) const {</span>
<span id="L5099"><span class="lineNum">    5099</span>              :     return at::_ops::addcdiv::call(const_cast&lt;Tensor&amp;&gt;(*this), tensor1, tensor2, value);</span>
<span id="L5100"><span class="lineNum">    5100</span>              : }</span>
<span id="L5101"><span class="lineNum">    5101</span>              : </span>
<span id="L5102"><span class="lineNum">    5102</span>              : // aten::addcdiv_(Tensor(a!) self, Tensor tensor1, Tensor tensor2, *, Scalar value=1) -&gt; Tensor(a!)</span>
<span id="L5103"><span class="lineNum">    5103</span>              : inline at::Tensor &amp; Tensor::addcdiv_(const at::Tensor &amp; tensor1, const at::Tensor &amp; tensor2, const at::Scalar &amp; value) const {</span>
<span id="L5104"><span class="lineNum">    5104</span>              :     return at::_ops::addcdiv_::call(const_cast&lt;Tensor&amp;&gt;(*this), tensor1, tensor2, value);</span>
<span id="L5105"><span class="lineNum">    5105</span>              : }</span>
<span id="L5106"><span class="lineNum">    5106</span>              : </span>
<span id="L5107"><span class="lineNum">    5107</span>              : // aten::triangular_solve(Tensor self, Tensor A, bool upper=True, bool transpose=False, bool unitriangular=False) -&gt; (Tensor solution, Tensor cloned_coefficient)</span>
<span id="L5108"><span class="lineNum">    5108</span>              : inline ::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::triangular_solve(const at::Tensor &amp; A, bool upper, bool transpose, bool unitriangular) const {</span>
<span id="L5109"><span class="lineNum">    5109</span>              :     return at::_ops::triangular_solve::call(const_cast&lt;Tensor&amp;&gt;(*this), A, upper, transpose, unitriangular);</span>
<span id="L5110"><span class="lineNum">    5110</span>              : }</span>
<span id="L5111"><span class="lineNum">    5111</span>              : </span>
<span id="L5112"><span class="lineNum">    5112</span>              : // aten::svd(Tensor self, bool some=True, bool compute_uv=True) -&gt; (Tensor U, Tensor S, Tensor V)</span>
<span id="L5113"><span class="lineNum">    5113</span>              : inline ::std::tuple&lt;at::Tensor,at::Tensor,at::Tensor&gt; Tensor::svd(bool some, bool compute_uv) const {</span>
<span id="L5114"><span class="lineNum">    5114</span>              :     return at::_ops::svd::call(const_cast&lt;Tensor&amp;&gt;(*this), some, compute_uv);</span>
<span id="L5115"><span class="lineNum">    5115</span>              : }</span>
<span id="L5116"><span class="lineNum">    5116</span>              : </span>
<span id="L5117"><span class="lineNum">    5117</span>              : // aten::swapaxes(Tensor(a) self, int axis0, int axis1) -&gt; Tensor(a)</span>
<span id="L5118"><span class="lineNum">    5118</span>              : inline at::Tensor Tensor::swapaxes(int64_t axis0, int64_t axis1) const {</span>
<span id="L5119"><span class="lineNum">    5119</span>              :     return at::_ops::swapaxes::call(const_cast&lt;Tensor&amp;&gt;(*this), axis0, axis1);</span>
<span id="L5120"><span class="lineNum">    5120</span>              : }</span>
<span id="L5121"><span class="lineNum">    5121</span>              : </span>
<span id="L5122"><span class="lineNum">    5122</span>              : // aten::swapaxes_(Tensor(a!) self, int axis0, int axis1) -&gt; Tensor(a!)</span>
<span id="L5123"><span class="lineNum">    5123</span>              : inline at::Tensor &amp; Tensor::swapaxes_(int64_t axis0, int64_t axis1) const {</span>
<span id="L5124"><span class="lineNum">    5124</span>              :     return at::_ops::swapaxes_::call(const_cast&lt;Tensor&amp;&gt;(*this), axis0, axis1);</span>
<span id="L5125"><span class="lineNum">    5125</span>              : }</span>
<span id="L5126"><span class="lineNum">    5126</span>              : </span>
<span id="L5127"><span class="lineNum">    5127</span>              : // aten::swapdims(Tensor(a) self, int dim0, int dim1) -&gt; Tensor(a)</span>
<span id="L5128"><span class="lineNum">    5128</span>              : inline at::Tensor Tensor::swapdims(int64_t dim0, int64_t dim1) const {</span>
<span id="L5129"><span class="lineNum">    5129</span>              :     return at::_ops::swapdims::call(const_cast&lt;Tensor&amp;&gt;(*this), dim0, dim1);</span>
<span id="L5130"><span class="lineNum">    5130</span>              : }</span>
<span id="L5131"><span class="lineNum">    5131</span>              : </span>
<span id="L5132"><span class="lineNum">    5132</span>              : // aten::swapdims_(Tensor(a!) self, int dim0, int dim1) -&gt; Tensor(a!)</span>
<span id="L5133"><span class="lineNum">    5133</span>              : inline at::Tensor &amp; Tensor::swapdims_(int64_t dim0, int64_t dim1) const {</span>
<span id="L5134"><span class="lineNum">    5134</span>              :     return at::_ops::swapdims_::call(const_cast&lt;Tensor&amp;&gt;(*this), dim0, dim1);</span>
<span id="L5135"><span class="lineNum">    5135</span>              : }</span>
<span id="L5136"><span class="lineNum">    5136</span>              : </span>
<span id="L5137"><span class="lineNum">    5137</span>              : // aten::cholesky(Tensor self, bool upper=False) -&gt; Tensor</span>
<span id="L5138"><span class="lineNum">    5138</span>              : inline at::Tensor Tensor::cholesky(bool upper) const {</span>
<span id="L5139"><span class="lineNum">    5139</span>              :     return at::_ops::cholesky::call(const_cast&lt;Tensor&amp;&gt;(*this), upper);</span>
<span id="L5140"><span class="lineNum">    5140</span>              : }</span>
<span id="L5141"><span class="lineNum">    5141</span>              : </span>
<span id="L5142"><span class="lineNum">    5142</span>              : // aten::cholesky_solve(Tensor self, Tensor input2, bool upper=False) -&gt; Tensor</span>
<span id="L5143"><span class="lineNum">    5143</span>              : inline at::Tensor Tensor::cholesky_solve(const at::Tensor &amp; input2, bool upper) const {</span>
<span id="L5144"><span class="lineNum">    5144</span>              :     return at::_ops::cholesky_solve::call(const_cast&lt;Tensor&amp;&gt;(*this), input2, upper);</span>
<span id="L5145"><span class="lineNum">    5145</span>              : }</span>
<span id="L5146"><span class="lineNum">    5146</span>              : </span>
<span id="L5147"><span class="lineNum">    5147</span>              : // aten::cholesky_inverse(Tensor self, bool upper=False) -&gt; Tensor</span>
<span id="L5148"><span class="lineNum">    5148</span>              : inline at::Tensor Tensor::cholesky_inverse(bool upper) const {</span>
<span id="L5149"><span class="lineNum">    5149</span>              :     return at::_ops::cholesky_inverse::call(const_cast&lt;Tensor&amp;&gt;(*this), upper);</span>
<span id="L5150"><span class="lineNum">    5150</span>              : }</span>
<span id="L5151"><span class="lineNum">    5151</span>              : </span>
<span id="L5152"><span class="lineNum">    5152</span>              : // aten::qr(Tensor self, bool some=True) -&gt; (Tensor Q, Tensor R)</span>
<span id="L5153"><span class="lineNum">    5153</span>              : inline ::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::qr(bool some) const {</span>
<span id="L5154"><span class="lineNum">    5154</span>              :     return at::_ops::qr::call(const_cast&lt;Tensor&amp;&gt;(*this), some);</span>
<span id="L5155"><span class="lineNum">    5155</span>              : }</span>
<span id="L5156"><span class="lineNum">    5156</span>              : </span>
<span id="L5157"><span class="lineNum">    5157</span>              : // aten::geqrf(Tensor self) -&gt; (Tensor a, Tensor tau)</span>
<span id="L5158"><span class="lineNum">    5158</span>              : inline ::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::geqrf() const {</span>
<span id="L5159"><span class="lineNum">    5159</span>              :     return at::_ops::geqrf::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L5160"><span class="lineNum">    5160</span>              : }</span>
<span id="L5161"><span class="lineNum">    5161</span>              : </span>
<span id="L5162"><span class="lineNum">    5162</span>              : // aten::orgqr(Tensor self, Tensor input2) -&gt; Tensor</span>
<span id="L5163"><span class="lineNum">    5163</span>              : inline at::Tensor Tensor::orgqr(const at::Tensor &amp; input2) const {</span>
<span id="L5164"><span class="lineNum">    5164</span>              :     return at::_ops::orgqr::call(const_cast&lt;Tensor&amp;&gt;(*this), input2);</span>
<span id="L5165"><span class="lineNum">    5165</span>              : }</span>
<span id="L5166"><span class="lineNum">    5166</span>              : </span>
<span id="L5167"><span class="lineNum">    5167</span>              : // aten::ormqr(Tensor self, Tensor input2, Tensor input3, bool left=True, bool transpose=False) -&gt; Tensor</span>
<span id="L5168"><span class="lineNum">    5168</span>              : inline at::Tensor Tensor::ormqr(const at::Tensor &amp; input2, const at::Tensor &amp; input3, bool left, bool transpose) const {</span>
<span id="L5169"><span class="lineNum">    5169</span>              :     return at::_ops::ormqr::call(const_cast&lt;Tensor&amp;&gt;(*this), input2, input3, left, transpose);</span>
<span id="L5170"><span class="lineNum">    5170</span>              : }</span>
<span id="L5171"><span class="lineNum">    5171</span>              : </span>
<span id="L5172"><span class="lineNum">    5172</span>              : // aten::lu_solve(Tensor self, Tensor LU_data, Tensor LU_pivots) -&gt; Tensor</span>
<span id="L5173"><span class="lineNum">    5173</span>              : inline at::Tensor Tensor::lu_solve(const at::Tensor &amp; LU_data, const at::Tensor &amp; LU_pivots) const {</span>
<span id="L5174"><span class="lineNum">    5174</span>              :     return at::_ops::lu_solve::call(const_cast&lt;Tensor&amp;&gt;(*this), LU_data, LU_pivots);</span>
<span id="L5175"><span class="lineNum">    5175</span>              : }</span>
<span id="L5176"><span class="lineNum">    5176</span>              : </span>
<span id="L5177"><span class="lineNum">    5177</span>              : // aten::multinomial(Tensor self, int num_samples, bool replacement=False, *, Generator? generator=None) -&gt; Tensor</span>
<span id="L5178"><span class="lineNum">    5178</span>              : inline at::Tensor Tensor::multinomial(int64_t num_samples, bool replacement, ::std::optional&lt;at::Generator&gt; generator) const {</span>
<span id="L5179"><span class="lineNum">    5179</span>              :     return at::_ops::multinomial::call(const_cast&lt;Tensor&amp;&gt;(*this), num_samples, replacement, generator);</span>
<span id="L5180"><span class="lineNum">    5180</span>              : }</span>
<span id="L5181"><span class="lineNum">    5181</span>              : </span>
<span id="L5182"><span class="lineNum">    5182</span>              : // aten::lgamma_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L5183"><span class="lineNum">    5183</span>              : inline at::Tensor &amp; Tensor::lgamma_() const {</span>
<span id="L5184"><span class="lineNum">    5184</span>              :     return at::_ops::lgamma_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L5185"><span class="lineNum">    5185</span>              : }</span>
<span id="L5186"><span class="lineNum">    5186</span>              : </span>
<span id="L5187"><span class="lineNum">    5187</span>              : // aten::lgamma(Tensor self) -&gt; Tensor</span>
<span id="L5188"><span class="lineNum">    5188</span>              : inline at::Tensor Tensor::lgamma() const {</span>
<span id="L5189"><span class="lineNum">    5189</span>              :     return at::_ops::lgamma::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L5190"><span class="lineNum">    5190</span>              : }</span>
<span id="L5191"><span class="lineNum">    5191</span>              : </span>
<span id="L5192"><span class="lineNum">    5192</span>              : // aten::digamma(Tensor self) -&gt; Tensor</span>
<span id="L5193"><span class="lineNum">    5193</span>              : inline at::Tensor Tensor::digamma() const {</span>
<span id="L5194"><span class="lineNum">    5194</span>              :     return at::_ops::digamma::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L5195"><span class="lineNum">    5195</span>              : }</span>
<span id="L5196"><span class="lineNum">    5196</span>              : </span>
<span id="L5197"><span class="lineNum">    5197</span>              : // aten::polygamma(int n, Tensor self) -&gt; Tensor</span>
<span id="L5198"><span class="lineNum">    5198</span>              : inline at::Tensor Tensor::polygamma(int64_t n) const {</span>
<span id="L5199"><span class="lineNum">    5199</span>              :     return at::_ops::polygamma::call(n, const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L5200"><span class="lineNum">    5200</span>              : }</span>
<span id="L5201"><span class="lineNum">    5201</span>              : </span>
<span id="L5202"><span class="lineNum">    5202</span>              : // aten::polygamma_(Tensor(a!) self, int n) -&gt; Tensor(a!)</span>
<span id="L5203"><span class="lineNum">    5203</span>              : inline at::Tensor &amp; Tensor::polygamma_(int64_t n) const {</span>
<span id="L5204"><span class="lineNum">    5204</span>              :     return at::_ops::polygamma_::call(const_cast&lt;Tensor&amp;&gt;(*this), n);</span>
<span id="L5205"><span class="lineNum">    5205</span>              : }</span>
<span id="L5206"><span class="lineNum">    5206</span>              : </span>
<span id="L5207"><span class="lineNum">    5207</span>              : // aten::erfinv(Tensor self) -&gt; Tensor</span>
<span id="L5208"><span class="lineNum">    5208</span>              : inline at::Tensor Tensor::erfinv() const {</span>
<span id="L5209"><span class="lineNum">    5209</span>              :     return at::_ops::erfinv::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L5210"><span class="lineNum">    5210</span>              : }</span>
<span id="L5211"><span class="lineNum">    5211</span>              : </span>
<span id="L5212"><span class="lineNum">    5212</span>              : // aten::erfinv_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L5213"><span class="lineNum">    5213</span>              : inline at::Tensor &amp; Tensor::erfinv_() const {</span>
<span id="L5214"><span class="lineNum">    5214</span>              :     return at::_ops::erfinv_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L5215"><span class="lineNum">    5215</span>              : }</span>
<span id="L5216"><span class="lineNum">    5216</span>              : </span>
<span id="L5217"><span class="lineNum">    5217</span>              : // aten::i0(Tensor self) -&gt; Tensor</span>
<span id="L5218"><span class="lineNum">    5218</span>              : inline at::Tensor Tensor::i0() const {</span>
<span id="L5219"><span class="lineNum">    5219</span>              :     return at::_ops::i0::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L5220"><span class="lineNum">    5220</span>              : }</span>
<span id="L5221"><span class="lineNum">    5221</span>              : </span>
<span id="L5222"><span class="lineNum">    5222</span>              : // aten::i0_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L5223"><span class="lineNum">    5223</span>              : inline at::Tensor &amp; Tensor::i0_() const {</span>
<span id="L5224"><span class="lineNum">    5224</span>              :     return at::_ops::i0_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L5225"><span class="lineNum">    5225</span>              : }</span>
<span id="L5226"><span class="lineNum">    5226</span>              : </span>
<span id="L5227"><span class="lineNum">    5227</span>              : // aten::sign(Tensor self) -&gt; Tensor</span>
<span id="L5228"><span class="lineNum">    5228</span>              : inline at::Tensor Tensor::sign() const {</span>
<span id="L5229"><span class="lineNum">    5229</span>              :     return at::_ops::sign::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L5230"><span class="lineNum">    5230</span>              : }</span>
<span id="L5231"><span class="lineNum">    5231</span>              : </span>
<span id="L5232"><span class="lineNum">    5232</span>              : // aten::sign_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span id="L5233"><span class="lineNum">    5233</span>              : inline at::Tensor &amp; Tensor::sign_() const {</span>
<span id="L5234"><span class="lineNum">    5234</span>              :     return at::_ops::sign_::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L5235"><span class="lineNum">    5235</span>              : }</span>
<span id="L5236"><span class="lineNum">    5236</span>              : </span>
<span id="L5237"><span class="lineNum">    5237</span>              : // aten::signbit(Tensor self) -&gt; Tensor</span>
<span id="L5238"><span class="lineNum">    5238</span>              : inline at::Tensor Tensor::signbit() const {</span>
<span id="L5239"><span class="lineNum">    5239</span>              :     return at::_ops::signbit::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L5240"><span class="lineNum">    5240</span>              : }</span>
<span id="L5241"><span class="lineNum">    5241</span>              : </span>
<span id="L5242"><span class="lineNum">    5242</span>              : // aten::dist(Tensor self, Tensor other, Scalar p=2) -&gt; Tensor</span>
<span id="L5243"><span class="lineNum">    5243</span>              : inline at::Tensor Tensor::dist(const at::Tensor &amp; other, const at::Scalar &amp; p) const {</span>
<span id="L5244"><span class="lineNum">    5244</span>              :     return at::_ops::dist::call(const_cast&lt;Tensor&amp;&gt;(*this), other, p);</span>
<span id="L5245"><span class="lineNum">    5245</span>              : }</span>
<span id="L5246"><span class="lineNum">    5246</span>              : </span>
<span id="L5247"><span class="lineNum">    5247</span>              : // aten::atan2_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L5248"><span class="lineNum">    5248</span>              : inline at::Tensor &amp; Tensor::atan2_(const at::Tensor &amp; other) const {</span>
<span id="L5249"><span class="lineNum">    5249</span>              :     return at::_ops::atan2_::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L5250"><span class="lineNum">    5250</span>              : }</span>
<span id="L5251"><span class="lineNum">    5251</span>              : </span>
<span id="L5252"><span class="lineNum">    5252</span>              : // aten::atan2(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L5253"><span class="lineNum">    5253</span>              : inline at::Tensor Tensor::atan2(const at::Tensor &amp; other) const {</span>
<span id="L5254"><span class="lineNum">    5254</span>              :     return at::_ops::atan2::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L5255"><span class="lineNum">    5255</span>              : }</span>
<span id="L5256"><span class="lineNum">    5256</span>              : </span>
<span id="L5257"><span class="lineNum">    5257</span>              : // aten::arctan2(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L5258"><span class="lineNum">    5258</span>              : inline at::Tensor Tensor::arctan2(const at::Tensor &amp; other) const {</span>
<span id="L5259"><span class="lineNum">    5259</span>              :     return at::_ops::arctan2::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L5260"><span class="lineNum">    5260</span>              : }</span>
<span id="L5261"><span class="lineNum">    5261</span>              : </span>
<span id="L5262"><span class="lineNum">    5262</span>              : // aten::arctan2_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L5263"><span class="lineNum">    5263</span>              : inline at::Tensor &amp; Tensor::arctan2_(const at::Tensor &amp; other) const {</span>
<span id="L5264"><span class="lineNum">    5264</span>              :     return at::_ops::arctan2_::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L5265"><span class="lineNum">    5265</span>              : }</span>
<span id="L5266"><span class="lineNum">    5266</span>              : </span>
<span id="L5267"><span class="lineNum">    5267</span>              : // aten::lerp.Scalar(Tensor self, Tensor end, Scalar weight) -&gt; Tensor</span>
<span id="L5268"><span class="lineNum">    5268</span>              : inline at::Tensor Tensor::lerp(const at::Tensor &amp; end, const at::Scalar &amp; weight) const {</span>
<span id="L5269"><span class="lineNum">    5269</span>              :     return at::_ops::lerp_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), end, weight);</span>
<span id="L5270"><span class="lineNum">    5270</span>              : }</span>
<span id="L5271"><span class="lineNum">    5271</span>              : </span>
<span id="L5272"><span class="lineNum">    5272</span>              : // aten::lerp.Tensor(Tensor self, Tensor end, Tensor weight) -&gt; Tensor</span>
<span id="L5273"><span class="lineNum">    5273</span>              : inline at::Tensor Tensor::lerp(const at::Tensor &amp; end, const at::Tensor &amp; weight) const {</span>
<span id="L5274"><span class="lineNum">    5274</span>              :     return at::_ops::lerp_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), end, weight);</span>
<span id="L5275"><span class="lineNum">    5275</span>              : }</span>
<span id="L5276"><span class="lineNum">    5276</span>              : </span>
<span id="L5277"><span class="lineNum">    5277</span>              : // aten::histc(Tensor self, int bins=100, Scalar min=0, Scalar max=0) -&gt; Tensor</span>
<span id="L5278"><span class="lineNum">    5278</span>              : inline at::Tensor Tensor::histc(int64_t bins, const at::Scalar &amp; min, const at::Scalar &amp; max) const {</span>
<span id="L5279"><span class="lineNum">    5279</span>              :     return at::_ops::histc::call(const_cast&lt;Tensor&amp;&gt;(*this), bins, min, max);</span>
<span id="L5280"><span class="lineNum">    5280</span>              : }</span>
<span id="L5281"><span class="lineNum">    5281</span>              : </span>
<span id="L5282"><span class="lineNum">    5282</span>              : // aten::histogram.bins_tensor(Tensor self, Tensor bins, *, Tensor? weight=None, bool density=False) -&gt; (Tensor hist, Tensor bin_edges)</span>
<span id="L5283"><span class="lineNum">    5283</span>              : inline ::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::histogram(const at::Tensor &amp; bins, const ::std::optional&lt;at::Tensor&gt; &amp; weight, bool density) const {</span>
<span id="L5284"><span class="lineNum">    5284</span>              :     return at::_ops::histogram_bins_tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), bins, weight, density);</span>
<span id="L5285"><span class="lineNum">    5285</span>              : }</span>
<span id="L5286"><span class="lineNum">    5286</span>              : </span>
<span id="L5287"><span class="lineNum">    5287</span>              : // aten::histogram.bin_ct(Tensor self, int bins=100, *, float[]? range=None, Tensor? weight=None, bool density=False) -&gt; (Tensor hist, Tensor bin_edges)</span>
<span id="L5288"><span class="lineNum">    5288</span>              : inline ::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::histogram(int64_t bins, ::std::optional&lt;at::ArrayRef&lt;double&gt;&gt; range, const ::std::optional&lt;at::Tensor&gt; &amp; weight, bool density) const {</span>
<span id="L5289"><span class="lineNum">    5289</span>              :     return at::_ops::histogram_bin_ct::call(const_cast&lt;Tensor&amp;&gt;(*this), bins, range, weight, density);</span>
<span id="L5290"><span class="lineNum">    5290</span>              : }</span>
<span id="L5291"><span class="lineNum">    5291</span>              : </span>
<span id="L5292"><span class="lineNum">    5292</span>              : // aten::fmod.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span id="L5293"><span class="lineNum">    5293</span>              : inline at::Tensor Tensor::fmod(const at::Scalar &amp; other) const {</span>
<span id="L5294"><span class="lineNum">    5294</span>              :     return at::_ops::fmod_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L5295"><span class="lineNum">    5295</span>              : }</span>
<span id="L5296"><span class="lineNum">    5296</span>              : </span>
<span id="L5297"><span class="lineNum">    5297</span>              : // aten::fmod_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span id="L5298"><span class="lineNum">    5298</span>              : inline at::Tensor &amp; Tensor::fmod_(const at::Scalar &amp; other) const {</span>
<span id="L5299"><span class="lineNum">    5299</span>              :     return at::_ops::fmod__Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L5300"><span class="lineNum">    5300</span>              : }</span>
<span id="L5301"><span class="lineNum">    5301</span>              : </span>
<span id="L5302"><span class="lineNum">    5302</span>              : // aten::fmod.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L5303"><span class="lineNum">    5303</span>              : inline at::Tensor Tensor::fmod(const at::Tensor &amp; other) const {</span>
<span id="L5304"><span class="lineNum">    5304</span>              :     return at::_ops::fmod_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L5305"><span class="lineNum">    5305</span>              : }</span>
<span id="L5306"><span class="lineNum">    5306</span>              : </span>
<span id="L5307"><span class="lineNum">    5307</span>              : // aten::fmod_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L5308"><span class="lineNum">    5308</span>              : inline at::Tensor &amp; Tensor::fmod_(const at::Tensor &amp; other) const {</span>
<span id="L5309"><span class="lineNum">    5309</span>              :     return at::_ops::fmod__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L5310"><span class="lineNum">    5310</span>              : }</span>
<span id="L5311"><span class="lineNum">    5311</span>              : </span>
<span id="L5312"><span class="lineNum">    5312</span>              : // aten::hypot(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L5313"><span class="lineNum">    5313</span>              : inline at::Tensor Tensor::hypot(const at::Tensor &amp; other) const {</span>
<span id="L5314"><span class="lineNum">    5314</span>              :     return at::_ops::hypot::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L5315"><span class="lineNum">    5315</span>              : }</span>
<span id="L5316"><span class="lineNum">    5316</span>              : </span>
<span id="L5317"><span class="lineNum">    5317</span>              : // aten::hypot_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L5318"><span class="lineNum">    5318</span>              : inline at::Tensor &amp; Tensor::hypot_(const at::Tensor &amp; other) const {</span>
<span id="L5319"><span class="lineNum">    5319</span>              :     return at::_ops::hypot_::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L5320"><span class="lineNum">    5320</span>              : }</span>
<span id="L5321"><span class="lineNum">    5321</span>              : </span>
<span id="L5322"><span class="lineNum">    5322</span>              : // aten::igamma(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L5323"><span class="lineNum">    5323</span>              : inline at::Tensor Tensor::igamma(const at::Tensor &amp; other) const {</span>
<span id="L5324"><span class="lineNum">    5324</span>              :     return at::_ops::igamma::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L5325"><span class="lineNum">    5325</span>              : }</span>
<span id="L5326"><span class="lineNum">    5326</span>              : </span>
<span id="L5327"><span class="lineNum">    5327</span>              : // aten::igamma_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L5328"><span class="lineNum">    5328</span>              : inline at::Tensor &amp; Tensor::igamma_(const at::Tensor &amp; other) const {</span>
<span id="L5329"><span class="lineNum">    5329</span>              :     return at::_ops::igamma_::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L5330"><span class="lineNum">    5330</span>              : }</span>
<span id="L5331"><span class="lineNum">    5331</span>              : </span>
<span id="L5332"><span class="lineNum">    5332</span>              : // aten::igammac(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L5333"><span class="lineNum">    5333</span>              : inline at::Tensor Tensor::igammac(const at::Tensor &amp; other) const {</span>
<span id="L5334"><span class="lineNum">    5334</span>              :     return at::_ops::igammac::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L5335"><span class="lineNum">    5335</span>              : }</span>
<span id="L5336"><span class="lineNum">    5336</span>              : </span>
<span id="L5337"><span class="lineNum">    5337</span>              : // aten::igammac_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L5338"><span class="lineNum">    5338</span>              : inline at::Tensor &amp; Tensor::igammac_(const at::Tensor &amp; other) const {</span>
<span id="L5339"><span class="lineNum">    5339</span>              :     return at::_ops::igammac_::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L5340"><span class="lineNum">    5340</span>              : }</span>
<span id="L5341"><span class="lineNum">    5341</span>              : </span>
<span id="L5342"><span class="lineNum">    5342</span>              : // aten::nextafter(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L5343"><span class="lineNum">    5343</span>              : inline at::Tensor Tensor::nextafter(const at::Tensor &amp; other) const {</span>
<span id="L5344"><span class="lineNum">    5344</span>              :     return at::_ops::nextafter::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L5345"><span class="lineNum">    5345</span>              : }</span>
<span id="L5346"><span class="lineNum">    5346</span>              : </span>
<span id="L5347"><span class="lineNum">    5347</span>              : // aten::nextafter_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L5348"><span class="lineNum">    5348</span>              : inline at::Tensor &amp; Tensor::nextafter_(const at::Tensor &amp; other) const {</span>
<span id="L5349"><span class="lineNum">    5349</span>              :     return at::_ops::nextafter_::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L5350"><span class="lineNum">    5350</span>              : }</span>
<span id="L5351"><span class="lineNum">    5351</span>              : </span>
<span id="L5352"><span class="lineNum">    5352</span>              : // aten::remainder.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span id="L5353"><span class="lineNum">    5353</span>              : inline at::Tensor Tensor::remainder(const at::Scalar &amp; other) const {</span>
<span id="L5354"><span class="lineNum">    5354</span>              :     return at::_ops::remainder_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L5355"><span class="lineNum">    5355</span>              : }</span>
<span id="L5356"><span class="lineNum">    5356</span>              : </span>
<span id="L5357"><span class="lineNum">    5357</span>              : // aten::remainder_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span id="L5358"><span class="lineNum">    5358</span>              : inline at::Tensor &amp; Tensor::remainder_(const at::Scalar &amp; other) const {</span>
<span id="L5359"><span class="lineNum">    5359</span>              :     return at::_ops::remainder__Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L5360"><span class="lineNum">    5360</span>              : }</span>
<span id="L5361"><span class="lineNum">    5361</span>              : </span>
<span id="L5362"><span class="lineNum">    5362</span>              : // aten::remainder.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L5363"><span class="lineNum">    5363</span>              : inline at::Tensor Tensor::remainder(const at::Tensor &amp; other) const {</span>
<span id="L5364"><span class="lineNum">    5364</span>              :     return at::_ops::remainder_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L5365"><span class="lineNum">    5365</span>              : }</span>
<span id="L5366"><span class="lineNum">    5366</span>              : </span>
<span id="L5367"><span class="lineNum">    5367</span>              : // aten::remainder_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span id="L5368"><span class="lineNum">    5368</span>              : inline at::Tensor &amp; Tensor::remainder_(const at::Tensor &amp; other) const {</span>
<span id="L5369"><span class="lineNum">    5369</span>              :     return at::_ops::remainder__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L5370"><span class="lineNum">    5370</span>              : }</span>
<span id="L5371"><span class="lineNum">    5371</span>              : </span>
<span id="L5372"><span class="lineNum">    5372</span>              : // aten::min(Tensor self) -&gt; Tensor</span>
<span id="L5373"><span class="lineNum">    5373</span>              : inline at::Tensor Tensor::min() const {</span>
<span id="L5374"><span class="lineNum">    5374</span>              :     return at::_ops::min::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L5375"><span class="lineNum">    5375</span>              : }</span>
<span id="L5376"><span class="lineNum">    5376</span>              : </span>
<span id="L5377"><span class="lineNum">    5377</span>              : // aten::fmin(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L5378"><span class="lineNum">    5378</span>              : inline at::Tensor Tensor::fmin(const at::Tensor &amp; other) const {</span>
<span id="L5379"><span class="lineNum">    5379</span>              :     return at::_ops::fmin::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L5380"><span class="lineNum">    5380</span>              : }</span>
<span id="L5381"><span class="lineNum">    5381</span>              : </span>
<span id="L5382"><span class="lineNum">    5382</span>              : // aten::max(Tensor self) -&gt; Tensor</span>
<span id="L5383"><span class="lineNum">    5383</span>              : inline at::Tensor Tensor::max() const {</span>
<span id="L5384"><span class="lineNum">    5384</span>              :     return at::_ops::max::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L5385"><span class="lineNum">    5385</span>              : }</span>
<span id="L5386"><span class="lineNum">    5386</span>              : </span>
<span id="L5387"><span class="lineNum">    5387</span>              : // aten::fmax(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L5388"><span class="lineNum">    5388</span>              : inline at::Tensor Tensor::fmax(const at::Tensor &amp; other) const {</span>
<span id="L5389"><span class="lineNum">    5389</span>              :     return at::_ops::fmax::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L5390"><span class="lineNum">    5390</span>              : }</span>
<span id="L5391"><span class="lineNum">    5391</span>              : </span>
<span id="L5392"><span class="lineNum">    5392</span>              : // aten::maximum(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L5393"><span class="lineNum">    5393</span>              : inline at::Tensor Tensor::maximum(const at::Tensor &amp; other) const {</span>
<span id="L5394"><span class="lineNum">    5394</span>              :     return at::_ops::maximum::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L5395"><span class="lineNum">    5395</span>              : }</span>
<span id="L5396"><span class="lineNum">    5396</span>              : </span>
<span id="L5397"><span class="lineNum">    5397</span>              : // aten::max.other(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L5398"><span class="lineNum">    5398</span>              : inline at::Tensor Tensor::max(const at::Tensor &amp; other) const {</span>
<span id="L5399"><span class="lineNum">    5399</span>              :     return at::_ops::max_other::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L5400"><span class="lineNum">    5400</span>              : }</span>
<span id="L5401"><span class="lineNum">    5401</span>              : </span>
<span id="L5402"><span class="lineNum">    5402</span>              : // aten::minimum(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L5403"><span class="lineNum">    5403</span>              : inline at::Tensor Tensor::minimum(const at::Tensor &amp; other) const {</span>
<span id="L5404"><span class="lineNum">    5404</span>              :     return at::_ops::minimum::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L5405"><span class="lineNum">    5405</span>              : }</span>
<span id="L5406"><span class="lineNum">    5406</span>              : </span>
<span id="L5407"><span class="lineNum">    5407</span>              : // aten::min.other(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L5408"><span class="lineNum">    5408</span>              : inline at::Tensor Tensor::min(const at::Tensor &amp; other) const {</span>
<span id="L5409"><span class="lineNum">    5409</span>              :     return at::_ops::min_other::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L5410"><span class="lineNum">    5410</span>              : }</span>
<span id="L5411"><span class="lineNum">    5411</span>              : </span>
<span id="L5412"><span class="lineNum">    5412</span>              : // aten::quantile(Tensor self, Tensor q, int? dim=None, bool keepdim=False, *, str interpolation='linear') -&gt; Tensor</span>
<span id="L5413"><span class="lineNum">    5413</span>              : inline at::Tensor Tensor::quantile(const at::Tensor &amp; q, ::std::optional&lt;int64_t&gt; dim, bool keepdim, c10::string_view interpolation) const {</span>
<span id="L5414"><span class="lineNum">    5414</span>              :     return at::_ops::quantile::call(const_cast&lt;Tensor&amp;&gt;(*this), q, dim, keepdim, interpolation);</span>
<span id="L5415"><span class="lineNum">    5415</span>              : }</span>
<span id="L5416"><span class="lineNum">    5416</span>              : </span>
<span id="L5417"><span class="lineNum">    5417</span>              : // aten::quantile.scalar(Tensor self, float q, int? dim=None, bool keepdim=False, *, str interpolation='linear') -&gt; Tensor</span>
<span id="L5418"><span class="lineNum">    5418</span>              : inline at::Tensor Tensor::quantile(double q, ::std::optional&lt;int64_t&gt; dim, bool keepdim, c10::string_view interpolation) const {</span>
<span id="L5419"><span class="lineNum">    5419</span>              :     return at::_ops::quantile_scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), q, dim, keepdim, interpolation);</span>
<span id="L5420"><span class="lineNum">    5420</span>              : }</span>
<span id="L5421"><span class="lineNum">    5421</span>              : </span>
<span id="L5422"><span class="lineNum">    5422</span>              : // aten::nanquantile(Tensor self, Tensor q, int? dim=None, bool keepdim=False, *, str interpolation='linear') -&gt; Tensor</span>
<span id="L5423"><span class="lineNum">    5423</span>              : inline at::Tensor Tensor::nanquantile(const at::Tensor &amp; q, ::std::optional&lt;int64_t&gt; dim, bool keepdim, c10::string_view interpolation) const {</span>
<span id="L5424"><span class="lineNum">    5424</span>              :     return at::_ops::nanquantile::call(const_cast&lt;Tensor&amp;&gt;(*this), q, dim, keepdim, interpolation);</span>
<span id="L5425"><span class="lineNum">    5425</span>              : }</span>
<span id="L5426"><span class="lineNum">    5426</span>              : </span>
<span id="L5427"><span class="lineNum">    5427</span>              : // aten::nanquantile.scalar(Tensor self, float q, int? dim=None, bool keepdim=False, *, str interpolation='linear') -&gt; Tensor</span>
<span id="L5428"><span class="lineNum">    5428</span>              : inline at::Tensor Tensor::nanquantile(double q, ::std::optional&lt;int64_t&gt; dim, bool keepdim, c10::string_view interpolation) const {</span>
<span id="L5429"><span class="lineNum">    5429</span>              :     return at::_ops::nanquantile_scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), q, dim, keepdim, interpolation);</span>
<span id="L5430"><span class="lineNum">    5430</span>              : }</span>
<span id="L5431"><span class="lineNum">    5431</span>              : </span>
<span id="L5432"><span class="lineNum">    5432</span>              : // aten::sort(Tensor self, int dim=-1, bool descending=False) -&gt; (Tensor values, Tensor indices)</span>
<span id="L5433"><span class="lineNum">    5433</span>              : inline ::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::sort(int64_t dim, bool descending) const {</span>
<span id="L5434"><span class="lineNum">    5434</span>              :     return at::_ops::sort::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, descending);</span>
<span id="L5435"><span class="lineNum">    5435</span>              : }</span>
<span id="L5436"><span class="lineNum">    5436</span>              : </span>
<span id="L5437"><span class="lineNum">    5437</span>              : // aten::sort.stable(Tensor self, *, bool? stable, int dim=-1, bool descending=False) -&gt; (Tensor values, Tensor indices)</span>
<span id="L5438"><span class="lineNum">    5438</span>              : inline ::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::sort(::std::optional&lt;bool&gt; stable, int64_t dim, bool descending) const {</span>
<span id="L5439"><span class="lineNum">    5439</span>              :     return at::_ops::sort_stable::call(const_cast&lt;Tensor&amp;&gt;(*this), stable, dim, descending);</span>
<span id="L5440"><span class="lineNum">    5440</span>              : }</span>
<span id="L5441"><span class="lineNum">    5441</span>              : </span>
<span id="L5442"><span class="lineNum">    5442</span>              : // aten::sort.dimname(Tensor self, Dimname dim, bool descending=False) -&gt; (Tensor values, Tensor indices)</span>
<span id="L5443"><span class="lineNum">    5443</span>              : inline ::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::sort(at::Dimname dim, bool descending) const {</span>
<span id="L5444"><span class="lineNum">    5444</span>              :     return at::_ops::sort_dimname::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, descending);</span>
<span id="L5445"><span class="lineNum">    5445</span>              : }</span>
<span id="L5446"><span class="lineNum">    5446</span>              : </span>
<span id="L5447"><span class="lineNum">    5447</span>              : // aten::sort.dimname_stable(Tensor self, *, bool? stable, Dimname dim, bool descending=False) -&gt; (Tensor values, Tensor indices)</span>
<span id="L5448"><span class="lineNum">    5448</span>              : inline ::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::sort(::std::optional&lt;bool&gt; stable, at::Dimname dim, bool descending) const {</span>
<span id="L5449"><span class="lineNum">    5449</span>              :     return at::_ops::sort_dimname_stable::call(const_cast&lt;Tensor&amp;&gt;(*this), stable, dim, descending);</span>
<span id="L5450"><span class="lineNum">    5450</span>              : }</span>
<span id="L5451"><span class="lineNum">    5451</span>              : </span>
<span id="L5452"><span class="lineNum">    5452</span>              : // aten::msort(Tensor self) -&gt; Tensor</span>
<span id="L5453"><span class="lineNum">    5453</span>              : inline at::Tensor Tensor::msort() const {</span>
<span id="L5454"><span class="lineNum">    5454</span>              :     return at::_ops::msort::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L5455"><span class="lineNum">    5455</span>              : }</span>
<span id="L5456"><span class="lineNum">    5456</span>              : </span>
<span id="L5457"><span class="lineNum">    5457</span>              : // aten::argsort(Tensor self, int dim=-1, bool descending=False) -&gt; Tensor</span>
<span id="L5458"><span class="lineNum">    5458</span>              : inline at::Tensor Tensor::argsort(int64_t dim, bool descending) const {</span>
<span id="L5459"><span class="lineNum">    5459</span>              :     return at::_ops::argsort::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, descending);</span>
<span id="L5460"><span class="lineNum">    5460</span>              : }</span>
<span id="L5461"><span class="lineNum">    5461</span>              : </span>
<span id="L5462"><span class="lineNum">    5462</span>              : // aten::argsort.stable(Tensor self, *, bool stable, int dim=-1, bool descending=False) -&gt; Tensor</span>
<span id="L5463"><span class="lineNum">    5463</span>              : inline at::Tensor Tensor::argsort(bool stable, int64_t dim, bool descending) const {</span>
<span id="L5464"><span class="lineNum">    5464</span>              :     return at::_ops::argsort_stable::call(const_cast&lt;Tensor&amp;&gt;(*this), stable, dim, descending);</span>
<span id="L5465"><span class="lineNum">    5465</span>              : }</span>
<span id="L5466"><span class="lineNum">    5466</span>              : </span>
<span id="L5467"><span class="lineNum">    5467</span>              : // aten::argsort.dimname(Tensor self, Dimname dim, bool descending=False) -&gt; Tensor</span>
<span id="L5468"><span class="lineNum">    5468</span>              : inline at::Tensor Tensor::argsort(at::Dimname dim, bool descending) const {</span>
<span id="L5469"><span class="lineNum">    5469</span>              :     return at::_ops::argsort_dimname::call(const_cast&lt;Tensor&amp;&gt;(*this), dim, descending);</span>
<span id="L5470"><span class="lineNum">    5470</span>              : }</span>
<span id="L5471"><span class="lineNum">    5471</span>              : </span>
<span id="L5472"><span class="lineNum">    5472</span>              : // aten::topk(Tensor self, SymInt k, int dim=-1, bool largest=True, bool sorted=True) -&gt; (Tensor values, Tensor indices)</span>
<span id="L5473"><span class="lineNum">    5473</span>              : inline ::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::topk(int64_t k, int64_t dim, bool largest, bool sorted) const {</span>
<span id="L5474"><span class="lineNum">    5474</span>              :     return at::_ops::topk::call(const_cast&lt;Tensor&amp;&gt;(*this), k, dim, largest, sorted);</span>
<span id="L5475"><span class="lineNum">    5475</span>              : }</span>
<span id="L5476"><span class="lineNum">    5476</span>              : </span>
<span id="L5477"><span class="lineNum">    5477</span>              : // aten::topk(Tensor self, SymInt k, int dim=-1, bool largest=True, bool sorted=True) -&gt; (Tensor values, Tensor indices)</span>
<span id="L5478"><span class="lineNum">    5478</span>              : inline ::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::topk_symint(c10::SymInt k, int64_t dim, bool largest, bool sorted) const {</span>
<span id="L5479"><span class="lineNum">    5479</span>              :     return at::_ops::topk::call(const_cast&lt;Tensor&amp;&gt;(*this), k, dim, largest, sorted);</span>
<span id="L5480"><span class="lineNum">    5480</span>              : }</span>
<span id="L5481"><span class="lineNum">    5481</span>              : </span>
<span id="L5482"><span class="lineNum">    5482</span>              : // aten::all(Tensor self) -&gt; Tensor</span>
<span id="L5483"><span class="lineNum">    5483</span>              : inline at::Tensor Tensor::all() const {</span>
<span id="L5484"><span class="lineNum">    5484</span>              :     return at::_ops::all::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L5485"><span class="lineNum">    5485</span>              : }</span>
<span id="L5486"><span class="lineNum">    5486</span>              : </span>
<span id="L5487"><span class="lineNum">    5487</span>              : // aten::any(Tensor self) -&gt; Tensor</span>
<span id="L5488"><span class="lineNum">    5488</span>              : inline at::Tensor Tensor::any() const {</span>
<span id="L5489"><span class="lineNum">    5489</span>              :     return at::_ops::any::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L5490"><span class="lineNum">    5490</span>              : }</span>
<span id="L5491"><span class="lineNum">    5491</span>              : </span>
<span id="L5492"><span class="lineNum">    5492</span>              : // aten::renorm(Tensor self, Scalar p, int dim, Scalar maxnorm) -&gt; Tensor</span>
<span id="L5493"><span class="lineNum">    5493</span>              : inline at::Tensor Tensor::renorm(const at::Scalar &amp; p, int64_t dim, const at::Scalar &amp; maxnorm) const {</span>
<span id="L5494"><span class="lineNum">    5494</span>              :     return at::_ops::renorm::call(const_cast&lt;Tensor&amp;&gt;(*this), p, dim, maxnorm);</span>
<span id="L5495"><span class="lineNum">    5495</span>              : }</span>
<span id="L5496"><span class="lineNum">    5496</span>              : </span>
<span id="L5497"><span class="lineNum">    5497</span>              : // aten::renorm_(Tensor(a!) self, Scalar p, int dim, Scalar maxnorm) -&gt; Tensor(a!)</span>
<span id="L5498"><span class="lineNum">    5498</span>              : inline at::Tensor &amp; Tensor::renorm_(const at::Scalar &amp; p, int64_t dim, const at::Scalar &amp; maxnorm) const {</span>
<span id="L5499"><span class="lineNum">    5499</span>              :     return at::_ops::renorm_::call(const_cast&lt;Tensor&amp;&gt;(*this), p, dim, maxnorm);</span>
<span id="L5500"><span class="lineNum">    5500</span>              : }</span>
<span id="L5501"><span class="lineNum">    5501</span>              : </span>
<span id="L5502"><span class="lineNum">    5502</span>              : // aten::unfold(Tensor(a) self, int dimension, int size, int step) -&gt; Tensor(a)</span>
<span id="L5503"><span class="lineNum">    5503</span>              : inline at::Tensor Tensor::unfold(int64_t dimension, int64_t size, int64_t step) const {</span>
<span id="L5504"><span class="lineNum">    5504</span>              :     return at::_ops::unfold::call(const_cast&lt;Tensor&amp;&gt;(*this), dimension, size, step);</span>
<span id="L5505"><span class="lineNum">    5505</span>              : }</span>
<span id="L5506"><span class="lineNum">    5506</span>              : </span>
<span id="L5507"><span class="lineNum">    5507</span>              : // aten::equal(Tensor self, Tensor other) -&gt; bool</span>
<span id="L5508"><span class="lineNum">    5508</span>              : inline bool Tensor::equal(const at::Tensor &amp; other) const {</span>
<span id="L5509"><span class="lineNum">    5509</span>              :     return at::_ops::equal::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L5510"><span class="lineNum">    5510</span>              : }</span>
<span id="L5511"><span class="lineNum">    5511</span>              : </span>
<span id="L5512"><span class="lineNum">    5512</span>              : // aten::pow.Tensor_Tensor(Tensor self, Tensor exponent) -&gt; Tensor</span>
<span id="L5513"><span class="lineNum">    5513</span>              : inline at::Tensor Tensor::pow(const at::Tensor &amp; exponent) const {</span>
<span id="L5514"><span class="lineNum">    5514</span>              :     return at::_ops::pow_Tensor_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), exponent);</span>
<span id="L5515"><span class="lineNum">    5515</span>              : }</span>
<span id="L5516"><span class="lineNum">    5516</span>              : </span>
<span id="L5517"><span class="lineNum">    5517</span>              : // aten::pow.Tensor_Scalar(Tensor self, Scalar exponent) -&gt; Tensor</span>
<span id="L5518"><span class="lineNum">    5518</span>              : inline at::Tensor Tensor::pow(const at::Scalar &amp; exponent) const {</span>
<span id="L5519"><span class="lineNum">    5519</span>              :     return at::_ops::pow_Tensor_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), exponent);</span>
<span id="L5520"><span class="lineNum">    5520</span>              : }</span>
<span id="L5521"><span class="lineNum">    5521</span>              : </span>
<span id="L5522"><span class="lineNum">    5522</span>              : // aten::pow_.Scalar(Tensor(a!) self, Scalar exponent) -&gt; Tensor(a!)</span>
<span id="L5523"><span class="lineNum">    5523</span>              : inline at::Tensor &amp; Tensor::pow_(const at::Scalar &amp; exponent) const {</span>
<span id="L5524"><span class="lineNum">    5524</span>              :     return at::_ops::pow__Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), exponent);</span>
<span id="L5525"><span class="lineNum">    5525</span>              : }</span>
<span id="L5526"><span class="lineNum">    5526</span>              : </span>
<span id="L5527"><span class="lineNum">    5527</span>              : // aten::pow_.Tensor(Tensor(a!) self, Tensor exponent) -&gt; Tensor(a!)</span>
<span id="L5528"><span class="lineNum">    5528</span>              : inline at::Tensor &amp; Tensor::pow_(const at::Tensor &amp; exponent) const {</span>
<span id="L5529"><span class="lineNum">    5529</span>              :     return at::_ops::pow__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), exponent);</span>
<span id="L5530"><span class="lineNum">    5530</span>              : }</span>
<span id="L5531"><span class="lineNum">    5531</span>              : </span>
<span id="L5532"><span class="lineNum">    5532</span>              : // aten::float_power.Tensor_Tensor(Tensor self, Tensor exponent) -&gt; Tensor</span>
<span id="L5533"><span class="lineNum">    5533</span>              : inline at::Tensor Tensor::float_power(const at::Tensor &amp; exponent) const {</span>
<span id="L5534"><span class="lineNum">    5534</span>              :     return at::_ops::float_power_Tensor_Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), exponent);</span>
<span id="L5535"><span class="lineNum">    5535</span>              : }</span>
<span id="L5536"><span class="lineNum">    5536</span>              : </span>
<span id="L5537"><span class="lineNum">    5537</span>              : // aten::float_power.Tensor_Scalar(Tensor self, Scalar exponent) -&gt; Tensor</span>
<span id="L5538"><span class="lineNum">    5538</span>              : inline at::Tensor Tensor::float_power(const at::Scalar &amp; exponent) const {</span>
<span id="L5539"><span class="lineNum">    5539</span>              :     return at::_ops::float_power_Tensor_Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), exponent);</span>
<span id="L5540"><span class="lineNum">    5540</span>              : }</span>
<span id="L5541"><span class="lineNum">    5541</span>              : </span>
<span id="L5542"><span class="lineNum">    5542</span>              : // aten::float_power_.Scalar(Tensor(a!) self, Scalar exponent) -&gt; Tensor(a!)</span>
<span id="L5543"><span class="lineNum">    5543</span>              : inline at::Tensor &amp; Tensor::float_power_(const at::Scalar &amp; exponent) const {</span>
<span id="L5544"><span class="lineNum">    5544</span>              :     return at::_ops::float_power__Scalar::call(const_cast&lt;Tensor&amp;&gt;(*this), exponent);</span>
<span id="L5545"><span class="lineNum">    5545</span>              : }</span>
<span id="L5546"><span class="lineNum">    5546</span>              : </span>
<span id="L5547"><span class="lineNum">    5547</span>              : // aten::float_power_.Tensor(Tensor(a!) self, Tensor exponent) -&gt; Tensor(a!)</span>
<span id="L5548"><span class="lineNum">    5548</span>              : inline at::Tensor &amp; Tensor::float_power_(const at::Tensor &amp; exponent) const {</span>
<span id="L5549"><span class="lineNum">    5549</span>              :     return at::_ops::float_power__Tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), exponent);</span>
<span id="L5550"><span class="lineNum">    5550</span>              : }</span>
<span id="L5551"><span class="lineNum">    5551</span>              : </span>
<span id="L5552"><span class="lineNum">    5552</span>              : // aten::normal_(Tensor(a!) self, float mean=0, float std=1, *, Generator? generator=None) -&gt; Tensor(a!)</span>
<span id="L5553"><span class="lineNum">    5553</span>              : inline at::Tensor &amp; Tensor::normal_(double mean, double std, ::std::optional&lt;at::Generator&gt; generator) const {</span>
<span id="L5554"><span class="lineNum">    5554</span>              :     return at::_ops::normal_::call(const_cast&lt;Tensor&amp;&gt;(*this), mean, std, generator);</span>
<span id="L5555"><span class="lineNum">    5555</span>              : }</span>
<span id="L5556"><span class="lineNum">    5556</span>              : </span>
<span id="L5557"><span class="lineNum">    5557</span>              : // aten::alias(Tensor(a) self) -&gt; Tensor(a)</span>
<span id="L5558"><span class="lineNum">    5558</span>              : inline at::Tensor Tensor::alias() const {</span>
<span id="L5559"><span class="lineNum">    5559</span>              :     return at::_ops::alias::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L5560"><span class="lineNum">    5560</span>              : }</span>
<span id="L5561"><span class="lineNum">    5561</span>              : </span>
<span id="L5562"><span class="lineNum">    5562</span>              : // aten::isfinite(Tensor self) -&gt; Tensor</span>
<span id="L5563"><span class="lineNum">    5563</span>              : inline at::Tensor Tensor::isfinite() const {</span>
<span id="L5564"><span class="lineNum">    5564</span>              :     return at::_ops::isfinite::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L5565"><span class="lineNum">    5565</span>              : }</span>
<span id="L5566"><span class="lineNum">    5566</span>              : </span>
<span id="L5567"><span class="lineNum">    5567</span>              : // aten::isinf(Tensor self) -&gt; Tensor</span>
<span id="L5568"><span class="lineNum">    5568</span>              : inline at::Tensor Tensor::isinf() const {</span>
<span id="L5569"><span class="lineNum">    5569</span>              :     return at::_ops::isinf::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L5570"><span class="lineNum">    5570</span>              : }</span>
<span id="L5571"><span class="lineNum">    5571</span>              : </span>
<span id="L5572"><span class="lineNum">    5572</span>              : // aten::record_stream(Tensor(a!) self, Stream s) -&gt; ()</span>
<span id="L5573"><span class="lineNum">    5573</span>              : inline void Tensor::record_stream(at::Stream s) const {</span>
<span id="L5574"><span class="lineNum">    5574</span>              :     return at::_ops::record_stream::call(const_cast&lt;Tensor&amp;&gt;(*this), s);</span>
<span id="L5575"><span class="lineNum">    5575</span>              : }</span>
<span id="L5576"><span class="lineNum">    5576</span>              : </span>
<span id="L5577"><span class="lineNum">    5577</span>              : // aten::isposinf(Tensor self) -&gt; Tensor</span>
<span id="L5578"><span class="lineNum">    5578</span>              : inline at::Tensor Tensor::isposinf() const {</span>
<span id="L5579"><span class="lineNum">    5579</span>              :     return at::_ops::isposinf::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L5580"><span class="lineNum">    5580</span>              : }</span>
<span id="L5581"><span class="lineNum">    5581</span>              : </span>
<span id="L5582"><span class="lineNum">    5582</span>              : // aten::isneginf(Tensor self) -&gt; Tensor</span>
<span id="L5583"><span class="lineNum">    5583</span>              : inline at::Tensor Tensor::isneginf() const {</span>
<span id="L5584"><span class="lineNum">    5584</span>              :     return at::_ops::isneginf::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L5585"><span class="lineNum">    5585</span>              : }</span>
<span id="L5586"><span class="lineNum">    5586</span>              : </span>
<span id="L5587"><span class="lineNum">    5587</span>              : // aten::det(Tensor self) -&gt; Tensor</span>
<span id="L5588"><span class="lineNum">    5588</span>              : inline at::Tensor Tensor::det() const {</span>
<span id="L5589"><span class="lineNum">    5589</span>              :     return at::_ops::det::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L5590"><span class="lineNum">    5590</span>              : }</span>
<span id="L5591"><span class="lineNum">    5591</span>              : </span>
<span id="L5592"><span class="lineNum">    5592</span>              : // aten::slogdet(Tensor self) -&gt; (Tensor sign, Tensor logabsdet)</span>
<span id="L5593"><span class="lineNum">    5593</span>              : inline ::std::tuple&lt;at::Tensor,at::Tensor&gt; Tensor::slogdet() const {</span>
<span id="L5594"><span class="lineNum">    5594</span>              :     return at::_ops::slogdet::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L5595"><span class="lineNum">    5595</span>              : }</span>
<span id="L5596"><span class="lineNum">    5596</span>              : </span>
<span id="L5597"><span class="lineNum">    5597</span>              : // aten::logdet(Tensor self) -&gt; Tensor</span>
<span id="L5598"><span class="lineNum">    5598</span>              : inline at::Tensor Tensor::logdet() const {</span>
<span id="L5599"><span class="lineNum">    5599</span>              :     return at::_ops::logdet::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L5600"><span class="lineNum">    5600</span>              : }</span>
<span id="L5601"><span class="lineNum">    5601</span>              : </span>
<span id="L5602"><span class="lineNum">    5602</span>              : // aten::inverse(Tensor self) -&gt; Tensor</span>
<span id="L5603"><span class="lineNum">    5603</span>              : inline at::Tensor Tensor::inverse() const {</span>
<span id="L5604"><span class="lineNum">    5604</span>              :     return at::_ops::inverse::call(const_cast&lt;Tensor&amp;&gt;(*this));</span>
<span id="L5605"><span class="lineNum">    5605</span>              : }</span>
<span id="L5606"><span class="lineNum">    5606</span>              : </span>
<span id="L5607"><span class="lineNum">    5607</span>              : // aten::inner(Tensor self, Tensor other) -&gt; Tensor</span>
<span id="L5608"><span class="lineNum">    5608</span>              : inline at::Tensor Tensor::inner(const at::Tensor &amp; other) const {</span>
<span id="L5609"><span class="lineNum">    5609</span>              :     return at::_ops::inner::call(const_cast&lt;Tensor&amp;&gt;(*this), other);</span>
<span id="L5610"><span class="lineNum">    5610</span>              : }</span>
<span id="L5611"><span class="lineNum">    5611</span>              : </span>
<span id="L5612"><span class="lineNum">    5612</span>              : // aten::outer(Tensor self, Tensor vec2) -&gt; Tensor</span>
<span id="L5613"><span class="lineNum">    5613</span>              : inline at::Tensor Tensor::outer(const at::Tensor &amp; vec2) const {</span>
<span id="L5614"><span class="lineNum">    5614</span>              :     return at::_ops::outer::call(const_cast&lt;Tensor&amp;&gt;(*this), vec2);</span>
<span id="L5615"><span class="lineNum">    5615</span>              : }</span>
<span id="L5616"><span class="lineNum">    5616</span>              : </span>
<span id="L5617"><span class="lineNum">    5617</span>              : // aten::ger(Tensor self, Tensor vec2) -&gt; Tensor</span>
<span id="L5618"><span class="lineNum">    5618</span>              : inline at::Tensor Tensor::ger(const at::Tensor &amp; vec2) const {</span>
<span id="L5619"><span class="lineNum">    5619</span>              :     return at::_ops::ger::call(const_cast&lt;Tensor&amp;&gt;(*this), vec2);</span>
<span id="L5620"><span class="lineNum">    5620</span>              : }</span>
<span id="L5621"><span class="lineNum">    5621</span>              : </span>
<span id="L5622"><span class="lineNum">    5622</span>              : // aten::to_padded_tensor(Tensor self, float padding, SymInt[]? output_size=None) -&gt; Tensor</span>
<span id="L5623"><span class="lineNum">    5623</span>              : inline at::Tensor Tensor::to_padded_tensor(double padding, at::OptionalIntArrayRef output_size) const {</span>
<span id="L5624"><span class="lineNum">    5624</span>              :     return at::_ops::to_padded_tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), padding, output_size.has_value() ? ::std::make_optional(c10::fromIntArrayRefSlow(*output_size)) : ::std::nullopt);</span>
<span id="L5625"><span class="lineNum">    5625</span>              : }</span>
<span id="L5626"><span class="lineNum">    5626</span>              : </span>
<span id="L5627"><span class="lineNum">    5627</span>              : // aten::to_padded_tensor(Tensor self, float padding, SymInt[]? output_size=None) -&gt; Tensor</span>
<span id="L5628"><span class="lineNum">    5628</span>              : inline at::Tensor Tensor::to_padded_tensor_symint(double padding, at::OptionalSymIntArrayRef output_size) const {</span>
<span id="L5629"><span class="lineNum">    5629</span>              :     return at::_ops::to_padded_tensor::call(const_cast&lt;Tensor&amp;&gt;(*this), padding, output_size);</span>
<span id="L5630"><span class="lineNum">    5630</span>              : }</span>
<span id="L5631"><span class="lineNum">    5631</span>              : } // namespace at</span>
<span id="L5632"><span class="lineNum">    5632</span>              : </span>
<span id="L5633"><span class="lineNum">    5633</span>              : </span>
<span id="L5634"><span class="lineNum">    5634</span>              : namespace c10 {</span>
<span id="L5635"><span class="lineNum">    5635</span>              : template &lt;&gt;</span>
<span id="L5636"><span class="lineNum">    5636</span>              : struct MaybeOwnedTraits&lt;at::Tensor&gt; {</span>
<span id="L5637"><span class="lineNum">    5637</span>              :   using owned_type = at::Tensor;</span>
<span id="L5638"><span class="lineNum">    5638</span>              :   using borrow_type = at::Tensor;</span>
<span id="L5639"><span class="lineNum">    5639</span>              : </span>
<span id="L5640"><span class="lineNum">    5640</span>              :   static borrow_type createBorrow(const owned_type&amp; from) {</span>
<span id="L5641"><span class="lineNum">    5641</span>              :     // NOTE: this can be implemented without the special</span>
<span id="L5642"><span class="lineNum">    5642</span>              :     // unsafe_borrow_t Tensor constructor as</span>
<span id="L5643"><span class="lineNum">    5643</span>              :     //</span>
<span id="L5644"><span class="lineNum">    5644</span>              :     // return borrow_type(c10::intrusive_ptr&lt;at::TensorImpl, at::UndefinedTensorImpl&gt;::reclaim(from.unsafeGetTensorImpl()));</span>
<span id="L5645"><span class="lineNum">    5645</span>              :     //</span>
<span id="L5646"><span class="lineNum">    5646</span>              :     // but that hurts inlining due to the nullptr check in the</span>
<span id="L5647"><span class="lineNum">    5647</span>              :     // Tensor(c10::intrusive_ptr&lt;...&gt;) constructor. We already know</span>
<span id="L5648"><span class="lineNum">    5648</span>              :     // that from.impl_ isn't null because from is a valid Tensor, so</span>
<span id="L5649"><span class="lineNum">    5649</span>              :     // we needn't do the check again. (using __builtin_assume can</span>
<span id="L5650"><span class="lineNum">    5650</span>              :     // avoid this, but wouldn't be portable to MSVC.)</span>
<span id="L5651"><span class="lineNum">    5651</span>              :     return borrow_type(borrow_type::unsafe_borrow_t{}, from);</span>
<span id="L5652"><span class="lineNum">    5652</span>              :   }</span>
<span id="L5653"><span class="lineNum">    5653</span>              : </span>
<span id="L5654"><span class="lineNum">    5654</span>              :   static void assignBorrow(borrow_type&amp; lhs, const borrow_type&amp; rhs) {</span>
<span id="L5655"><span class="lineNum">    5655</span>              :     lhs.unsafeReleaseTensorImpl();</span>
<span id="L5656"><span class="lineNum">    5656</span>              :     // See above note: this can be implemented with public API</span>
<span id="L5657"><span class="lineNum">    5657</span>              :     // similarly to createBorrow(), but that would hurt inlining.</span>
<span id="L5658"><span class="lineNum">    5658</span>              :     lhs = borrow_type(borrow_type::unsafe_borrow_t{}, rhs);</span>
<span id="L5659"><span class="lineNum">    5659</span>              :   }</span>
<span id="L5660"><span class="lineNum">    5660</span>              : </span>
<span id="L5661"><span class="lineNum">    5661</span>              :   static void destroyBorrow(borrow_type&amp; toDestroy) {</span>
<span id="L5662"><span class="lineNum">    5662</span>              :     toDestroy.unsafeReleaseTensorImpl(); // &quot;leak&quot; it, but it was already +0.</span>
<span id="L5663"><span class="lineNum">    5663</span>              :   }</span>
<span id="L5664"><span class="lineNum">    5664</span>              : </span>
<span id="L5665"><span class="lineNum">    5665</span>              :   static const owned_type&amp; referenceFromBorrow(const borrow_type&amp; borrow) {</span>
<span id="L5666"><span class="lineNum">    5666</span>              :     return borrow;</span>
<span id="L5667"><span class="lineNum">    5667</span>              :   }</span>
<span id="L5668"><span class="lineNum">    5668</span>              : </span>
<span id="L5669"><span class="lineNum">    5669</span>              :   static const owned_type* pointerFromBorrow(const borrow_type&amp; borrow) {</span>
<span id="L5670"><span class="lineNum">    5670</span>              :     return &amp;borrow;</span>
<span id="L5671"><span class="lineNum">    5671</span>              :   }</span>
<span id="L5672"><span class="lineNum">    5672</span>              : </span>
<span id="L5673"><span class="lineNum">    5673</span>              :   static bool debugBorrowIsValid(const borrow_type&amp; /*borrow*/) {</span>
<span id="L5674"><span class="lineNum">    5674</span>              :     return true;</span>
<span id="L5675"><span class="lineNum">    5675</span>              :   }</span>
<span id="L5676"><span class="lineNum">    5676</span>              : };</span>
<span id="L5677"><span class="lineNum">    5677</span>              : </span>
<span id="L5678"><span class="lineNum">    5678</span>              : template &lt;&gt;</span>
<span id="L5679"><span class="lineNum">    5679</span>              : struct ExclusivelyOwnedTraits&lt;at::Tensor&gt; {</span>
<span id="L5680"><span class="lineNum">    5680</span>              :   using repr_type = at::Tensor;</span>
<span id="L5681"><span class="lineNum">    5681</span>              :   using pointer_type = at::Tensor*;</span>
<span id="L5682"><span class="lineNum">    5682</span>              :   using const_pointer_type = const at::Tensor*;</span>
<span id="L5683"><span class="lineNum">    5683</span>              : </span>
<span id="L5684"><span class="lineNum">    5684</span>              :   static repr_type nullRepr() {</span>
<span id="L5685"><span class="lineNum">    5685</span>              :     return at::Tensor();</span>
<span id="L5686"><span class="lineNum">    5686</span>              :   }</span>
<span id="L5687"><span class="lineNum">    5687</span>              : </span>
<span id="L5688"><span class="lineNum">    5688</span>              :   template &lt;class... Args&gt;</span>
<span id="L5689"><span class="lineNum">    5689</span>              :   static repr_type createInPlace(Args&amp;&amp;... args) {</span>
<span id="L5690"><span class="lineNum">    5690</span>              :     return at::Tensor(std::forward&lt;Args&gt;(args)...);</span>
<span id="L5691"><span class="lineNum">    5691</span>              :   }</span>
<span id="L5692"><span class="lineNum">    5692</span>              : </span>
<span id="L5693"><span class="lineNum">    5693</span>              :   static repr_type moveToRepr(at::Tensor&amp;&amp; x) {</span>
<span id="L5694"><span class="lineNum">    5694</span>              :     return std::move(x);</span>
<span id="L5695"><span class="lineNum">    5695</span>              :   }</span>
<span id="L5696"><span class="lineNum">    5696</span>              : </span>
<span id="L5697"><span class="lineNum">    5697</span>              :   static void destroyOwned(at::Tensor&amp; x) {</span>
<span id="L5698"><span class="lineNum">    5698</span>              :     return ExclusivelyOwnedTraits&lt;at::TensorBase&gt;::destroyOwned(x);</span>
<span id="L5699"><span class="lineNum">    5699</span>              :   }</span>
<span id="L5700"><span class="lineNum">    5700</span>              : </span>
<span id="L5701"><span class="lineNum">    5701</span>              :   static at::Tensor take(at::Tensor&amp; x) {</span>
<span id="L5702"><span class="lineNum">    5702</span>              :     return std::move(x);</span>
<span id="L5703"><span class="lineNum">    5703</span>              :   }</span>
<span id="L5704"><span class="lineNum">    5704</span>              : </span>
<span id="L5705"><span class="lineNum">    5705</span>              :   static pointer_type getImpl(repr_type&amp; x) {</span>
<span id="L5706"><span class="lineNum">    5706</span>              :     return &amp;x;</span>
<span id="L5707"><span class="lineNum">    5707</span>              :   }</span>
<span id="L5708"><span class="lineNum">    5708</span>              : </span>
<span id="L5709"><span class="lineNum">    5709</span>              :   static const_pointer_type getImpl(const repr_type&amp; x) {</span>
<span id="L5710"><span class="lineNum">    5710</span>              :     return &amp;x;</span>
<span id="L5711"><span class="lineNum">    5711</span>              :   }</span>
<span id="L5712"><span class="lineNum">    5712</span>              : };</span>
<span id="L5713"><span class="lineNum">    5713</span>              : } // namespace c10</span>
<span id="L5714"><span class="lineNum">    5714</span>              : </span>
<span id="L5715"><span class="lineNum">    5715</span>              : namespace at {</span>
<span id="L5716"><span class="lineNum">    5716</span>              : </span>
<span id="L5717"><span class="lineNum">    5717</span>              : inline c10::MaybeOwned&lt;Tensor&gt; borrow_from_optional_tensor(</span>
<span id="L5718"><span class="lineNum">    5718</span>              :     const std::optional&lt;Tensor&gt;&amp; opt) {</span>
<span id="L5719"><span class="lineNum">    5719</span>              :   return opt.has_value()</span>
<span id="L5720"><span class="lineNum">    5720</span>              :     ? c10::MaybeOwned&lt;Tensor&gt;::borrowed(*opt)</span>
<span id="L5721"><span class="lineNum">    5721</span>              :     : c10::MaybeOwned&lt;Tensor&gt;::owned(std::in_place);</span>
<span id="L5722"><span class="lineNum">    5722</span>              : }</span>
<span id="L5723"><span class="lineNum">    5723</span>              : </span>
<span id="L5724"><span class="lineNum">    5724</span>              : inline c10::MaybeOwned&lt;Tensor&gt; Tensor::expect_contiguous(MemoryFormat memory_format) const &amp; {</span>
<span id="L5725"><span class="lineNum">    5725</span>              :   if (is_contiguous(memory_format)) {</span>
<span id="L5726"><span class="lineNum">    5726</span>              :     return c10::MaybeOwned&lt;Tensor&gt;::borrowed(*this);</span>
<span id="L5727"><span class="lineNum">    5727</span>              :   } else {</span>
<span id="L5728"><span class="lineNum">    5728</span>              :     return c10::MaybeOwned&lt;Tensor&gt;::owned(__dispatch_contiguous(memory_format));</span>
<span id="L5729"><span class="lineNum">    5729</span>              :   }</span>
<span id="L5730"><span class="lineNum">    5730</span>              : }</span>
<span id="L5731"><span class="lineNum">    5731</span>              : } // namespace at</span>
        </pre>
              </td>
            </tr>
          </table>
          <br>

          <table width="100%" border=0 cellspacing=0 cellpadding=0>
            <tr><td class="ruler"><img src="../../../../../../glass.png" width=3 height=3 alt=""></td></tr>
            <tr><td class="versionInfo">Generated by: <a href="https://github.com//linux-test-project/lcov" target="_parent">LCOV version 2.0-1</a></td></tr>
          </table>
          <br>

</body>
</html>
